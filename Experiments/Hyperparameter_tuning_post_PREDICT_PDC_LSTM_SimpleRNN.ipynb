{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import CuDNNGRU\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.utils import generic_utils\n",
    "from keras.utils import Sequence\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy \n",
    "import math\n",
    "import h5py\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "import feather\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from numpy.random import seed\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(456)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/whsu014/dev/mlrig/Experiments\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(os.getcwd())\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))\n",
    "from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VSIMPLE_INDEX_MASTER', 'QUARTER', 'AGE', 'SEX', 'NZDEP', 'ETHN_1',\n",
      "       'ETHN_2', 'ETHN_3', 'ETHN_4', 'ETHN_5',\n",
      "       ...\n",
      "       'PT_DIABETES_YR', 'PT_ATRIAL_FIBRILLATION', 'PT_IMP_FATAL_CVD',\n",
      "       'TRUE_HDL', 'TRUE_LDL', 'TRUE_TRI', 'TRUE_TCL', 'TRUE_TCHDL',\n",
      "       'TRUE_HBA1C', 'TRUE_EGFR'],\n",
      "      dtype='object', length=190)\n",
      "(2479500, 190)\n"
     ]
    }
   ],
   "source": [
    "view_1hot_df = feather.read_dataframe(\"/home/whsu014/data/Post_PREDICT_Train_with_TRUE_85500inds.feather\")\n",
    "print(view_1hot_df.columns)\n",
    "print(view_1hot_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inds: 85500\n",
      "85500.0\n",
      "85500.0\n",
      "(1710000, 182)\n",
      "85500.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of inds:\", len(view_1hot_df['VSIMPLE_INDEX_MASTER'].unique()))\n",
    "# set length to 28\n",
    "print(view_1hot_df.shape[0]/29)\n",
    "view_1hot_df = copy.deepcopy(view_1hot_df[view_1hot_df['QUARTER']>8])\n",
    "print(view_1hot_df.shape[0]/20)\n",
    "# Take 85500 inds for train and validation set\n",
    "# remove true values\n",
    "# remove QUARTER\n",
    "view_1hot_df = view_1hot_df.drop(['QUARTER'], axis=1)\n",
    "train_v = copy.deepcopy(view_1hot_df.iloc[:, :-7].values)\n",
    "print(train_v.shape)\n",
    "print(train_v.shape[0]/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise data\n",
    "# z = (X - u)/s\n",
    "# u is the mean of the training samples\n",
    "# s is the standard devidation of the training samples\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(train_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL_PDC: 28\n"
     ]
    }
   ],
   "source": [
    "print('LL_PDC:', view_1hot_df.columns.get_loc('LL_PDC'))\n",
    "#print('Unique LL_PDC:', np.unique(train_v[:, 28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_xy(time_series_v, scaled_v, obs_steps):\n",
    "    # make x_train and y_train\n",
    "    num_of_inds = time_series_v.shape[0]//20\n",
    "    print(\"Number of inds:\", num_of_inds)\n",
    "    num_of_features = time_series_v.shape[1]\n",
    "    print(\"Number of features:\", num_of_features)\n",
    "\n",
    "    x_ = np.empty((num_of_inds, obs_steps, num_of_features))\n",
    "    # creating 2 binary vectors for softmax \n",
    "    # non-adherent and adherent\n",
    "    y_ = np.empty((num_of_inds, 2))\n",
    "\n",
    "    for i in range(num_of_inds):\n",
    "        ind_v = time_series_v[(i*20):((i+1)*20), :]\n",
    "        if sum(ind_v[16:20, 28])/4 >= 80:\n",
    "            y_[i, 0] = 0.0\n",
    "            y_[i, 1] = 1.0\n",
    "        else:\n",
    "            y_[i, 0] = 1.0\n",
    "            y_[i, 1] = 0.0\n",
    "        scaled_ind_v = scaled_v[(i*20):((i+1)*20), :]\n",
    "        x_[i] = scaled_ind_v[(16-obs_steps):16, :]\n",
    "    return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inds: 85500\n",
      "Number of features: 182\n",
      "(85500, 8, 182)\n",
      "(85500, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = setup_xy(train_v, scaled_train, 8)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.rcParams.update({'font.size': 10})\n",
    "pyplot.figure(figsize=(8,5))\n",
    "pyplot.subplot(111)\n",
    "pyplot.hist(y_train[:, 1], bins=10)\n",
    "pyplot.xticks([0.05, 0.95], [\"Non-adherent\", \"Adherent\"])\n",
    "pyplot.subplots_adjust(top=0.9, bottom=0.1, left=0.10, right=0.7, hspace=0.4, wspace=0.2)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8550\n"
     ]
    }
   ],
   "source": [
    "num_per_fold = x_train.shape[0]//10\n",
    "print(num_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8550\n",
      "WARNING:tensorflow:From /home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6677 - acc: 0.7576 - val_loss: 0.4410 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44104, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3925 - acc: 0.8672 - val_loss: 0.3738 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44104 to 0.37378, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3557 - acc: 0.8704 - val_loss: 0.3543 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37378 to 0.35429, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3419 - acc: 0.8713 - val_loss: 0.3455 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35429 to 0.34548, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3354 - acc: 0.8721 - val_loss: 0.3407 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34548 to 0.34067, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3317 - acc: 0.8724 - val_loss: 0.3377 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34067 to 0.33768, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8726 - val_loss: 0.3358 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33768 to 0.33578, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3277 - acc: 0.8729 - val_loss: 0.3345 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33578 to 0.33451, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3267 - acc: 0.8728 - val_loss: 0.3338 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33451 to 0.33383, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3260 - acc: 0.8728 - val_loss: 0.3336 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33383 to 0.33356, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8727 - val_loss: 0.3335 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33356 to 0.33347, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8728 - val_loss: 0.3334 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33347 to 0.33344, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8729 - val_loss: 0.3338 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33344\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8730 - val_loss: 0.3336 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33344\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3237 - acc: 0.8730 - val_loss: 0.3338 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33344\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8732 - val_loss: 0.3338 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33344\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3232 - acc: 0.8731 - val_loss: 0.3341 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33344\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8730 - val_loss: 0.3340 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33344\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8732 - val_loss: 0.3345 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33344\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8733 - val_loss: 0.3346 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33344\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3225 - acc: 0.8735 - val_loss: 0.3350 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33344\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8735 - val_loss: 0.3351 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33344\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8736 - val_loss: 0.3352 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33344\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8736 - val_loss: 0.3354 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33344\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8740 - val_loss: 0.3356 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33344\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8741 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33344\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8740 - val_loss: 0.3360 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33344\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8744 - val_loss: 0.3361 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33344\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8744 - val_loss: 0.3365 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33344\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8744 - val_loss: 0.3367 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33344\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8745 - val_loss: 0.3370 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33344\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8745 - val_loss: 0.3373 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33344\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8746 - val_loss: 0.3375 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33344\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3204 - acc: 0.8751 - val_loss: 0.3377 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33344\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8752 - val_loss: 0.3378 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33344\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8752 - val_loss: 0.3381 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33344\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8753 - val_loss: 0.3383 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33344\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8755 - val_loss: 0.3386 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33344\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8755 - val_loss: 0.3383 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33344\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8754 - val_loss: 0.3383 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33344\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8753 - val_loss: 0.3383 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33344\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8756 - val_loss: 0.3382 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33344\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8758 - val_loss: 0.3387 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33344\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8760 - val_loss: 0.3384 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33344\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8760 - val_loss: 0.3389 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33344\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8759 - val_loss: 0.3395 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33344\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8762 - val_loss: 0.3397 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33344\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8762 - val_loss: 0.3402 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33344\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8764 - val_loss: 0.3407 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33344\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8764 - val_loss: 0.3409 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33344\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8765 - val_loss: 0.3416 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33344\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8767 - val_loss: 0.3417 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33344\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8765 - val_loss: 0.3421 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33344\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8765 - val_loss: 0.3421 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33344\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8767 - val_loss: 0.3424 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33344\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8769 - val_loss: 0.3423 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33344\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8770 - val_loss: 0.3425 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33344\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8770 - val_loss: 0.3421 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33344\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8768 - val_loss: 0.3420 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33344\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8768 - val_loss: 0.3420 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33344\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8769 - val_loss: 0.3418 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33344\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8769 - val_loss: 0.3423 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33344\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8772 - val_loss: 0.3422 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33344\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8775 - val_loss: 0.3415 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33344\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8775 - val_loss: 0.3419 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33344\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8774 - val_loss: 0.3424 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33344\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8776 - val_loss: 0.3429 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33344\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8776 - val_loss: 0.3437 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33344\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8774 - val_loss: 0.3427 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33344\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8776 - val_loss: 0.3440 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33344\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8780 - val_loss: 0.3429 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33344\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8777 - val_loss: 0.3433 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33344\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8778 - val_loss: 0.3435 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33344\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8778 - val_loss: 0.3431 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33344\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8778 - val_loss: 0.3428 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33344\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8776 - val_loss: 0.3427 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33344\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8776 - val_loss: 0.3430 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33344\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8775 - val_loss: 0.3437 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33344\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8776 - val_loss: 0.3446 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33344\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8776 - val_loss: 0.3448 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33344\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8774 - val_loss: 0.3455 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33344\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8775 - val_loss: 0.3473 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33344\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8779 - val_loss: 0.3469 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33344\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8781 - val_loss: 0.3465 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33344\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8780 - val_loss: 0.3474 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33344\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8778 - val_loss: 0.3468 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33344\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8780 - val_loss: 0.3463 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33344\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8778 - val_loss: 0.3477 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33344\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8776 - val_loss: 0.3474 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33344\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8777 - val_loss: 0.3480 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33344\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8776 - val_loss: 0.3482 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33344\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8779 - val_loss: 0.3480 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33344\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8777 - val_loss: 0.3487 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33344\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8779 - val_loss: 0.3478 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33344\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8779 - val_loss: 0.3469 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33344\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8777 - val_loss: 0.3471 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33344\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8785 - val_loss: 0.3459 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33344\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8780 - val_loss: 0.3473 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33344\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8777 - val_loss: 0.3471 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33344\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8784 - val_loss: 0.3472 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33344\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 512\n",
      "Fold: 0\n",
      "best val loss: 0.33344130067797434\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  142.1764349937439\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6700 - acc: 0.7562 - val_loss: 0.4351 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43512, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3930 - acc: 0.8669 - val_loss: 0.3710 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43512 to 0.37100, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3555 - acc: 0.8698 - val_loss: 0.3520 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37100 to 0.35203, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3418 - acc: 0.8713 - val_loss: 0.3435 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35203 to 0.34354, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3350 - acc: 0.8719 - val_loss: 0.3391 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34354 to 0.33915, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3313 - acc: 0.8721 - val_loss: 0.3368 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33915 to 0.33677, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3289 - acc: 0.8726 - val_loss: 0.3353 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33677 to 0.33531, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3274 - acc: 0.8726 - val_loss: 0.3344 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33531 to 0.33445, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3262 - acc: 0.8733 - val_loss: 0.3340 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33445 to 0.33404, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3254 - acc: 0.8734 - val_loss: 0.3338 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33404 to 0.33378, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8735 - val_loss: 0.3337 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33378 to 0.33366, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8734 - val_loss: 0.3340 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33366\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8735 - val_loss: 0.3341 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33366\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3235 - acc: 0.8735 - val_loss: 0.3348 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33366\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3232 - acc: 0.8736 - val_loss: 0.3347 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33366\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8737 - val_loss: 0.3352 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33366\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8739 - val_loss: 0.3351 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33366\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8738 - val_loss: 0.3353 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33366\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8741 - val_loss: 0.3354 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33366\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8743 - val_loss: 0.3356 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33366\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8742 - val_loss: 0.3357 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33366\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8744 - val_loss: 0.3362 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33366\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8746 - val_loss: 0.3362 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33366\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8747 - val_loss: 0.3363 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33366\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8750 - val_loss: 0.3369 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33366\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8751 - val_loss: 0.3370 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33366\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8750 - val_loss: 0.3369 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33366\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8752 - val_loss: 0.3377 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33366\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8751 - val_loss: 0.3380 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33366\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8754 - val_loss: 0.3380 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33366\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8754 - val_loss: 0.3380 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33366\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8754 - val_loss: 0.3384 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33366\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8756 - val_loss: 0.3384 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33366\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8756 - val_loss: 0.3385 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33366\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8758 - val_loss: 0.3386 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33366\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8760 - val_loss: 0.3387 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33366\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8760 - val_loss: 0.3390 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33366\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8759 - val_loss: 0.3392 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33366\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8758 - val_loss: 0.3392 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33366\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8758 - val_loss: 0.3400 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33366\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8760 - val_loss: 0.3402 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33366\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8759 - val_loss: 0.3403 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33366\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8759 - val_loss: 0.3402 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33366\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8761 - val_loss: 0.3406 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33366\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8760 - val_loss: 0.3407 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33366\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8761 - val_loss: 0.3407 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33366\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8764 - val_loss: 0.3412 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33366\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8760 - val_loss: 0.3415 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33366\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8760 - val_loss: 0.3413 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33366\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8765 - val_loss: 0.3419 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33366\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8763 - val_loss: 0.3416 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33366\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8762 - val_loss: 0.3418 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33366\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8764 - val_loss: 0.3422 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33366\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8763 - val_loss: 0.3419 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33366\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8761 - val_loss: 0.3411 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33366\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8762 - val_loss: 0.3424 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33366\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3180 - acc: 0.8764 - val_loss: 0.3416 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33366\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8767 - val_loss: 0.3422 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33366\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8766 - val_loss: 0.3422 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33366\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8767 - val_loss: 0.3418 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33366\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8769 - val_loss: 0.3427 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33366\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8769 - val_loss: 0.3423 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33366\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8768 - val_loss: 0.3430 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33366\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8771 - val_loss: 0.3428 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33366\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8774 - val_loss: 0.3432 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33366\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8772 - val_loss: 0.3431 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33366\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8778 - val_loss: 0.3433 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33366\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8776 - val_loss: 0.3425 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33366\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8774 - val_loss: 0.3429 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33366\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8769 - val_loss: 0.3424 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33366\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8775 - val_loss: 0.3426 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33366\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8776 - val_loss: 0.3428 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33366\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8778 - val_loss: 0.3429 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33366\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8778 - val_loss: 0.3427 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33366\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8775 - val_loss: 0.3425 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33366\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8777 - val_loss: 0.3434 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33366\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8774 - val_loss: 0.3432 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33366\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8773 - val_loss: 0.3437 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33366\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8777 - val_loss: 0.3438 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33366\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8774 - val_loss: 0.3441 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33366\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8775 - val_loss: 0.3441 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33366\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8778 - val_loss: 0.3435 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33366\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8778 - val_loss: 0.3447 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33366\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8780 - val_loss: 0.3454 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33366\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8781 - val_loss: 0.3447 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33366\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8778 - val_loss: 0.3448 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33366\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8780 - val_loss: 0.3441 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33366\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8775 - val_loss: 0.3440 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33366\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8777 - val_loss: 0.3452 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33366\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8780 - val_loss: 0.3454 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33366\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8776 - val_loss: 0.3461 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33366\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8781 - val_loss: 0.3472 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33366\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8774 - val_loss: 0.3472 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33366\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8775 - val_loss: 0.3476 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33366\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8779 - val_loss: 0.3475 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33366\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8778 - val_loss: 0.3473 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33366\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8781 - val_loss: 0.3482 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33366\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8779 - val_loss: 0.3481 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33366\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8777 - val_loss: 0.3483 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33366\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8779 - val_loss: 0.3482 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33366\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 512\n",
      "Fold: 1\n",
      "best val loss: 0.33365830542748437\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  141.16710019111633\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6681 - acc: 0.7569 - val_loss: 0.4475 - val_acc: 0.8503\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44751, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3920 - acc: 0.8674 - val_loss: 0.3770 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44751 to 0.37704, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3550 - acc: 0.8711 - val_loss: 0.3571 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37704 to 0.35713, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3413 - acc: 0.8721 - val_loss: 0.3487 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35713 to 0.34875, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3346 - acc: 0.8727 - val_loss: 0.3444 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34875 to 0.34439, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3310 - acc: 0.8726 - val_loss: 0.3419 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34439 to 0.34192, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3285 - acc: 0.8730 - val_loss: 0.3403 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34192 to 0.34030, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3269 - acc: 0.8732 - val_loss: 0.3397 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34030 to 0.33969, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3257 - acc: 0.8735 - val_loss: 0.3392 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33969 to 0.33919, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3249 - acc: 0.8733 - val_loss: 0.3392 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33919\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8735 - val_loss: 0.3394 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.33919\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3237 - acc: 0.8737 - val_loss: 0.3400 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33919\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8736 - val_loss: 0.3398 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33919\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8738 - val_loss: 0.3400 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33919\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8739 - val_loss: 0.3401 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33919\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8742 - val_loss: 0.3403 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33919\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8742 - val_loss: 0.3405 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33919\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8744 - val_loss: 0.3407 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33919\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8745 - val_loss: 0.3406 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33919\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8744 - val_loss: 0.3408 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33919\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8744 - val_loss: 0.3410 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33919\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8744 - val_loss: 0.3415 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33919\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8745 - val_loss: 0.3416 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33919\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8744 - val_loss: 0.3418 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33919\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8744 - val_loss: 0.3419 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33919\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8746 - val_loss: 0.3421 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33919\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3204 - acc: 0.8749 - val_loss: 0.3425 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33919\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8746 - val_loss: 0.3421 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33919\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8748 - val_loss: 0.3425 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33919\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8751 - val_loss: 0.3424 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33919\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8750 - val_loss: 0.3427 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33919\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8753 - val_loss: 0.3427 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33919\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8754 - val_loss: 0.3429 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33919\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8756 - val_loss: 0.3432 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33919\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8756 - val_loss: 0.3431 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33919\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8755 - val_loss: 0.3433 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33919\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8753 - val_loss: 0.3433 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33919\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8754 - val_loss: 0.3437 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33919\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8754 - val_loss: 0.3441 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33919\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8754 - val_loss: 0.3440 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33919\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8756 - val_loss: 0.3439 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33919\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8756 - val_loss: 0.3441 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33919\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8758 - val_loss: 0.3444 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33919\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8758 - val_loss: 0.3444 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33919\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8758 - val_loss: 0.3447 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33919\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8757 - val_loss: 0.3447 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33919\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8755 - val_loss: 0.3449 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33919\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8757 - val_loss: 0.3449 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33919\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8756 - val_loss: 0.3454 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33919\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8757 - val_loss: 0.3457 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33919\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8756 - val_loss: 0.3457 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33919\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8758 - val_loss: 0.3457 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33919\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8759 - val_loss: 0.3461 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33919\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8758 - val_loss: 0.3461 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33919\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8759 - val_loss: 0.3459 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33919\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8759 - val_loss: 0.3459 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33919\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8759 - val_loss: 0.3455 - val_acc: 0.8639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33919\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8761 - val_loss: 0.3458 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33919\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8758 - val_loss: 0.3456 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33919\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8760 - val_loss: 0.3454 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33919\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8762 - val_loss: 0.3456 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33919\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8764 - val_loss: 0.3455 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33919\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8761 - val_loss: 0.3454 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33919\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8763 - val_loss: 0.3460 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33919\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8763 - val_loss: 0.3459 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33919\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8764 - val_loss: 0.3464 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33919\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8764 - val_loss: 0.3461 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33919\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8764 - val_loss: 0.3462 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33919\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8765 - val_loss: 0.3464 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33919\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8767 - val_loss: 0.3469 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33919\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8765 - val_loss: 0.3467 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33919\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8767 - val_loss: 0.3466 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33919\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8768 - val_loss: 0.3467 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33919\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8772 - val_loss: 0.3470 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33919\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8768 - val_loss: 0.3473 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33919\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8768 - val_loss: 0.3474 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33919\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8770 - val_loss: 0.3481 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33919\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8772 - val_loss: 0.3482 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33919\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8771 - val_loss: 0.3489 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33919\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8771 - val_loss: 0.3494 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33919\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8768 - val_loss: 0.3492 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33919\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8768 - val_loss: 0.3501 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33919\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8767 - val_loss: 0.3496 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33919\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8769 - val_loss: 0.3498 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33919\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8772 - val_loss: 0.3494 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33919\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8772 - val_loss: 0.3499 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33919\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8773 - val_loss: 0.3489 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33919\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8776 - val_loss: 0.3488 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33919\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8776 - val_loss: 0.3494 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33919\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8776 - val_loss: 0.3490 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33919\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8780 - val_loss: 0.3499 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33919\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8779 - val_loss: 0.3491 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33919\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8778 - val_loss: 0.3490 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33919\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8778 - val_loss: 0.3490 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33919\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8776 - val_loss: 0.3493 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33919\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8774 - val_loss: 0.3494 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33919\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8776 - val_loss: 0.3494 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33919\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8775 - val_loss: 0.3502 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33919\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8776 - val_loss: 0.3508 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33919\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8778 - val_loss: 0.3519 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33919\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 512\n",
      "Fold: 2\n",
      "best val loss: 0.3391906669892763\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  142.96739745140076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f68c0792b00>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6715 - acc: 0.7559 - val_loss: 0.4379 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43795, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3932 - acc: 0.8668 - val_loss: 0.3704 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43795 to 0.37044, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3559 - acc: 0.8701 - val_loss: 0.3504 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37044 to 0.35038, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3425 - acc: 0.8708 - val_loss: 0.3417 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35038 to 0.34171, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3357 - acc: 0.8718 - val_loss: 0.3375 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34171 to 0.33748, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3321 - acc: 0.8720 - val_loss: 0.3351 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33748 to 0.33509, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3296 - acc: 0.8722 - val_loss: 0.3342 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33509 to 0.33418, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3279 - acc: 0.8724 - val_loss: 0.3335 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33418 to 0.33355, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3269 - acc: 0.8723 - val_loss: 0.3334 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33355 to 0.33342, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3259 - acc: 0.8727 - val_loss: 0.3334 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33342 to 0.33341, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3253 - acc: 0.8730 - val_loss: 0.3337 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.33341\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8734 - val_loss: 0.3337 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33341\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8735 - val_loss: 0.3343 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33341\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8735 - val_loss: 0.3342 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33341\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3236 - acc: 0.8733 - val_loss: 0.3347 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33341\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3233 - acc: 0.8737 - val_loss: 0.3348 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33341\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8739 - val_loss: 0.3351 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33341\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8738 - val_loss: 0.3352 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33341\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8736 - val_loss: 0.3357 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33341\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8737 - val_loss: 0.3358 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33341\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8737 - val_loss: 0.3362 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33341\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8739 - val_loss: 0.3363 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33341\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8739 - val_loss: 0.3366 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33341\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8739 - val_loss: 0.3367 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33341\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8743 - val_loss: 0.3369 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33341\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8742 - val_loss: 0.3372 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33341\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8743 - val_loss: 0.3377 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33341\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8745 - val_loss: 0.3375 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33341\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8745 - val_loss: 0.3378 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33341\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8745 - val_loss: 0.3381 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33341\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8748 - val_loss: 0.3382 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33341\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8750 - val_loss: 0.3380 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33341\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8750 - val_loss: 0.3383 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33341\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8750 - val_loss: 0.3378 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33341\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8754 - val_loss: 0.3376 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33341\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8754 - val_loss: 0.3380 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33341\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8755 - val_loss: 0.3384 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33341\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8756 - val_loss: 0.3386 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33341\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8756 - val_loss: 0.3388 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33341\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8755 - val_loss: 0.3389 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33341\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8754 - val_loss: 0.3392 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33341\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8754 - val_loss: 0.3385 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33341\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8752 - val_loss: 0.3396 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33341\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8751 - val_loss: 0.3402 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33341\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8751 - val_loss: 0.3402 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33341\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8752 - val_loss: 0.3405 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33341\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8752 - val_loss: 0.3417 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33341\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8750 - val_loss: 0.3416 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33341\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8752 - val_loss: 0.3431 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33341\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8752 - val_loss: 0.3427 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33341\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8753 - val_loss: 0.3437 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33341\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8753 - val_loss: 0.3429 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33341\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8755 - val_loss: 0.3439 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33341\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8753 - val_loss: 0.3436 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33341\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8755 - val_loss: 0.3435 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33341\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8755 - val_loss: 0.3434 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33341\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8756 - val_loss: 0.3432 - val_acc: 0.8682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33341\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8757 - val_loss: 0.3438 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33341\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8760 - val_loss: 0.3437 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33341\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8758 - val_loss: 0.3443 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33341\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8757 - val_loss: 0.3444 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33341\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8761 - val_loss: 0.3435 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33341\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8764 - val_loss: 0.3437 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33341\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8765 - val_loss: 0.3444 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33341\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8767 - val_loss: 0.3439 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33341\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8764 - val_loss: 0.3444 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33341\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8764 - val_loss: 0.3445 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33341\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8764 - val_loss: 0.3451 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33341\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8765 - val_loss: 0.3444 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33341\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8764 - val_loss: 0.3446 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33341\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8768 - val_loss: 0.3447 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33341\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8770 - val_loss: 0.3454 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33341\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8766 - val_loss: 0.3453 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33341\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8768 - val_loss: 0.3446 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33341\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8767 - val_loss: 0.3460 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33341\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8768 - val_loss: 0.3454 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33341\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8771 - val_loss: 0.3467 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33341\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8766 - val_loss: 0.3465 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33341\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8772 - val_loss: 0.3465 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33341\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8777 - val_loss: 0.3462 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33341\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8772 - val_loss: 0.3463 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33341\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8775 - val_loss: 0.3467 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33341\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8774 - val_loss: 0.3467 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33341\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8774 - val_loss: 0.3465 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33341\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8779 - val_loss: 0.3475 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33341\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8782 - val_loss: 0.3482 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33341\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8775 - val_loss: 0.3489 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33341\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8779 - val_loss: 0.3488 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33341\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8776 - val_loss: 0.3491 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33341\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8779 - val_loss: 0.3482 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33341\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8778 - val_loss: 0.3492 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33341\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8774 - val_loss: 0.3488 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33341\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8776 - val_loss: 0.3482 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33341\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8776 - val_loss: 0.3490 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33341\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8773 - val_loss: 0.3493 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33341\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8773 - val_loss: 0.3491 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33341\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8772 - val_loss: 0.3481 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33341\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8769 - val_loss: 0.3487 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33341\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8770 - val_loss: 0.3491 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33341\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8770 - val_loss: 0.3494 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33341\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 512\n",
      "Fold: 3\n",
      "best val loss: 0.3334132865367577\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  144.25877285003662\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6693 - acc: 0.7579 - val_loss: 0.4450 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44501, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3917 - acc: 0.8676 - val_loss: 0.3778 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44501 to 0.37783, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3543 - acc: 0.8712 - val_loss: 0.3581 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37783 to 0.35809, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3407 - acc: 0.8722 - val_loss: 0.3493 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35809 to 0.34932, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3344 - acc: 0.8725 - val_loss: 0.3451 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34932 to 0.34506, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3309 - acc: 0.8726 - val_loss: 0.3427 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34506 to 0.34270, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3287 - acc: 0.8730 - val_loss: 0.3414 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34270 to 0.34141, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3271 - acc: 0.8733 - val_loss: 0.3404 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34141 to 0.34040, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3260 - acc: 0.8734 - val_loss: 0.3399 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34040 to 0.33991, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3253 - acc: 0.8736 - val_loss: 0.3398 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33991 to 0.33976, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8738 - val_loss: 0.3395 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33976 to 0.33950, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8737 - val_loss: 0.3396 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33950\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8736 - val_loss: 0.3395 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33950\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8737 - val_loss: 0.3394 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33950 to 0.33941, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8737 - val_loss: 0.3395 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33941\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8739 - val_loss: 0.3395 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33941\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8738 - val_loss: 0.3399 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33941\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8743 - val_loss: 0.3397 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33941\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8741 - val_loss: 0.3399 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33941\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8740 - val_loss: 0.3403 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33941\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8741 - val_loss: 0.3402 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33941\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8743 - val_loss: 0.3403 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33941\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8745 - val_loss: 0.3404 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33941\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8746 - val_loss: 0.3404 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33941\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8747 - val_loss: 0.3405 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33941\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8750 - val_loss: 0.3407 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33941\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8749 - val_loss: 0.3409 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33941\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8750 - val_loss: 0.3413 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33941\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8752 - val_loss: 0.3416 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33941\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8753 - val_loss: 0.3418 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33941\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8751 - val_loss: 0.3422 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33941\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8753 - val_loss: 0.3420 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33941\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8753 - val_loss: 0.3424 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33941\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8753 - val_loss: 0.3424 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33941\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8755 - val_loss: 0.3425 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33941\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8756 - val_loss: 0.3424 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33941\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8756 - val_loss: 0.3424 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33941\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8753 - val_loss: 0.3425 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33941\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8753 - val_loss: 0.3425 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33941\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8753 - val_loss: 0.3422 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33941\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8756 - val_loss: 0.3427 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33941\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8757 - val_loss: 0.3427 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33941\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8755 - val_loss: 0.3428 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33941\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8754 - val_loss: 0.3431 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33941\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8758 - val_loss: 0.3435 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33941\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8758 - val_loss: 0.3442 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33941\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8760 - val_loss: 0.3441 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33941\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8762 - val_loss: 0.3451 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33941\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8764 - val_loss: 0.3452 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33941\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8763 - val_loss: 0.3449 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33941\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8768 - val_loss: 0.3460 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33941\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8767 - val_loss: 0.3458 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33941\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8766 - val_loss: 0.3461 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33941\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8766 - val_loss: 0.3466 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33941\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8767 - val_loss: 0.3471 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33941\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8770 - val_loss: 0.3468 - val_acc: 0.8646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33941\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8767 - val_loss: 0.3465 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33941\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8772 - val_loss: 0.3466 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33941\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8770 - val_loss: 0.3472 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33941\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8769 - val_loss: 0.3477 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33941\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8769 - val_loss: 0.3479 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33941\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8771 - val_loss: 0.3482 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33941\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8772 - val_loss: 0.3485 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33941\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8777 - val_loss: 0.3491 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33941\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8777 - val_loss: 0.3493 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33941\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8779 - val_loss: 0.3491 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33941\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8785 - val_loss: 0.3501 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33941\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8783 - val_loss: 0.3495 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33941\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8782 - val_loss: 0.3499 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33941\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8784 - val_loss: 0.3493 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33941\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8788 - val_loss: 0.3500 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33941\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8789 - val_loss: 0.3494 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33941\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8791 - val_loss: 0.3499 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33941\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8793 - val_loss: 0.3501 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33941\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8793 - val_loss: 0.3502 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33941\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8795 - val_loss: 0.3504 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33941\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8792 - val_loss: 0.3507 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33941\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8793 - val_loss: 0.3504 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33941\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8792 - val_loss: 0.3511 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33941\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8789 - val_loss: 0.3510 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33941\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8793 - val_loss: 0.3512 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33941\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8787 - val_loss: 0.3515 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33941\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8786 - val_loss: 0.3509 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33941\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8788 - val_loss: 0.3513 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33941\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8787 - val_loss: 0.3513 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33941\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8788 - val_loss: 0.3517 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33941\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8789 - val_loss: 0.3524 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33941\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8788 - val_loss: 0.3528 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33941\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8788 - val_loss: 0.3529 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33941\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8786 - val_loss: 0.3518 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33941\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8787 - val_loss: 0.3517 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33941\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8785 - val_loss: 0.3519 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33941\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8788 - val_loss: 0.3518 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33941\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8786 - val_loss: 0.3510 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33941\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8787 - val_loss: 0.3509 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33941\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8786 - val_loss: 0.3521 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33941\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8790 - val_loss: 0.3507 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33941\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8790 - val_loss: 0.3504 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33941\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8789 - val_loss: 0.3516 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33941\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8788 - val_loss: 0.3518 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33941\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 512\n",
      "Fold: 4\n",
      "best val loss: 0.3394083375122115\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  144.28396797180176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f68b4630470>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8190 - acc: 0.6818 - val_loss: 0.5790 - val_acc: 0.8097\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57898, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4739 - acc: 0.8485 - val_loss: 0.4201 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57898 to 0.42007, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3891 - acc: 0.8667 - val_loss: 0.3799 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42007 to 0.37993, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3616 - acc: 0.8702 - val_loss: 0.3620 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37993 to 0.36204, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3481 - acc: 0.8712 - val_loss: 0.3524 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36204 to 0.35238, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3404 - acc: 0.8720 - val_loss: 0.3466 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35238 to 0.34656, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3355 - acc: 0.8725 - val_loss: 0.3425 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34656 to 0.34252, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3322 - acc: 0.8730 - val_loss: 0.3398 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34252 to 0.33981, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3298 - acc: 0.8732 - val_loss: 0.3379 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33981 to 0.33785, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3281 - acc: 0.8731 - val_loss: 0.3363 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33785 to 0.33634, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3266 - acc: 0.8734 - val_loss: 0.3353 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33634 to 0.33528, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8733 - val_loss: 0.3344 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33528 to 0.33445, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3246 - acc: 0.8733 - val_loss: 0.3339 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33445 to 0.33388, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8732 - val_loss: 0.3335 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33388 to 0.33351, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3232 - acc: 0.8734 - val_loss: 0.3333 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33351 to 0.33330, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8735 - val_loss: 0.3332 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33330 to 0.33324, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8736 - val_loss: 0.3332 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33324 to 0.33318, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8737 - val_loss: 0.3332 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33318\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8740 - val_loss: 0.3332 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33318 to 0.33315, saving model to Post_val_weights1.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8740 - val_loss: 0.3332 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33315\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8744 - val_loss: 0.3333 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33315\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3204 - acc: 0.8745 - val_loss: 0.3334 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33315\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8746 - val_loss: 0.3335 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33315\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8745 - val_loss: 0.3338 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33315\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8746 - val_loss: 0.3338 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33315\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8746 - val_loss: 0.3342 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33315\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8747 - val_loss: 0.3346 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33315\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8746 - val_loss: 0.3347 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33315\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8747 - val_loss: 0.3351 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33315\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8748 - val_loss: 0.3352 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33315\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8748 - val_loss: 0.3356 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33315\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8747 - val_loss: 0.3356 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33315\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8748 - val_loss: 0.3359 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33315\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8749 - val_loss: 0.3360 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33315\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8749 - val_loss: 0.3360 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33315\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8749 - val_loss: 0.3362 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33315\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8749 - val_loss: 0.3361 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33315\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8749 - val_loss: 0.3365 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33315\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8749 - val_loss: 0.3364 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33315\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8749 - val_loss: 0.3367 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33315\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8749 - val_loss: 0.3368 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33315\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8750 - val_loss: 0.3367 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33315\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8751 - val_loss: 0.3371 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33315\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8753 - val_loss: 0.3372 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33315\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8752 - val_loss: 0.3374 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33315\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8753 - val_loss: 0.3376 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33315\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8755 - val_loss: 0.3379 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33315\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8754 - val_loss: 0.3379 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33315\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8756 - val_loss: 0.3383 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33315\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8755 - val_loss: 0.3384 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33315\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8759 - val_loss: 0.3388 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33315\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8760 - val_loss: 0.3389 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33315\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8761 - val_loss: 0.3390 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33315\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8761 - val_loss: 0.3395 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33315\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3156 - acc: 0.8766 - val_loss: 0.3396 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33315\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8765 - val_loss: 0.3400 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33315\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8767 - val_loss: 0.3400 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33315\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8768 - val_loss: 0.3404 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33315\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8769 - val_loss: 0.3404 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33315\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8771 - val_loss: 0.3406 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33315\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8769 - val_loss: 0.3407 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33315\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8769 - val_loss: 0.3411 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33315\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8766 - val_loss: 0.3412 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33315\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8768 - val_loss: 0.3414 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33315\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8768 - val_loss: 0.3418 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33315\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8771 - val_loss: 0.3420 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33315\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8769 - val_loss: 0.3424 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33315\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8772 - val_loss: 0.3426 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33315\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8773 - val_loss: 0.3428 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33315\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8774 - val_loss: 0.3431 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33315\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8773 - val_loss: 0.3435 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33315\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8775 - val_loss: 0.3437 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33315\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8775 - val_loss: 0.3439 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33315\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8777 - val_loss: 0.3441 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33315\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8779 - val_loss: 0.3441 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33315\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8779 - val_loss: 0.3444 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33315\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8779 - val_loss: 0.3448 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33315\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8781 - val_loss: 0.3451 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33315\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8779 - val_loss: 0.3453 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33315\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8778 - val_loss: 0.3456 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33315\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8777 - val_loss: 0.3461 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33315\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8778 - val_loss: 0.3461 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33315\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8779 - val_loss: 0.3463 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33315\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8778 - val_loss: 0.3464 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33315\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8777 - val_loss: 0.3466 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33315\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8776 - val_loss: 0.3467 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33315\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8776 - val_loss: 0.3472 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33315\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8775 - val_loss: 0.3475 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33315\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8777 - val_loss: 0.3472 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33315\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8776 - val_loss: 0.3475 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33315\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8775 - val_loss: 0.3483 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33315\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8773 - val_loss: 0.3478 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33315\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8775 - val_loss: 0.3484 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33315\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8773 - val_loss: 0.3482 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33315\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8774 - val_loss: 0.3479 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33315\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8774 - val_loss: 0.3482 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33315\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8776 - val_loss: 0.3488 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33315\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8778 - val_loss: 0.3490 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33315\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8778 - val_loss: 0.3495 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33315\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8777 - val_loss: 0.3493 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33315\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 1024\n",
      "Fold: 0\n",
      "best val loss: 0.3331538017172562\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  92.8881402015686\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8210 - acc: 0.6780 - val_loss: 0.5730 - val_acc: 0.8213\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57302, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4756 - acc: 0.8477 - val_loss: 0.4141 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57302 to 0.41412, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3887 - acc: 0.8671 - val_loss: 0.3762 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41412 to 0.37622, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3612 - acc: 0.8703 - val_loss: 0.3594 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37622 to 0.35937, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3478 - acc: 0.8714 - val_loss: 0.3505 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35937 to 0.35049, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3401 - acc: 0.8720 - val_loss: 0.3452 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35049 to 0.34519, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3351 - acc: 0.8725 - val_loss: 0.3417 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34519 to 0.34167, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3318 - acc: 0.8729 - val_loss: 0.3392 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34167 to 0.33925, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3294 - acc: 0.8731 - val_loss: 0.3376 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33925 to 0.33755, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3276 - acc: 0.8732 - val_loss: 0.3358 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33755 to 0.33583, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3262 - acc: 0.8732 - val_loss: 0.3353 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33583 to 0.33525, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8732 - val_loss: 0.3342 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33525 to 0.33417, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8734 - val_loss: 0.3338 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33417 to 0.33376, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3235 - acc: 0.8737 - val_loss: 0.3334 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33376 to 0.33336, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8738 - val_loss: 0.3331 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33336 to 0.33311, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8739 - val_loss: 0.3330 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33311 to 0.33298, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8740 - val_loss: 0.3330 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33298 to 0.33298, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8743 - val_loss: 0.3331 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33298\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8743 - val_loss: 0.3331 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33298\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8743 - val_loss: 0.3334 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33298\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3204 - acc: 0.8746 - val_loss: 0.3333 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33298\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8745 - val_loss: 0.3337 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33298\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8746 - val_loss: 0.3335 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33298\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8746 - val_loss: 0.3340 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33298\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8750 - val_loss: 0.3341 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33298\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8750 - val_loss: 0.3345 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33298\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8752 - val_loss: 0.3349 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33298\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8753 - val_loss: 0.3350 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33298\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8753 - val_loss: 0.3354 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33298\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8756 - val_loss: 0.3354 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33298\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8755 - val_loss: 0.3360 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33298\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8756 - val_loss: 0.3361 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33298\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8756 - val_loss: 0.3366 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33298\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8756 - val_loss: 0.3369 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33298\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8757 - val_loss: 0.3372 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33298\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8758 - val_loss: 0.3375 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33298\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8760 - val_loss: 0.3377 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33298\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8762 - val_loss: 0.3378 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33298\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8762 - val_loss: 0.3384 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33298\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8764 - val_loss: 0.3385 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33298\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8765 - val_loss: 0.3384 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33298\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8764 - val_loss: 0.3387 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33298\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8765 - val_loss: 0.3388 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33298\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8766 - val_loss: 0.3390 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33298\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8769 - val_loss: 0.3395 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33298\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8769 - val_loss: 0.3396 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33298\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8771 - val_loss: 0.3399 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33298\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8773 - val_loss: 0.3402 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33298\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8775 - val_loss: 0.3408 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33298\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8777 - val_loss: 0.3409 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33298\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8776 - val_loss: 0.3414 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33298\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8777 - val_loss: 0.3419 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33298\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8779 - val_loss: 0.3422 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33298\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8782 - val_loss: 0.3421 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33298\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3144 - acc: 0.8781 - val_loss: 0.3425 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33298\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8783 - val_loss: 0.3426 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33298\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8779 - val_loss: 0.3428 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33298\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8779 - val_loss: 0.3433 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33298\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8781 - val_loss: 0.3439 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33298\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8781 - val_loss: 0.3440 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33298\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8783 - val_loss: 0.3445 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33298\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8783 - val_loss: 0.3445 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33298\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8782 - val_loss: 0.3449 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33298\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8784 - val_loss: 0.3456 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33298\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8784 - val_loss: 0.3451 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33298\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8785 - val_loss: 0.3453 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33298\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8783 - val_loss: 0.3454 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33298\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8788 - val_loss: 0.3456 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33298\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8787 - val_loss: 0.3458 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33298\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8788 - val_loss: 0.3463 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33298\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8788 - val_loss: 0.3462 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33298\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8789 - val_loss: 0.3466 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33298\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8789 - val_loss: 0.3467 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33298\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8789 - val_loss: 0.3471 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33298\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8791 - val_loss: 0.3470 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33298\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8792 - val_loss: 0.3471 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33298\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8793 - val_loss: 0.3476 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33298\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8791 - val_loss: 0.3477 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33298\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8793 - val_loss: 0.3478 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33298\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8796 - val_loss: 0.3482 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33298\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8796 - val_loss: 0.3489 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33298\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8797 - val_loss: 0.3486 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33298\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8797 - val_loss: 0.3489 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33298\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8799 - val_loss: 0.3489 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33298\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8800 - val_loss: 0.3489 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33298\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8797 - val_loss: 0.3491 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33298\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8800 - val_loss: 0.3500 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33298\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8800 - val_loss: 0.3499 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33298\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8801 - val_loss: 0.3498 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33298\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8801 - val_loss: 0.3498 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33298\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8801 - val_loss: 0.3505 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33298\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8799 - val_loss: 0.3505 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33298\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8803 - val_loss: 0.3499 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33298\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8802 - val_loss: 0.3500 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33298\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8802 - val_loss: 0.3510 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33298\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8802 - val_loss: 0.3500 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33298\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8802 - val_loss: 0.3509 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33298\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8803 - val_loss: 0.3511 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33298\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8806 - val_loss: 0.3511 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33298\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8807 - val_loss: 0.3513 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33298\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 1024\n",
      "Fold: 1\n",
      "best val loss: 0.33298310250566715\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  90.99193453788757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f68841d30b8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8194 - acc: 0.6808 - val_loss: 0.5828 - val_acc: 0.8097\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58279, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4744 - acc: 0.8490 - val_loss: 0.4253 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58279 to 0.42535, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3885 - acc: 0.8680 - val_loss: 0.3825 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42535 to 0.38247, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3608 - acc: 0.8714 - val_loss: 0.3645 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38247 to 0.36453, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3472 - acc: 0.8725 - val_loss: 0.3553 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36453 to 0.35528, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3393 - acc: 0.8734 - val_loss: 0.3498 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35528 to 0.34982, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3344 - acc: 0.8735 - val_loss: 0.3466 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34982 to 0.34660, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3310 - acc: 0.8738 - val_loss: 0.3444 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34660 to 0.34443, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3287 - acc: 0.8737 - val_loss: 0.3429 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34443 to 0.34294, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3269 - acc: 0.8739 - val_loss: 0.3417 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34294 to 0.34171, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8741 - val_loss: 0.3410 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34171 to 0.34095, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3245 - acc: 0.8740 - val_loss: 0.3403 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34095 to 0.34032, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3235 - acc: 0.8743 - val_loss: 0.3400 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34032 to 0.34002, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8743 - val_loss: 0.3397 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34002 to 0.33967, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8743 - val_loss: 0.3395 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33967 to 0.33947, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8745 - val_loss: 0.3395 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33947\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8746 - val_loss: 0.3395 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33947 to 0.33947, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8746 - val_loss: 0.3397 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33947\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8749 - val_loss: 0.3398 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33947\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8749 - val_loss: 0.3399 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33947\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8750 - val_loss: 0.3399 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33947\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8751 - val_loss: 0.3402 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33947\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8752 - val_loss: 0.3402 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33947\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8753 - val_loss: 0.3406 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33947\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8753 - val_loss: 0.3405 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33947\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8755 - val_loss: 0.3407 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33947\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8758 - val_loss: 0.3410 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33947\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8758 - val_loss: 0.3413 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33947\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8760 - val_loss: 0.3416 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33947\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8759 - val_loss: 0.3419 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33947\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8758 - val_loss: 0.3423 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33947\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8759 - val_loss: 0.3426 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33947\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8760 - val_loss: 0.3430 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33947\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8762 - val_loss: 0.3434 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33947\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8762 - val_loss: 0.3437 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33947\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8764 - val_loss: 0.3441 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33947\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8766 - val_loss: 0.3446 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33947\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8767 - val_loss: 0.3448 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33947\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8766 - val_loss: 0.3452 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33947\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8768 - val_loss: 0.3456 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33947\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8766 - val_loss: 0.3459 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33947\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8768 - val_loss: 0.3462 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33947\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8769 - val_loss: 0.3464 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33947\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8767 - val_loss: 0.3466 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33947\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8768 - val_loss: 0.3468 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33947\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8768 - val_loss: 0.3470 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33947\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8768 - val_loss: 0.3471 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33947\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8769 - val_loss: 0.3473 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33947\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8771 - val_loss: 0.3473 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33947\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8770 - val_loss: 0.3475 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33947\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8771 - val_loss: 0.3476 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33947\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8772 - val_loss: 0.3479 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33947\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8772 - val_loss: 0.3481 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33947\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8772 - val_loss: 0.3482 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33947\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8772 - val_loss: 0.3483 - val_acc: 0.8637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33947\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8772 - val_loss: 0.3486 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33947\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8773 - val_loss: 0.3488 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33947\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8778 - val_loss: 0.3489 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33947\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8780 - val_loss: 0.3493 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33947\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8782 - val_loss: 0.3495 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33947\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8780 - val_loss: 0.3493 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33947\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8781 - val_loss: 0.3497 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33947\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8779 - val_loss: 0.3500 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33947\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8780 - val_loss: 0.3501 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33947\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8780 - val_loss: 0.3500 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33947\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8781 - val_loss: 0.3502 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33947\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8782 - val_loss: 0.3501 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33947\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8780 - val_loss: 0.3506 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33947\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8781 - val_loss: 0.3504 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33947\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8782 - val_loss: 0.3510 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33947\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8782 - val_loss: 0.3508 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33947\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8782 - val_loss: 0.3510 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33947\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8781 - val_loss: 0.3513 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33947\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8783 - val_loss: 0.3513 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33947\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8783 - val_loss: 0.3516 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33947\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8783 - val_loss: 0.3522 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33947\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8782 - val_loss: 0.3519 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33947\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8784 - val_loss: 0.3522 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33947\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8785 - val_loss: 0.3525 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33947\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8783 - val_loss: 0.3530 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33947\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8784 - val_loss: 0.3532 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33947\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8783 - val_loss: 0.3536 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33947\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8787 - val_loss: 0.3542 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33947\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8791 - val_loss: 0.3538 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33947\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8788 - val_loss: 0.3546 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33947\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8788 - val_loss: 0.3541 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33947\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8786 - val_loss: 0.3544 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33947\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8788 - val_loss: 0.3549 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33947\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8790 - val_loss: 0.3551 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33947\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8789 - val_loss: 0.3552 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33947\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8788 - val_loss: 0.3558 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33947\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8786 - val_loss: 0.3554 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33947\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8788 - val_loss: 0.3555 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33947\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8788 - val_loss: 0.3556 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33947\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8789 - val_loss: 0.3558 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33947\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8788 - val_loss: 0.3559 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33947\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8790 - val_loss: 0.3561 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33947\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8790 - val_loss: 0.3567 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33947\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8791 - val_loss: 0.3571 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33947\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8791 - val_loss: 0.3572 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33947\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 1024\n",
      "Fold: 2\n",
      "best val loss: 0.3394669556757163\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3debhddX3v8fd37emMIScjJAGSVoaQARKOSC+iIOoTtII4gdWn4qPmXgsFO9zb2NsHKdWn9tZS1EvtRYu1vUrKjRVibygVDQ/tVTBBETMwRKachCEJJDnJmfbwvX/81h7OyUlyEvY5O2ufz+t59rP3XmvttX/rrOTz+63f+u21zN0REZHkixpdABERqQ8FuohIk1Cgi4g0CQW6iEiTUKCLiDSJdKO+eMaMGT5//vxGfb2ISCI9+uiju9195mjzGhbo8+fPZ+PGjY36ehGRRDKz5w83T10uIiJNQoEuItIkFOgiIk2iYX3oItJc8vk8PT09DAwMNLooTaGlpYV58+aRyWTG/BkFuojURU9PD52dncyfPx8za3RxEs3d2bNnDz09PSxYsGDMn1OXi4jUxcDAANOnT1eY14GZMX369GM+2lGgi0jdKMzr53j+lokL9A3Pvcpf/duT5IulRhdFROSEkrhA//kLr/HVH21jsKBAF5GqvXv38jd/8zfH/Ll3vetd7N27dxxKNPESF+iZVChyQS10EalxuEAvFApH/Ny6deuYOnXqeBVrQiVulEs50IcU6CJSY9WqVfzqV7/ivPPOI5PJ0NLSQldXF0888QRPPfUU733ve9m+fTsDAwPceOONrFy5EqhehuTAgQNcfvnlvPnNb+bHP/4xc+fO5d5776W1tbXBWzZ2iQv0bBzo+aJunSdyovrT729my879dV3nOXOm8Ln3LDrs/C9+8Yts2rSJxx57jAcffJB3v/vdbNq0qTLs784772TatGn09/fzxje+kfe///1Mnz592Dqefvpp7rrrLr7+9a/zoQ99iO9+97t89KMfret2jKfEBXomHc785tWHLiJHcMEFFwwbw/2Vr3yF733vewBs376dp59++pBAX7BgAeeddx4A559/Ps8999yElbcexhToZrYC+DKQAr7h7l8cMf804FvA1HiZVe6+rs5lBapdLhrlInLiOlJLeqK0t7dXXj/44IM88MAD/OQnP6GtrY1LLrlk1DHeuVyu8jqVStHf3z8hZa2Xo54UNbMUcDtwOXAO8GEzO2fEYn8C3O3uy4BrgGM/1TxG6Uh96CJyqM7OTnp7e0edt2/fPrq6umhra+OJJ57g4YcfnuDSTYyxtNAvALa5+zMAZrYauBLYUrOMA1Pi1ycBO+tZyFrZcpeL+tBFpMb06dO56KKLWLx4Ma2trcyePbsyb8WKFfzt3/4tCxcu5KyzzuLCCy9sYEnHz1gCfS6wveZ9D/CmEcvcDPybmf0u0A68fbQVmdlKYCXAaaeddqxlBTRsUUQO7zvf+c6o03O5HPfdd9+o88r95DNmzGDTpk2V6X/4h39Y9/KNt3qNQ/8w8PfuPg94F/CPZnbIut39DnfvdvfumTNHvYPSUWnYoojI6MYS6DuAU2vez4un1foEcDeAu/8EaAFm1KOAI2U0bFFEZFRjCfQNwBlmtsDMsoSTnmtHLPMCcBmAmS0kBPqueha0rDIOXcMWRUSGOWqgu3sBuB64H9hKGM2y2cxuMbMr4sX+APiUmf0CuAu41t3HpQldGYeuLhcRkWHGNA49HlO+bsS0m2pebwEuqm/RRqdhiyIio0vcxbn0038RkdElLtDV5SIi9dDR0QHAzp07+cAHPjDqMpdccgkbN2484npuu+02+vr6Ku8beTne5AW6xqGLSB3NmTOHNWvWHPfnRwZ6Iy/Hm9hAH1KXi4jUWLVqFbfffnvl/c0338znP/95LrvsMpYvX86SJUu49957D/ncc889x+LFiwHo7+/nmmuuYeHChVx11VXDruXy6U9/mu7ubhYtWsTnPvc5IFzwa+fOnVx66aVceumlQLgc7+7duwG49dZbWbx4MYsXL+a2226rfN/ChQv51Kc+xaJFi3jnO99Zt2vGJO5qi1ldnEvkxHffKnjpl/Vd58lL4PIvHnb21VdfzWc+8xmuu+46AO6++27uv/9+brjhBqZMmcLu3bu58MILueKKKw57v86vfe1rtLW1sXXrVh5//HGWL19emfeFL3yBadOmUSwWueyyy3j88ce54YYbuPXWW1m/fj0zZgz/6c2jjz7KN7/5TR555BHcnTe96U289a1vpaura9wu05vAFrounysih1q2bBmvvPIKO3fu5Be/+AVdXV2cfPLJ/PEf/zFLly7l7W9/Ozt27ODll18+7DoeeuihSrAuXbqUpUuXVubdfffdLF++nGXLlrF582a2bNlyuNUA8B//8R9cddVVtLe309HRwfve9z7+/d//HRi/y/QmroWeinRSVOSEd4SW9Hj64Ac/yJo1a3jppZe4+uqr+fa3v82uXbt49NFHyWQyzJ8/f9TL5h7Ns88+y5e+9CU2bNhAV1cX11577XGtp2y8LtObuBa6mZFNRepDF5FDXH311axevZo1a9bwwQ9+kH379jFr1iwymQzr16/n+eefP+Ln3/KWt1Qu8LVp0yYef/xxAPbv3097ezsnnXQSL7/88rALfR3usr0XX3wx99xzD319fRw8eJDvfe97XHzxxXXc2kMlroUOodtFLXQRGWnRokX09vYyd+5cTjnlFD7ykY/wnve8hyVLltDd3c3ZZ599xM9/+tOf5uMf/zgLFy5k4cKFnH/++QCce+65LFu2jLPPPptTTz2Viy6q/o5y5cqVrFixgjlz5rB+/frK9OXLl3PttddywQUXAPDJT36SZcuWjetdkGycfqF/VN3d3X608Z2Hc94t/8aV587hT69cXOdSicjx2rp1KwsXLmx0MZrKaH9TM3vU3btHWz5xXS4Qhi6qy0VEZLhEBno2FanLRURkhEQGuvrQRU5MjerCbUbH87dMZKCn1UIXOeG0tLSwZ88ehXoduDt79uyhpaXlmD6X0FEuEUMF/aMROZHMmzePnp4edu0al3vbTDotLS3MmzfvmD6TyEDPqstF5ISTyWRYsGBBo4sxqSWyyyWTiiiUFOgiIrUSG+h5dbmIiAyTzEBPR7oFnYjICIkMdPWhi4gcKpGBntGwRRGRQyQy0MM4dPWhi4jUSmSgZ1LGkG5wISIyTCIDXddyERE5VCIDPYxDV5eLiEitxAa67ikqIjJcMgM9bRqHLiIyQiIDXX3oIiKHSmSgp6OIkkNR/egiIhWJDPRM2gDUShcRqTGmQDezFWb2pJltM7NVo8z/azN7LH48ZWZ761/UqmwqFFv96CIiVUe9HrqZpYDbgXcAPcAGM1vr7lvKy7j779Us/7vAsnEoa0UmDvSCfi0qIlIxlhb6BcA2d3/G3YeA1cCVR1j+w8Bd9Sjc4ZQDXV0uIiJVYwn0ucD2mvc98bRDmNnpwALgR4eZv9LMNprZxtdzm6pMKvSh6+f/IiJV9T4peg2wxt2Lo8109zvcvdvdu2fOnHncX5JNq4UuIjLSWAJ9B3Bqzft58bTRXMM4d7dAGLYI6IqLIiI1xhLoG4AzzGyBmWUJob125EJmdjbQBfykvkU8VLnLRS10EZGqowa6uxeA64H7ga3A3e6+2cxuMbMraha9Bljt7uPebM6kNWxRRGSkow5bBHD3dcC6EdNuGvH+5voV68jK49B1gS4Rkapk/lK0PA5dP/0XEalIaKDHwxbV5SIiUpHQQFeXi4jISMkOdA1bFBGpSGiga9iiiMhICQ10DVsUERkpkYGun/6LiBwqkYGuy+eKiBwqoYGuPnQRkZESGujqQxcRGSnRgZ4vqMtFRKQskYGeiozI1OUiIlIrkYEOoZWuQBcRqUpsoGdTkfrQRURqJDbQM+lIwxZFRGokN9BTpi4XEZEaCQ50dbmIiNRKbKBnU5GutigiUiOxgZ5Oma6HLiJSI7GBrmGLIiLDJTrQ1YcuIlKV2EDPqoUuIjJMYgM9kzaNQxcRqZHcQFcLXURkmEQH+pBa6CIiFQkOdP1SVESkVoIDXV0uIiK1kh3o+mGRiEhFogNdfegiIlVjCnQzW2FmT5rZNjNbdZhlPmRmW8xss5l9p77FPFQ2ZRRKaqGLiJSlj7aAmaWA24F3AD3ABjNb6+5bapY5A/gscJG7v2Zms8arwGXqchERGW4sLfQLgG3u/oy7DwGrgStHLPMp4HZ3fw3A3V+pbzEPlUnraosiIrXGEuhzge0173viabXOBM40s/9nZg+b2Yp6FfBwMpExVCzhrlAXEYExdLkcw3rOAC4B5gEPmdkSd99bu5CZrQRWApx22mmv6wszqVAXFUpOJmWva10iIs1gLC30HcCpNe/nxdNq9QBr3T3v7s8CTxECfhh3v8Pdu929e+bMmcdbZiB0uQAaiy4iEhtLoG8AzjCzBWaWBa4B1o5Y5h5C6xwzm0HognmmjuU8RLmFni+oy0VEBMYQ6O5eAK4H7ge2Ane7+2Yzu8XMrogXux/YY2ZbgPXAf3X3PeNVaAjDFgHyGrooIgKMsQ/d3dcB60ZMu6nmtQO/Hz8mRKWFri4XEREgib8UfeFh+NHnyUShq0VdLiIiQfICvWcDPPSXtDIIoNvQiYjEkhfo2Q4AWkp9gLpcRETKkhfouU5AgS4iMlLyAr3cQvd+QIEuIlKWvEDPhUDPFg8CMKSToiIiQBIDfUQfui6hKyISJDbQM0V1uYiI1EpeoFe6XEILXV0uIiJB8gI9bqGnC6EPXS10EZEggYHeDhiZogJdRKRW8gLdDLIdpAsahy4iUit5gQ6Q6yCVPwDAkG5DJyICJDXQsx2k8qHLpaAWuogIkNhAbydSl4uIyDDJDPRcJ9FQ6HLJq8tFRARIaqBnO7ByH3pBLXQREUhqoOc6sMEDpCNTl4uISCyZgZ7tgKEDZFKRAl1EJJbMQM91wOABMilTH7qISCyZgZ7tgEI/rSlXC11EJJbcQAc6U0MKdBGRWDIDPb7i4knRoLpcRERiyQz0cgs9GmBILXQRESCpgR7fKHpKNEhe49BFRICkBnpNC1196CIiQTIDPe5D77R+9aGLiMSSGehxC70D9aGLiJQlO9CjQV0+V0QklsxAj7tc2hhQl4uISGxMgW5mK8zsSTPbZmarRpl/rZntMrPH4scn61/UGpk2sIh2+nVSVEQklj7aAmaWAm4H3gH0ABvMbK27bxmx6D+5+/XjUMbRCgXZDlq9X33oIiKxsbTQLwC2ufsz7j4ErAauHN9ijUG2gzZXC11EpGwsgT4X2F7zvieeNtL7zexxM1tjZqeOtiIzW2lmG81s465du46juDWy7bR6P/mC+tBFRKB+J0W/D8x396XAD4BvjbaQu9/h7t3u3j1z5szX9425Dlq9Ty10EZHYWAJ9B1Db4p4XT6tw9z3uPhi//QZwfn2KdwTZDnIl/VJURKRsLIG+ATjDzBaYWRa4Blhbu4CZnVLz9gpga/2KeBi5Tlq8T8MWRURiRx3l4u4FM7seuB9IAXe6+2YzuwXY6O5rgRvM7AqgALwKXDuOZQ6yHeSK6nIRESk7aqADuPs6YN2IaTfVvP4s8Nn6Fu0och1kS30USk6p5ESRTejXi4icaJL5S1GAbAfZYh8A+ZJa6SIiiQ70dGmQFEX1o4uIkORAj6/n0s6AbnIhIkKSAz1bE+g6MSoikuBAL7fQrZ/+fLHBhRERabzkBno23Fe0gwF2HxhqcGFERBovuYFe00LffWDwKAuLiDS/5AZ6th0ILfRdvQp0EZEEB3r5pKha6CIikORAz4U+9Bm5glroIiIkOdDjFvqsXF4tdBERkhzomVawiBmZIbXQRURIcqCbQbaTrvSQhi2KiJDkQAfIdXBSFEa5uOt6LiIyuSU70LPtdEaD9OeLHBzSr0VFZHJLeKB30E4/ALvVjy4ik1yyAz3XQSsDAOzSSBcRmeSSHejZTnLxTS7UQheRyS7ZgZ7rIFM8CKiFLiKS7EDPdhDlDxKZWugiIgkP9HZs8ADT2nNqoYvIpJfsQM91QnGQ2e2Rfi0qIpNesgM9vp7Lqe1FdunXoiIyySU70FunAnB6y4D60EVk0kt2oM88C4Azo+3sOqCf/4vI5JbsQJ91DljEguKzDBVK7B8oNLpEIiINk+xAz7TC9DdwSv82AF0XXUQmtWQHOsDsxXT1PgmgkS4iMqklP9BPXkzLwR1M4aACXUQmtSYI9KUAnG0vqMtFRCa1MQW6ma0wsyfNbJuZrTrCcu83Mzez7voV8ShmLwZgUeoFtdBFZFI7aqCbWQq4HbgcOAf4sJmdM8pyncCNwCP1LuQRdZ4MbdM5L9ujFrqITGpjaaFfAGxz92fcfQhYDVw5ynJ/BvwFxBconyhmMHsx59jzaqGLyKQ2lkCfC2yved8TT6sws+XAqe7+f4+0IjNbaWYbzWzjrl27jrmwh3XyEuYXn+fV3v76rVNEJGFe90lRM4uAW4E/ONqy7n6Hu3e7e/fMmTNf71dXnbyEDHlae5+t3zpFRBJmLIG+Azi15v28eFpZJ7AYeNDMngMuBNY24sToyf1PUyrp5/8iMjmNJdA3AGeY2QIzywLXAGvLM919n7vPcPf57j4feBi4wt03jkuJRzPjTIqW5myeZ19/fsK+VkTkRHLUQHf3AnA9cD+wFbjb3Teb2S1mdsV4F3BM0lkOTHkDC+15Xto/sedkRUROFOmxLOTu64B1I6bddJhlL3n9xTp2qZOXsHDvD7jv2VdZeMqURhRBRKShkv9L0VjH/GXMsr38bMuTjS6KiEhDNE2gc9pvADDjhXUM5IsNLoyIyMRrnkCfu5x908/lo9zHI8/sbnRpREQmXPMEOtB68fUsiF5m50/vaXRRREQmXFMFenbJVexJzeTs5/6x0UUREZlwTRXopDI882u/xbLiL3nxiZ82ujQiIhOquQIdmPXW/0yf5zj40FcbXRQRkQnVdIF++ry5/GvmMk7feR/s23H0D4iINImmC3SAF878GEMeUVr9ERg62OjiiIhMiKYM9HPPXc4N+euxFx+Df14JpVKjiyQiMu7G9NP/pHnLGTP5y9mX8uX9r/KZJ74JD9wE7/x8o4slIicCdygVYLAX+l6Fvj3gJch1QLYD0i1AfNVWL4VlS8XwXBiAwiAUh+J5RfAiFIbCvHw/9L8G/a+GdQ8dCL0EQwegWAjLlopw0Y1wTv0vhdWUgZ6KjJuvWMSH/tc+Lpnfy3k//irkB+Adt0C2rdHFE5nc3CHfF4Jv8EAIwuJQCMN8XwjAwd4QtH17YHA/pFsh2w6pbJh24OUQmNk2aDkJcp1QzMef74OBfTCwNzwXBqqBXMxDaQKuyGopaO0K5cp1QKYdUhmwDEQpSOfG5WubMtABLlgwjfecO5ff2nwVj3R30bnh6/DMerjqDph3fqOLJ3L83EPrEIMoqk4rFUIoejEESpQOr/v3hvDM94dQSefAonj6qyE8o3SYF2VCuBbLLc4BKPSHVmmpGL7XS1AcjAN4oBqc/XvDvExLCGA8LFMYGL6uoYNh/WOR7YDclPhzfeF7W6dBx2xomxZC/dVnQ+inspBpq4b8jDOhZUooSyoTtjmVCctFmRC0rdPCeiwKrejBA+E7sHB7Syz8baJ0HMQt4ZGKg9lS1YBO5cK2t3aFMpuNz/4/AnNvzA0huru7fePG8b1k+s69/bztrx7k0rNm8bX/dADu+R3ofREWvx/e+Ak49U0N+aPLCaocipXWXM1hdGGw5nB7MD7cjsPN46CrtBAPhs8Uh6otwvI6S0UY6g0hOtgbz4/nRWlIx2FTGAghOdgb1lkOw2KeSndAmaXCNJ+gc0UWxeHVGh65KSHEWqeGeeUQx+Jwjx/loM+2xcvHLdh0a9ju8rxMe2iNt00Pn6lVKlUrsUnKzB5191FvINS0LXSAOVNbue6SN/BXP3iK7y9Zxnt+58ew/s/hsW/DL++GWYtg0VXw62+DOeeFmlYmTqk0vI+x8vpgTYj2xy3B/uqheWEohGql1TdQDc5iPixTObwuB2lh+HwvhQDHwzKFwfE7FC+34sotvWxH9VA8lYtbeNlQjnw/FPeFcOs8JbQys+0hONMtoXVpUXiUy14qhIZJujUEoKWqfbUWhaBtmRrCspgP2+qlML3cmiwV479bPnxH+bvK35tuiVukDW4ATfIwP5qmbqEDDOSLfOQbj/DY9r38zw8v4/Ilp4TDqk3fhZ/9A+yIy9DaBfPeCCcvgZOXwqxzYNqCcGglIUSHDoTW4mA5eHvD68Heahjn+yEfh/JgHNKDveGQeLA3HDaXW7qF47ipdyobPzLVAEvlQiCWD6VTmZouhJrD5fLnokxN5W3VlnF5frm7IpWtaWHm4pZkLv6eVDVYy48oHcI32xGCMJWNv1shJPVzpBZ60wc6wIHBAh+786fDQ73s4G545kH41XrY+XPY9URo3UD4z9g1H6aeHvrsOmdD+0xomwHt06GlKz7sbIn77trD8/G29Eul0EIqtx69ROVQunxIXw7DUqHawiwMhKAcOhg+Xw4YL1XPyJc/V27p5vuqJ6HKrdzyevJ91a6DclCXCmPfjvIJrPKogVxnaAW2TAl/n0xrNSDLy2Q74tfx3zDdUm0dlg/t0y2NbyGKNNikD3QYHuqrVpzNxy+aTzo1SsspPxBCfdeTsPsp2P1k+MXpgZfDYyzBlsrFLbm4hege97N63JJLARbCtzBUPQk1sm90PNX2gWZaq63dTFv8aIFsZ9ziLFdW5ddxSFdCuPy+PaxHLVKRcaNAjx0YLPCZ1T/nga2vsHjuFP78qqUsmXfS2FdQKoUz+n2vQt/ucNKq3L87rFV7sHpSrVjTYjartra9NLz7oHJ4nh6+fKW/1OITRy3VftfyWfh0SzV4owzVE2RW7SIot4gzNf2hIpI4CvQa7s66X77Ezd/fzJ4Dg/zm0jn89m+czvmnd2E6nBeRE9ykHeUyGjPj3UtP4eIzZ/DVHz7N6g3bWfuLnZxzyhTet3wuly2czYIZ7Y0upojIMZt0LfSR+oYK3PPznfzvh59ny4v7Afj1me28+Q0zWH56F8tP62JeV6ta7yJyQlCXyxhtf7WPB7a+zI+eeIWNz71Gf3yz6altGc6c3clZszt5w6wOTpvexunT2pjX1UY2rROAIjJxFOjHoVAs8eTLvfzshb1s2bmfp17u5amXeukdrI5yMYPZnS3M7WplztRWZnXmmNWZY0ZHjmntWbras3S1ZZjalqUzlyaK1MoXkddHfejHIZ2KWDTnJBbNqY6CcXd2HRjkhT19PLenj+2v9rFjbz89r/XxeM9eXtk/WGnVjxQZTGnN0NmSpj2bprMlzZSW8L6zJUN7Lk17NkVbLk1rJkVrNqIlnSKXicilU+TSES2ZFK3ZFK2ZFNl0FB6piFw6UpeQiCjQj4WZMauzhVmdLXTPn3bIfHfnwGCB3QeGeK1viNcODvFaX569fUPs68+zty/PwcECvYMFegfyvLR/gKdfKbB/IE/fUJGhwvFfiyObDsGeTUWkIiMdGZl0qBRa4kohm47IpIxMKiITL5tJWfzZ8vyIbDwtk6pWGplURLr82ZSRjsL7lBmpyIgiq1Qu2XQoQyoK8zOpiNZsShWPyDhToNeRmdHZkqGzJcMCjn2kTL5Yom+wyEChSP9QeB7MlxgslBgsFBnIl+gbKtA/VGSoWGKoEOaVnwfyRQqlEsWSUyg6Q8UwbSAfnvvzRfYPhOXzxRL5ojNUKFXWVX49njIpwywE/cgKwuIL3EVmGOHvGRnhCCUTKotcTQWViozIjFREXPFUK61yhVOeH1mo5NLx96WiiHRc6ZQruXJFFFn5AVFUfV1bSVnNtHQqIhM/lyvTVGRheyg/U6nMIkMVm4wLBfoJJJOKOKkt4iQad/0Ydw9BXyyRrwn7fLFEoRQqgELJKcQVQsmdYik88sVqBVMsOUWvTi9XKvliiaI7pVL4nkKpRKEYXjseLnjo4dmBUskrFdpgvsTeviEG8uF9WA/DvnuwUCRfbMx5oWNVG/RGqHSiiMpRT7mCiOJKLhqlEqg9SgqVU3wkFUVk0uEz+WL4G5fcSUdxpZMKR1TlSqzkoRFQLDkWV36plJFLRZVuv0qFVlNpZVLRsKsxGKECLVeY6VR52aiyHWZhH5dK4blWVHPEV7vd1XVVv8+ATOWoMgxO8PjX1pX1mMUVeChruUJOpWoq7XiF5aKYQTYVJfKclwJdhjEzsunQ5cL4XIN/QpRD3p1KxVIsV0SlUKHUVkz5Yqi8iiWvVCgjX9euxwmVXyGulPLFsK6iQ7EUKj33sEy5coL4KhA4pWHzyhUZwyrIYimsu1QKyxRLwy9lU/LqdhRrnsPRV4nBfKg8M1EI7sisss7+fHW5QtGHhXXJidcb/iaDcWU88m9QSka9edwqR3pxBVM9egv7oXwU7A4tmXCOK5eO4n8bDPv3Viz5sArqjy4/i6uWzat7mRXo0pRCOOnyBuOpVHLypRK1jexKBVo++ipXNPERWLnSSsXBNvKgo1yhVSrS2so47kqsXbZcKVXPP5Vb2z6iIg9lra0Aa7/D4s+ZVRsD5SPTYnwkUSiVKpWdO2TS8REKxmAhdGkO5kuVbsPIqOnis0olXiw5J09pHZd9MqZAN7MVwJeBFPANd//iiPn/BbgOKAIHgJXuvqXOZRWRE0gUGTlVmieUo/4qxsxSwO3A5cA5wIfN7JwRi33H3Ze4+3nA/wBurXtJRUTkiMbyM8cLgG3u/oy7DwGrgStrF3D3/TVv25nQ68CKiAiMrctlLrC95n0P8KaRC5nZdcDvA1ngbaOtyMxWAisBTjvttGMtq4iIHEHdLkTi7re7+68DfwT8yWGWucPdu929e+bMmfX6ahERYWyBvgM4teb9vHja4awG3vt6CiUiIsduLIG+ATjDzBaYWRa4Blhbu4CZnVHz9t3A0/UrooiIjMVR+9DdvWBm1wP3E4Yt3unum83sFmCju68FrjeztwN54DXgY+NZaBEROdSYxqG7+zpg3YhpN9W8vrHO5RIRkWPUsOuhm9ku4Pnj/PgMYD2YBkEAAAPHSURBVHcdi5MUk3G7J+M2w+Tc7sm4zXDs2326u486qqRhgf56mNnGw13gvZlNxu2ejNsMk3O7J+M2Q323W/dPExFpEgp0EZEmkdRAv6PRBWiQybjdk3GbYXJu92TcZqjjdieyD11ERA6V1Ba6iIiMoEAXEWkSiQt0M1thZk+a2TYzW9Xo8owHMzvVzNab2RYz22xmN8bTp5nZD8zs6fi5q9FlrTczS5nZz83sX+L3C8zskXh//1N8+YmmYmZTzWyNmT1hZlvN7Dcmyb7+vfjf9yYzu8vMWpptf5vZnWb2ipltqpk26r614Cvxtj9uZsuP9fsSFehjvNlGMygAf+Du5wAXAtfF27kK+KG7nwH8MH7fbG4Etta8/wvgr939DYTLSnyiIaUaX18G/tXdzwbOJWx/U+9rM5sL3AB0u/tiwmVFrqH59vffAytGTDvcvr0cOCN+rAS+dqxflqhAZww322gG7v6iu/8sft1L+A8+l7Ct34oX+xZNdlVLM5tHuLjbN+L3Rri2/pp4kWbc5pOAtwB/B+DuQ+6+lybf17E00GpmaaANeJEm29/u/hDw6ojJh9u3VwL/4MHDwFQzO+VYvi9pgT7azTbmNqgsE8LM5gPLgEeA2e7+YjzrJWB2g4o1Xm4D/htQvuPvdGCvuxfi9824vxcAu4Bvxl1N3zCzdpp8X7v7DuBLwAuEIN8HPErz7284/L593fmWtECfVMysA/gu8JkRt/nDw3jTphlzama/Cbzi7o82uiwTLA0sB77m7suAg4zoXmm2fQ0Q9xtfSajQ5hBuXTmya6Lp1XvfJi3Qj/VmG4llZhlCmH/b3f85nvxy+RAsfn6lUeUbBxcBV5jZc4SutLcR+panxofk0Jz7uwfocfdH4vdrCAHfzPsa4O3As+6+y93zwD8T/g00+/6Gw+/b151vSQv0o95soxnEfcd/B2x191trZq2leq35jwH3TnTZxou7f9bd57n7fMJ+/ZG7fwRYD3wgXqypthnA3V8CtpvZWfGky4AtNPG+jr0AXGhmbfG/9/J2N/X+jh1u364Ffjse7XIhsK+ma2Zs3D1RD+BdwFPAr4D/3ujyjNM2vplwGPY48Fj8eBehT/mHhDtCPQBMa3RZx2n7LwH+JX79a8BPgW3A/wFyjS7fOGzvecDGeH/fA3RNhn0N/CnwBLAJ+Ecg12z7G7iLcI4gTzga+8Th9i1ghFF8vwJ+SRgBdEzfp5/+i4g0iaR1uYiIyGEo0EVEmoQCXUSkSSjQRUSahAJdRKRJKNBFRJqEAl1EpEn8fyHBVrN+T7mFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  91.96296525001526\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8216 - acc: 0.6792 - val_loss: 0.5808 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58084, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4762 - acc: 0.8469 - val_loss: 0.4143 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58084 to 0.41434, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3887 - acc: 0.8674 - val_loss: 0.3740 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41434 to 0.37399, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3614 - acc: 0.8703 - val_loss: 0.3572 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37399 to 0.35717, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3481 - acc: 0.8711 - val_loss: 0.3480 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35717 to 0.34799, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3404 - acc: 0.8721 - val_loss: 0.3427 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34799 to 0.34267, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3357 - acc: 0.8721 - val_loss: 0.3392 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34267 to 0.33920, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3324 - acc: 0.8722 - val_loss: 0.3368 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33920 to 0.33677, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3300 - acc: 0.8724 - val_loss: 0.3355 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33677 to 0.33547, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3283 - acc: 0.8727 - val_loss: 0.3342 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33547 to 0.33422, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8728 - val_loss: 0.3333 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33422 to 0.33327, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3256 - acc: 0.8730 - val_loss: 0.3328 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33327 to 0.33280, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3246 - acc: 0.8731 - val_loss: 0.3324 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33280 to 0.33244, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8729 - val_loss: 0.3323 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33244 to 0.33235, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8730 - val_loss: 0.3322 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33235 to 0.33224, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3225 - acc: 0.8731 - val_loss: 0.3323 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33224\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8731 - val_loss: 0.3322 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33224 to 0.33222, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8734 - val_loss: 0.3326 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33222\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8734 - val_loss: 0.3328 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33222\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8737 - val_loss: 0.3328 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33222\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8738 - val_loss: 0.3331 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33222\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8739 - val_loss: 0.3333 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33222\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8740 - val_loss: 0.3334 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33222\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8741 - val_loss: 0.3335 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33222\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8741 - val_loss: 0.3336 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33222\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8741 - val_loss: 0.3337 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33222\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8743 - val_loss: 0.3340 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33222\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8744 - val_loss: 0.3339 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33222\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8744 - val_loss: 0.3340 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33222\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8746 - val_loss: 0.3341 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33222\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8747 - val_loss: 0.3344 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33222\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8748 - val_loss: 0.3344 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33222\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8749 - val_loss: 0.3349 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33222\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8750 - val_loss: 0.3351 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33222\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8749 - val_loss: 0.3351 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33222\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8752 - val_loss: 0.3355 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33222\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8753 - val_loss: 0.3352 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33222\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8756 - val_loss: 0.3356 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33222\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8755 - val_loss: 0.3357 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33222\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8755 - val_loss: 0.3362 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33222\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8754 - val_loss: 0.3367 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33222\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8756 - val_loss: 0.3366 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33222\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8757 - val_loss: 0.3367 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33222\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8761 - val_loss: 0.3372 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33222\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8762 - val_loss: 0.3374 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33222\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8761 - val_loss: 0.3374 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33222\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8763 - val_loss: 0.3379 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33222\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8761 - val_loss: 0.3378 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33222\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8762 - val_loss: 0.3383 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33222\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8763 - val_loss: 0.3382 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33222\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8764 - val_loss: 0.3387 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33222\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8764 - val_loss: 0.3391 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33222\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8765 - val_loss: 0.3395 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33222\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8763 - val_loss: 0.3400 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33222\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8766 - val_loss: 0.3400 - val_acc: 0.8678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33222\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8765 - val_loss: 0.3400 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33222\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8768 - val_loss: 0.3403 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33222\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8770 - val_loss: 0.3405 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33222\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8769 - val_loss: 0.3409 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33222\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8771 - val_loss: 0.3409 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33222\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8773 - val_loss: 0.3410 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33222\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8773 - val_loss: 0.3418 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33222\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8773 - val_loss: 0.3413 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33222\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8774 - val_loss: 0.3412 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33222\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8775 - val_loss: 0.3416 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33222\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8777 - val_loss: 0.3417 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33222\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8778 - val_loss: 0.3419 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33222\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8777 - val_loss: 0.3421 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33222\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8778 - val_loss: 0.3423 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33222\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8777 - val_loss: 0.3427 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33222\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8776 - val_loss: 0.3424 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33222\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8777 - val_loss: 0.3427 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33222\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8778 - val_loss: 0.3427 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33222\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8779 - val_loss: 0.3431 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33222\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8781 - val_loss: 0.3432 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33222\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8783 - val_loss: 0.3438 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33222\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8782 - val_loss: 0.3443 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33222\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8781 - val_loss: 0.3445 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33222\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8783 - val_loss: 0.3446 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33222\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8783 - val_loss: 0.3454 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33222\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8783 - val_loss: 0.3455 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33222\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8785 - val_loss: 0.3458 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33222\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8784 - val_loss: 0.3464 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33222\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8785 - val_loss: 0.3459 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33222\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8786 - val_loss: 0.3467 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33222\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8787 - val_loss: 0.3461 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33222\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8786 - val_loss: 0.3463 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33222\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8789 - val_loss: 0.3460 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33222\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8791 - val_loss: 0.3465 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33222\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8792 - val_loss: 0.3465 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33222\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8790 - val_loss: 0.3468 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33222\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8791 - val_loss: 0.3465 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33222\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8793 - val_loss: 0.3471 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33222\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8790 - val_loss: 0.3467 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33222\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8787 - val_loss: 0.3474 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33222\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8792 - val_loss: 0.3473 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33222\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8791 - val_loss: 0.3483 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33222\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8791 - val_loss: 0.3486 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33222\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8789 - val_loss: 0.3483 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33222\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8790 - val_loss: 0.3491 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33222\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 1024\n",
      "Fold: 3\n",
      "best val loss: 0.33222298836847497\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  91.5160973072052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f684c5c8470>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.8208 - acc: 0.6792 - val_loss: 0.5771 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57710, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4733 - acc: 0.8484 - val_loss: 0.4225 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57710 to 0.42254, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3877 - acc: 0.8681 - val_loss: 0.3823 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42254 to 0.38226, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3602 - acc: 0.8711 - val_loss: 0.3644 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38226 to 0.36439, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3469 - acc: 0.8724 - val_loss: 0.3550 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36439 to 0.35504, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3392 - acc: 0.8729 - val_loss: 0.3493 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35504 to 0.34927, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3343 - acc: 0.8731 - val_loss: 0.3457 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34927 to 0.34573, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3313 - acc: 0.8733 - val_loss: 0.3432 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34573 to 0.34323, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3290 - acc: 0.8732 - val_loss: 0.3417 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34323 to 0.34168, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3273 - acc: 0.8736 - val_loss: 0.3406 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34168 to 0.34056, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3260 - acc: 0.8737 - val_loss: 0.3398 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34056 to 0.33979, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3250 - acc: 0.8739 - val_loss: 0.3391 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33979 to 0.33908, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8740 - val_loss: 0.3388 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33908 to 0.33880, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8741 - val_loss: 0.3384 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33880 to 0.33842, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8742 - val_loss: 0.3384 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33842 to 0.33838, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8743 - val_loss: 0.3382 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33838 to 0.33815, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8743 - val_loss: 0.3380 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33815 to 0.33805, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8743 - val_loss: 0.3381 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33805\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8744 - val_loss: 0.3381 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33805\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8748 - val_loss: 0.3382 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33805\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8750 - val_loss: 0.3382 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33805\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8751 - val_loss: 0.3385 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33805\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8752 - val_loss: 0.3385 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33805\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8752 - val_loss: 0.3384 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33805\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8753 - val_loss: 0.3386 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33805\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8754 - val_loss: 0.3385 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33805\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8755 - val_loss: 0.3387 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33805\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8756 - val_loss: 0.3388 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33805\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8756 - val_loss: 0.3389 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33805\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8756 - val_loss: 0.3391 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33805\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8756 - val_loss: 0.3395 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33805\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8757 - val_loss: 0.3397 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33805\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8757 - val_loss: 0.3401 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33805\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8759 - val_loss: 0.3402 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33805\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8759 - val_loss: 0.3406 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33805\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8760 - val_loss: 0.3410 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33805\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8762 - val_loss: 0.3412 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33805\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8764 - val_loss: 0.3414 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33805\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8765 - val_loss: 0.3417 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33805\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8766 - val_loss: 0.3421 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33805\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8767 - val_loss: 0.3422 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33805\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8767 - val_loss: 0.3424 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33805\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8768 - val_loss: 0.3428 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33805\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8769 - val_loss: 0.3429 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33805\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8769 - val_loss: 0.3433 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33805\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8770 - val_loss: 0.3434 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33805\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8771 - val_loss: 0.3440 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33805\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8771 - val_loss: 0.3441 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33805\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8773 - val_loss: 0.3444 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33805\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8776 - val_loss: 0.3447 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33805\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8776 - val_loss: 0.3449 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33805\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8777 - val_loss: 0.3455 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33805\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8777 - val_loss: 0.3455 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33805\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8776 - val_loss: 0.3461 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33805\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3145 - acc: 0.8776 - val_loss: 0.3464 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33805\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8776 - val_loss: 0.3469 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33805\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8776 - val_loss: 0.3468 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33805\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8777 - val_loss: 0.3474 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33805\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8778 - val_loss: 0.3477 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33805\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8778 - val_loss: 0.3477 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33805\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8780 - val_loss: 0.3478 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33805\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8779 - val_loss: 0.3483 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33805\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8778 - val_loss: 0.3488 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33805\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8778 - val_loss: 0.3489 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33805\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8779 - val_loss: 0.3499 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33805\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8781 - val_loss: 0.3496 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33805\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8781 - val_loss: 0.3504 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33805\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8783 - val_loss: 0.3506 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33805\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8782 - val_loss: 0.3505 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33805\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8785 - val_loss: 0.3508 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33805\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8786 - val_loss: 0.3516 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33805\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8786 - val_loss: 0.3514 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33805\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8785 - val_loss: 0.3521 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33805\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8785 - val_loss: 0.3517 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33805\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8787 - val_loss: 0.3519 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33805\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8786 - val_loss: 0.3527 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33805\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8787 - val_loss: 0.3530 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33805\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8788 - val_loss: 0.3532 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33805\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8786 - val_loss: 0.3539 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33805\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8788 - val_loss: 0.3539 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33805\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8787 - val_loss: 0.3543 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33805\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8788 - val_loss: 0.3541 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33805\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8789 - val_loss: 0.3548 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33805\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8790 - val_loss: 0.3550 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33805\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8791 - val_loss: 0.3553 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33805\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8794 - val_loss: 0.3552 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33805\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8793 - val_loss: 0.3554 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33805\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8795 - val_loss: 0.3553 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33805\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8797 - val_loss: 0.3561 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33805\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8798 - val_loss: 0.3559 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33805\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8797 - val_loss: 0.3562 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33805\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8800 - val_loss: 0.3563 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33805\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8800 - val_loss: 0.3568 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33805\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8802 - val_loss: 0.3575 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33805\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8803 - val_loss: 0.3582 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33805\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8804 - val_loss: 0.3578 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33805\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8804 - val_loss: 0.3581 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33805\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8802 - val_loss: 0.3579 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33805\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8802 - val_loss: 0.3583 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33805\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8802 - val_loss: 0.3592 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33805\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 1024\n",
      "Fold: 4\n",
      "best val loss: 0.33804537513102706\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  93.22500324249268\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.9589 - acc: 0.5906 - val_loss: 0.7640 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76403, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6522 - acc: 0.7819 - val_loss: 0.5588 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76403 to 0.55875, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4900 - acc: 0.8434 - val_loss: 0.4491 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55875 to 0.44906, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4155 - acc: 0.8630 - val_loss: 0.4016 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.44906 to 0.40160, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3823 - acc: 0.8688 - val_loss: 0.3786 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40160 to 0.37856, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3646 - acc: 0.8700 - val_loss: 0.3653 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.37856 to 0.36532, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3536 - acc: 0.8710 - val_loss: 0.3569 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36532 to 0.35690, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3464 - acc: 0.8715 - val_loss: 0.3509 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35690 to 0.35085, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3411 - acc: 0.8718 - val_loss: 0.3463 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35085 to 0.34634, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3372 - acc: 0.8721 - val_loss: 0.3430 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34634 to 0.34301, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3343 - acc: 0.8724 - val_loss: 0.3403 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34301 to 0.34033, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3319 - acc: 0.8728 - val_loss: 0.3381 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34033 to 0.33814, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3302 - acc: 0.8728 - val_loss: 0.3366 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33814 to 0.33657, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8728 - val_loss: 0.3351 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33657 to 0.33508, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3273 - acc: 0.8728 - val_loss: 0.3340 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33508 to 0.33398, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3262 - acc: 0.8728 - val_loss: 0.3330 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33398 to 0.33296, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3253 - acc: 0.8730 - val_loss: 0.3322 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33296 to 0.33221, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8731 - val_loss: 0.3314 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33221 to 0.33138, saving model to Post_val_weights1.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3235 - acc: 0.8734 - val_loss: 0.3308 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33138 to 0.33083, saving model to Post_val_weights1.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8735 - val_loss: 0.3304 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33083 to 0.33036, saving model to Post_val_weights1.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8738 - val_loss: 0.3299 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33036 to 0.32987, saving model to Post_val_weights1.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8739 - val_loss: 0.3296 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.32987 to 0.32956, saving model to Post_val_weights1.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8740 - val_loss: 0.3294 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.32956 to 0.32944, saving model to Post_val_weights1.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3204 - acc: 0.8743 - val_loss: 0.3291 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.32944 to 0.32913, saving model to Post_val_weights1.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8746 - val_loss: 0.3291 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.32913 to 0.32909, saving model to Post_val_weights1.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8748 - val_loss: 0.3290 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.32909 to 0.32902, saving model to Post_val_weights1.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8751 - val_loss: 0.3291 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.32902\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8753 - val_loss: 0.3291 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32902\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8754 - val_loss: 0.3291 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32902\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8756 - val_loss: 0.3293 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32902\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8760 - val_loss: 0.3293 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32902\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8761 - val_loss: 0.3296 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32902\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8762 - val_loss: 0.3298 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32902\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8762 - val_loss: 0.3300 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32902\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8762 - val_loss: 0.3300 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.32902\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8763 - val_loss: 0.3303 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.32902\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8763 - val_loss: 0.3304 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.32902\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8763 - val_loss: 0.3308 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.32902\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8764 - val_loss: 0.3310 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.32902\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8764 - val_loss: 0.3313 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.32902\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8766 - val_loss: 0.3313 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.32902\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8765 - val_loss: 0.3317 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.32902\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8766 - val_loss: 0.3319 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.32902\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8766 - val_loss: 0.3321 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.32902\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8766 - val_loss: 0.3324 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.32902\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8767 - val_loss: 0.3326 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.32902\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8767 - val_loss: 0.3329 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.32902\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8769 - val_loss: 0.3331 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.32902\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8771 - val_loss: 0.3333 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.32902\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8771 - val_loss: 0.3336 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.32902\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8773 - val_loss: 0.3338 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.32902\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3131 - acc: 0.8772 - val_loss: 0.3340 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.32902\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8772 - val_loss: 0.3341 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32902\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8771 - val_loss: 0.3345 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.32902\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8771 - val_loss: 0.3348 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.32902\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8772 - val_loss: 0.3349 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.32902\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8773 - val_loss: 0.3351 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32902\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8774 - val_loss: 0.3353 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.32902\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8774 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.32902\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8775 - val_loss: 0.3358 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.32902\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8774 - val_loss: 0.3358 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.32902\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8775 - val_loss: 0.3362 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32902\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8775 - val_loss: 0.3364 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32902\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8775 - val_loss: 0.3367 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.32902\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8777 - val_loss: 0.3370 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32902\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8777 - val_loss: 0.3373 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.32902\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8777 - val_loss: 0.3377 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.32902\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8780 - val_loss: 0.3380 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.32902\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8780 - val_loss: 0.3383 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32902\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8782 - val_loss: 0.3387 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.32902\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8783 - val_loss: 0.3389 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.32902\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8785 - val_loss: 0.3392 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.32902\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8787 - val_loss: 0.3396 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.32902\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8789 - val_loss: 0.3399 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.32902\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8791 - val_loss: 0.3403 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.32902\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8792 - val_loss: 0.3405 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.32902\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8792 - val_loss: 0.3407 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32902\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8794 - val_loss: 0.3410 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.32902\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8795 - val_loss: 0.3412 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32902\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8795 - val_loss: 0.3415 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32902\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8796 - val_loss: 0.3419 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32902\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8798 - val_loss: 0.3423 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.32902\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8797 - val_loss: 0.3425 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.32902\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8798 - val_loss: 0.3426 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.32902\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8799 - val_loss: 0.3427 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32902\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8798 - val_loss: 0.3431 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.32902\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8798 - val_loss: 0.3435 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.32902\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8798 - val_loss: 0.3437 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.32902\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8798 - val_loss: 0.3441 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32902\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8798 - val_loss: 0.3444 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.32902\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8798 - val_loss: 0.3447 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.32902\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8797 - val_loss: 0.3449 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.32902\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8797 - val_loss: 0.3451 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32902\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8797 - val_loss: 0.3454 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.32902\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8798 - val_loss: 0.3453 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32902\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8797 - val_loss: 0.3459 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.32902\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8796 - val_loss: 0.3459 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32902\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8799 - val_loss: 0.3461 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32902\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8799 - val_loss: 0.3462 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32902\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8798 - val_loss: 0.3468 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32902\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 2048\n",
      "Fold: 0\n",
      "best val loss: 0.32901830730382464\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  63.736597299575806\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.9595 - acc: 0.5902 - val_loss: 0.7612 - val_acc: 0.7339\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76119, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6536 - acc: 0.7801 - val_loss: 0.5502 - val_acc: 0.8282\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76119 to 0.55016, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4909 - acc: 0.8425 - val_loss: 0.4422 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55016 to 0.44218, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4161 - acc: 0.8629 - val_loss: 0.3989 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.44218 to 0.39891, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3826 - acc: 0.8682 - val_loss: 0.3776 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39891 to 0.37764, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3648 - acc: 0.8696 - val_loss: 0.3647 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.37764 to 0.36470, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3538 - acc: 0.8709 - val_loss: 0.3562 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36470 to 0.35623, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3463 - acc: 0.8714 - val_loss: 0.3505 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35623 to 0.35045, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3410 - acc: 0.8721 - val_loss: 0.3464 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35045 to 0.34644, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3370 - acc: 0.8725 - val_loss: 0.3434 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34644 to 0.34342, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3340 - acc: 0.8726 - val_loss: 0.3412 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34342 to 0.34117, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3316 - acc: 0.8730 - val_loss: 0.3393 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34117 to 0.33927, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3297 - acc: 0.8732 - val_loss: 0.3379 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33927 to 0.33791, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8734 - val_loss: 0.3365 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33791 to 0.33652, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8737 - val_loss: 0.3356 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33652 to 0.33562, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3257 - acc: 0.8736 - val_loss: 0.3346 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33562 to 0.33457, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8740 - val_loss: 0.3341 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33457 to 0.33406, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8742 - val_loss: 0.3332 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33406 to 0.33318, saving model to Post_val_weights2.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3232 - acc: 0.8740 - val_loss: 0.3330 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33318 to 0.33297, saving model to Post_val_weights2.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3225 - acc: 0.8741 - val_loss: 0.3324 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33297 to 0.33237, saving model to Post_val_weights2.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8743 - val_loss: 0.3322 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33237 to 0.33225, saving model to Post_val_weights2.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8745 - val_loss: 0.3319 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33225 to 0.33189, saving model to Post_val_weights2.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8746 - val_loss: 0.3319 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33189 to 0.33188, saving model to Post_val_weights2.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8746 - val_loss: 0.3314 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33188 to 0.33143, saving model to Post_val_weights2.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8747 - val_loss: 0.3317 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33143\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8748 - val_loss: 0.3313 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33143 to 0.33129, saving model to Post_val_weights2.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8748 - val_loss: 0.3315 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33129\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8749 - val_loss: 0.3314 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33129\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8750 - val_loss: 0.3315 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33129\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8750 - val_loss: 0.3319 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33129\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8751 - val_loss: 0.3316 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33129\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8751 - val_loss: 0.3319 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33129\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8754 - val_loss: 0.3320 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33129\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8756 - val_loss: 0.3321 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33129\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8758 - val_loss: 0.3321 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33129\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8758 - val_loss: 0.3324 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33129\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8758 - val_loss: 0.3324 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33129\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8759 - val_loss: 0.3328 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33129\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8761 - val_loss: 0.3329 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33129\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8759 - val_loss: 0.3329 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33129\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8762 - val_loss: 0.3332 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33129\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8762 - val_loss: 0.3336 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33129\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8763 - val_loss: 0.3339 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33129\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8764 - val_loss: 0.3339 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33129\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8764 - val_loss: 0.3345 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33129\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8766 - val_loss: 0.3346 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33129\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8766 - val_loss: 0.3351 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33129\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8768 - val_loss: 0.3351 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33129\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8769 - val_loss: 0.3354 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33129\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8771 - val_loss: 0.3359 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33129\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8771 - val_loss: 0.3359 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33129\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8773 - val_loss: 0.3363 - val_acc: 0.8668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33129\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8776 - val_loss: 0.3368 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33129\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8775 - val_loss: 0.3372 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33129\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8776 - val_loss: 0.3373 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33129\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8777 - val_loss: 0.3377 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33129\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8776 - val_loss: 0.3380 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33129\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8777 - val_loss: 0.3384 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33129\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8779 - val_loss: 0.3387 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33129\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8778 - val_loss: 0.3392 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33129\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8780 - val_loss: 0.3393 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33129\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8780 - val_loss: 0.3399 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33129\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8781 - val_loss: 0.3400 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33129\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8783 - val_loss: 0.3405 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33129\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8784 - val_loss: 0.3405 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33129\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8784 - val_loss: 0.3411 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33129\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8785 - val_loss: 0.3411 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33129\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8785 - val_loss: 0.3416 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33129\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8785 - val_loss: 0.3415 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33129\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8784 - val_loss: 0.3420 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33129\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8784 - val_loss: 0.3422 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33129\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8785 - val_loss: 0.3425 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33129\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8785 - val_loss: 0.3425 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33129\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8784 - val_loss: 0.3426 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33129\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8788 - val_loss: 0.3431 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33129\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8788 - val_loss: 0.3431 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33129\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8788 - val_loss: 0.3434 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33129\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8789 - val_loss: 0.3435 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33129\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8789 - val_loss: 0.3440 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33129\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8790 - val_loss: 0.3440 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33129\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8790 - val_loss: 0.3446 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33129\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8792 - val_loss: 0.3444 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33129\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8793 - val_loss: 0.3451 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33129\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8794 - val_loss: 0.3449 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33129\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8794 - val_loss: 0.3456 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33129\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8795 - val_loss: 0.3454 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33129\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8795 - val_loss: 0.3461 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33129\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8796 - val_loss: 0.3459 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33129\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8797 - val_loss: 0.3465 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33129\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8796 - val_loss: 0.3466 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33129\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8794 - val_loss: 0.3469 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33129\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8796 - val_loss: 0.3470 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33129\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8797 - val_loss: 0.3474 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33129\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8800 - val_loss: 0.3474 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33129\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8799 - val_loss: 0.3482 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33129\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8801 - val_loss: 0.3477 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33129\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8799 - val_loss: 0.3482 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33129\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8801 - val_loss: 0.3480 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33129\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8799 - val_loss: 0.3482 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33129\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8799 - val_loss: 0.3481 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33129\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 2048\n",
      "Fold: 1\n",
      "best val loss: 0.3312898122915748\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  63.621875524520874\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.9586 - acc: 0.5906 - val_loss: 0.7693 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76927, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6529 - acc: 0.7809 - val_loss: 0.5616 - val_acc: 0.8171\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76927 to 0.56159, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4901 - acc: 0.8437 - val_loss: 0.4560 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56159 to 0.45596, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4154 - acc: 0.8640 - val_loss: 0.4084 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45596 to 0.40842, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3819 - acc: 0.8684 - val_loss: 0.3842 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40842 to 0.38416, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3640 - acc: 0.8707 - val_loss: 0.3704 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38416 to 0.37041, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3529 - acc: 0.8714 - val_loss: 0.3617 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37041 to 0.36169, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3454 - acc: 0.8721 - val_loss: 0.3560 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36169 to 0.35595, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3401 - acc: 0.8728 - val_loss: 0.3518 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35595 to 0.35181, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3361 - acc: 0.8733 - val_loss: 0.3489 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35181 to 0.34887, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3331 - acc: 0.8735 - val_loss: 0.3466 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34887 to 0.34662, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3308 - acc: 0.8739 - val_loss: 0.3449 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34662 to 0.34493, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3288 - acc: 0.8740 - val_loss: 0.3436 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34493 to 0.34356, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3273 - acc: 0.8741 - val_loss: 0.3425 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34356 to 0.34253, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3260 - acc: 0.8744 - val_loss: 0.3416 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34253 to 0.34157, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3249 - acc: 0.8745 - val_loss: 0.3408 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34157 to 0.34083, saving model to Post_val_weights3.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8747 - val_loss: 0.3401 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34083 to 0.34015, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8747 - val_loss: 0.3396 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34015 to 0.33964, saving model to Post_val_weights3.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8749 - val_loss: 0.3392 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33964 to 0.33919, saving model to Post_val_weights3.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8750 - val_loss: 0.3389 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33919 to 0.33886, saving model to Post_val_weights3.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8750 - val_loss: 0.3386 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33886 to 0.33862, saving model to Post_val_weights3.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8751 - val_loss: 0.3384 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33862 to 0.33835, saving model to Post_val_weights3.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8753 - val_loss: 0.3383 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33835 to 0.33826, saving model to Post_val_weights3.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8753 - val_loss: 0.3381 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33826 to 0.33807, saving model to Post_val_weights3.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8753 - val_loss: 0.3381 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33807 to 0.33805, saving model to Post_val_weights3.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8753 - val_loss: 0.3379 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33805 to 0.33793, saving model to Post_val_weights3.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8755 - val_loss: 0.3379 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33793\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8756 - val_loss: 0.3380 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33793\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8758 - val_loss: 0.3381 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33793\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8760 - val_loss: 0.3382 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33793\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8761 - val_loss: 0.3382 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33793\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8762 - val_loss: 0.3385 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33793\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8761 - val_loss: 0.3387 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33793\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8763 - val_loss: 0.3389 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33793\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8763 - val_loss: 0.3391 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33793\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8765 - val_loss: 0.3394 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33793\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8765 - val_loss: 0.3397 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33793\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8768 - val_loss: 0.3400 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33793\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8768 - val_loss: 0.3404 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33793\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8767 - val_loss: 0.3407 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33793\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8769 - val_loss: 0.3411 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33793\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8768 - val_loss: 0.3414 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33793\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8768 - val_loss: 0.3420 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33793\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8768 - val_loss: 0.3422 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33793\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8770 - val_loss: 0.3425 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33793\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8771 - val_loss: 0.3429 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33793\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8772 - val_loss: 0.3430 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33793\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8774 - val_loss: 0.3436 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33793\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8774 - val_loss: 0.3437 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33793\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8774 - val_loss: 0.3441 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33793\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8774 - val_loss: 0.3442 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33793\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3121 - acc: 0.8776 - val_loss: 0.3446 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33793\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8776 - val_loss: 0.3449 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33793\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8777 - val_loss: 0.3451 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33793\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8778 - val_loss: 0.3453 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33793\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8779 - val_loss: 0.3456 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33793\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8780 - val_loss: 0.3461 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33793\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8782 - val_loss: 0.3460 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33793\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8781 - val_loss: 0.3464 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33793\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8781 - val_loss: 0.3467 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33793\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8781 - val_loss: 0.3472 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33793\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8782 - val_loss: 0.3473 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33793\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8782 - val_loss: 0.3475 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33793\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8783 - val_loss: 0.3476 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33793\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8783 - val_loss: 0.3481 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33793\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8784 - val_loss: 0.3481 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33793\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8786 - val_loss: 0.3483 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33793\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8786 - val_loss: 0.3486 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33793\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8787 - val_loss: 0.3490 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33793\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8787 - val_loss: 0.3490 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33793\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8788 - val_loss: 0.3493 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33793\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8788 - val_loss: 0.3492 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33793\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8791 - val_loss: 0.3497 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33793\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8790 - val_loss: 0.3498 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33793\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8791 - val_loss: 0.3501 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33793\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8789 - val_loss: 0.3502 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33793\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8789 - val_loss: 0.3503 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33793\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8791 - val_loss: 0.3504 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33793\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8792 - val_loss: 0.3504 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33793\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8790 - val_loss: 0.3502 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33793\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8790 - val_loss: 0.3506 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33793\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8793 - val_loss: 0.3506 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33793\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8791 - val_loss: 0.3507 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33793\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8792 - val_loss: 0.3510 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33793\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8794 - val_loss: 0.3509 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33793\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8795 - val_loss: 0.3513 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33793\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8794 - val_loss: 0.3512 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33793\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8796 - val_loss: 0.3514 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33793\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8797 - val_loss: 0.3514 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33793\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8800 - val_loss: 0.3515 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33793\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8799 - val_loss: 0.3515 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33793\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8798 - val_loss: 0.3520 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33793\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8799 - val_loss: 0.3519 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33793\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8799 - val_loss: 0.3522 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33793\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8799 - val_loss: 0.3523 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33793\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8799 - val_loss: 0.3523 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33793\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8800 - val_loss: 0.3523 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33793\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8799 - val_loss: 0.3526 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33793\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8801 - val_loss: 0.3525 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33793\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8804 - val_loss: 0.3529 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33793\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 2048\n",
      "Fold: 2\n",
      "best val loss: 0.3379315251565119\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  65.31690096855164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f6844142710>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.9598 - acc: 0.5891 - val_loss: 0.7731 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77306, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6537 - acc: 0.7809 - val_loss: 0.5566 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77306 to 0.55662, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4914 - acc: 0.8426 - val_loss: 0.4446 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55662 to 0.44458, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4160 - acc: 0.8632 - val_loss: 0.3984 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.44458 to 0.39837, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3822 - acc: 0.8683 - val_loss: 0.3753 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39837 to 0.37527, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3643 - acc: 0.8702 - val_loss: 0.3622 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.37527 to 0.36216, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3532 - acc: 0.8710 - val_loss: 0.3538 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36216 to 0.35376, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3459 - acc: 0.8715 - val_loss: 0.3481 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35376 to 0.34811, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3407 - acc: 0.8720 - val_loss: 0.3439 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34811 to 0.34389, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3367 - acc: 0.8725 - val_loss: 0.3408 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34389 to 0.34076, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3338 - acc: 0.8725 - val_loss: 0.3385 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34076 to 0.33855, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3314 - acc: 0.8727 - val_loss: 0.3366 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33855 to 0.33663, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3296 - acc: 0.8730 - val_loss: 0.3352 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33663 to 0.33517, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3279 - acc: 0.8732 - val_loss: 0.3340 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33517 to 0.33401, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3267 - acc: 0.8736 - val_loss: 0.3330 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33401 to 0.33299, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8737 - val_loss: 0.3326 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33299 to 0.33264, saving model to Post_val_weights4.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3246 - acc: 0.8737 - val_loss: 0.3317 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33264 to 0.33174, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3236 - acc: 0.8739 - val_loss: 0.3313 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33174 to 0.33132, saving model to Post_val_weights4.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8739 - val_loss: 0.3310 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33132 to 0.33104, saving model to Post_val_weights4.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8742 - val_loss: 0.3309 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33104 to 0.33088, saving model to Post_val_weights4.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8743 - val_loss: 0.3306 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33088 to 0.33056, saving model to Post_val_weights4.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8745 - val_loss: 0.3306 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33056\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8745 - val_loss: 0.3306 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33056\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8746 - val_loss: 0.3304 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33056 to 0.33040, saving model to Post_val_weights4.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8748 - val_loss: 0.3304 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33040\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8750 - val_loss: 0.3306 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33040\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8753 - val_loss: 0.3308 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33040\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8755 - val_loss: 0.3306 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33040\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8754 - val_loss: 0.3312 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33040\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8755 - val_loss: 0.3310 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33040\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8754 - val_loss: 0.3313 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33040\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8754 - val_loss: 0.3314 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33040\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8757 - val_loss: 0.3320 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33040\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8755 - val_loss: 0.3319 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33040\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8756 - val_loss: 0.3326 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33040\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8756 - val_loss: 0.3324 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33040\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8757 - val_loss: 0.3330 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33040\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8759 - val_loss: 0.3331 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33040\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8761 - val_loss: 0.3335 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33040\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8761 - val_loss: 0.3338 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33040\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8762 - val_loss: 0.3341 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33040\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8764 - val_loss: 0.3343 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33040\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8764 - val_loss: 0.3348 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33040\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8765 - val_loss: 0.3347 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33040\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8766 - val_loss: 0.3352 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33040\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8765 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33040\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8766 - val_loss: 0.3355 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33040\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8767 - val_loss: 0.3359 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33040\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8770 - val_loss: 0.3359 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33040\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8771 - val_loss: 0.3361 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33040\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8772 - val_loss: 0.3365 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33040\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8770 - val_loss: 0.3368 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33040\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8772 - val_loss: 0.3371 - val_acc: 0.8682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33040\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8771 - val_loss: 0.3371 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33040\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8771 - val_loss: 0.3372 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33040\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8771 - val_loss: 0.3376 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33040\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8771 - val_loss: 0.3380 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33040\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8772 - val_loss: 0.3381 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33040\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8774 - val_loss: 0.3384 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33040\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8777 - val_loss: 0.3386 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33040\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8776 - val_loss: 0.3389 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33040\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8776 - val_loss: 0.3392 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33040\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8776 - val_loss: 0.3396 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33040\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8778 - val_loss: 0.3398 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33040\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8778 - val_loss: 0.3402 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33040\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8776 - val_loss: 0.3405 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33040\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8775 - val_loss: 0.3407 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33040\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8778 - val_loss: 0.3410 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33040\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8779 - val_loss: 0.3413 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33040\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8782 - val_loss: 0.3416 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33040\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8781 - val_loss: 0.3418 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33040\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8783 - val_loss: 0.3420 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33040\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8783 - val_loss: 0.3423 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33040\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8784 - val_loss: 0.3426 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33040\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8785 - val_loss: 0.3427 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33040\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8786 - val_loss: 0.3429 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33040\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8787 - val_loss: 0.3431 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33040\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8790 - val_loss: 0.3433 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33040\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8789 - val_loss: 0.3435 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33040\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8791 - val_loss: 0.3436 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33040\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8792 - val_loss: 0.3437 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33040\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8791 - val_loss: 0.3440 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33040\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8791 - val_loss: 0.3441 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33040\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8792 - val_loss: 0.3443 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33040\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8792 - val_loss: 0.3445 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33040\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8791 - val_loss: 0.3446 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33040\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8791 - val_loss: 0.3448 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33040\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8791 - val_loss: 0.3447 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33040\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8793 - val_loss: 0.3449 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33040\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8793 - val_loss: 0.3449 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33040\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8794 - val_loss: 0.3453 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33040\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8793 - val_loss: 0.3453 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33040\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8796 - val_loss: 0.3453 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33040\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8795 - val_loss: 0.3462 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33040\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8795 - val_loss: 0.3449 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33040\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8798 - val_loss: 0.3454 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33040\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8798 - val_loss: 0.3455 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33040\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8801 - val_loss: 0.3456 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33040\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8801 - val_loss: 0.3460 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33040\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8802 - val_loss: 0.3459 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33040\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 2048\n",
      "Fold: 3\n",
      "best val loss: 0.3303973318749701\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  65.03043818473816\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.9601 - acc: 0.5897 - val_loss: 0.7683 - val_acc: 0.7214\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76834, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6521 - acc: 0.7826 - val_loss: 0.5559 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76834 to 0.55588, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4890 - acc: 0.8443 - val_loss: 0.4512 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55588 to 0.45123, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4147 - acc: 0.8634 - val_loss: 0.4058 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45123 to 0.40580, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3812 - acc: 0.8684 - val_loss: 0.3831 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40580 to 0.38307, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3634 - acc: 0.8706 - val_loss: 0.3702 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38307 to 0.37023, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3523 - acc: 0.8716 - val_loss: 0.3615 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37023 to 0.36149, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3449 - acc: 0.8727 - val_loss: 0.3555 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36149 to 0.35550, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3397 - acc: 0.8732 - val_loss: 0.3514 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35550 to 0.35143, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3357 - acc: 0.8736 - val_loss: 0.3482 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35143 to 0.34822, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3328 - acc: 0.8740 - val_loss: 0.3458 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34822 to 0.34580, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3305 - acc: 0.8743 - val_loss: 0.3440 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34580 to 0.34397, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3287 - acc: 0.8741 - val_loss: 0.3425 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34397 to 0.34246, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3272 - acc: 0.8743 - val_loss: 0.3413 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34246 to 0.34132, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3259 - acc: 0.8744 - val_loss: 0.3404 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34132 to 0.34036, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3249 - acc: 0.8744 - val_loss: 0.3396 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34036 to 0.33957, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8746 - val_loss: 0.3389 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33957 to 0.33891, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3232 - acc: 0.8747 - val_loss: 0.3383 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33891 to 0.33832, saving model to Post_val_weights5.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8750 - val_loss: 0.3378 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33832 to 0.33781, saving model to Post_val_weights5.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8750 - val_loss: 0.3373 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33781 to 0.33734, saving model to Post_val_weights5.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8752 - val_loss: 0.3370 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33734 to 0.33697, saving model to Post_val_weights5.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8752 - val_loss: 0.3367 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33697 to 0.33669, saving model to Post_val_weights5.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8755 - val_loss: 0.3363 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33669 to 0.33631, saving model to Post_val_weights5.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8756 - val_loss: 0.3362 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33631 to 0.33620, saving model to Post_val_weights5.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8755 - val_loss: 0.3357 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33620 to 0.33575, saving model to Post_val_weights5.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8755 - val_loss: 0.3357 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33575 to 0.33570, saving model to Post_val_weights5.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8757 - val_loss: 0.3355 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33570 to 0.33547, saving model to Post_val_weights5.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8757 - val_loss: 0.3354 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33547 to 0.33544, saving model to Post_val_weights5.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8759 - val_loss: 0.3354 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33544 to 0.33539, saving model to Post_val_weights5.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8762 - val_loss: 0.3354 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33539\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8764 - val_loss: 0.3354 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33539\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8766 - val_loss: 0.3355 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33539\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8764 - val_loss: 0.3356 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33539\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8764 - val_loss: 0.3357 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33539\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8765 - val_loss: 0.3360 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33539\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8764 - val_loss: 0.3360 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33539\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8763 - val_loss: 0.3362 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33539\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8764 - val_loss: 0.3364 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33539\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8767 - val_loss: 0.3366 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33539\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8768 - val_loss: 0.3367 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33539\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8769 - val_loss: 0.3370 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33539\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8769 - val_loss: 0.3371 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33539\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8769 - val_loss: 0.3374 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33539\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8769 - val_loss: 0.3376 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33539\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8771 - val_loss: 0.3379 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33539\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8770 - val_loss: 0.3382 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33539\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8771 - val_loss: 0.3384 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33539\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8770 - val_loss: 0.3388 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33539\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8772 - val_loss: 0.3389 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33539\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8773 - val_loss: 0.3393 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33539\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3122 - acc: 0.8774 - val_loss: 0.3395 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33539\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8775 - val_loss: 0.3398 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33539\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8775 - val_loss: 0.3402 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33539\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8777 - val_loss: 0.3403 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33539\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8778 - val_loss: 0.3405 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33539\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8779 - val_loss: 0.3409 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33539\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8778 - val_loss: 0.3410 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33539\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8780 - val_loss: 0.3414 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33539\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8780 - val_loss: 0.3416 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33539\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8779 - val_loss: 0.3420 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33539\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8782 - val_loss: 0.3421 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33539\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8783 - val_loss: 0.3426 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33539\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8783 - val_loss: 0.3425 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33539\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8784 - val_loss: 0.3431 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33539\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8785 - val_loss: 0.3431 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33539\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8786 - val_loss: 0.3436 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33539\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8784 - val_loss: 0.3437 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33539\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8783 - val_loss: 0.3440 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33539\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8782 - val_loss: 0.3440 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33539\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8784 - val_loss: 0.3453 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33539\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8783 - val_loss: 0.3448 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33539\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8784 - val_loss: 0.3449 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33539\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8785 - val_loss: 0.3452 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33539\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8786 - val_loss: 0.3453 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33539\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8789 - val_loss: 0.3455 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33539\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8789 - val_loss: 0.3459 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33539\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8787 - val_loss: 0.3458 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33539\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8789 - val_loss: 0.3462 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33539\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8789 - val_loss: 0.3461 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33539\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8789 - val_loss: 0.3464 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33539\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8791 - val_loss: 0.3464 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33539\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8793 - val_loss: 0.3466 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33539\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8794 - val_loss: 0.3469 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33539\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8796 - val_loss: 0.3470 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33539\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8795 - val_loss: 0.3473 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33539\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8797 - val_loss: 0.3476 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33539\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8798 - val_loss: 0.3475 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33539\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8798 - val_loss: 0.3478 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33539\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8799 - val_loss: 0.3481 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33539\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8799 - val_loss: 0.3483 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33539\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8800 - val_loss: 0.3485 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33539\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8799 - val_loss: 0.3487 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33539\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8801 - val_loss: 0.3487 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33539\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8801 - val_loss: 0.3490 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33539\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8802 - val_loss: 0.3490 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33539\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8803 - val_loss: 0.3495 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33539\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8804 - val_loss: 0.3495 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33539\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8803 - val_loss: 0.3498 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33539\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8804 - val_loss: 0.3498 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33539\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8803 - val_loss: 0.3502 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33539\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 2048\n",
      "Fold: 4\n",
      "best val loss: 0.33539121395663213\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  67.32205390930176\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.0685 - acc: 0.5127 - val_loss: 0.9178 - val_acc: 0.6099\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.91782, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8359 - acc: 0.6772 - val_loss: 0.7546 - val_acc: 0.7230\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.91782 to 0.75464, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6925 - acc: 0.7626 - val_loss: 0.6361 - val_acc: 0.7847\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.75464 to 0.63606, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5816 - acc: 0.8116 - val_loss: 0.5424 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63606 to 0.54241, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4997 - acc: 0.8406 - val_loss: 0.4766 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54241 to 0.47655, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4460 - acc: 0.8557 - val_loss: 0.4352 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47655 to 0.43521, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4122 - acc: 0.8634 - val_loss: 0.4085 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43521 to 0.40851, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3903 - acc: 0.8672 - val_loss: 0.3902 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.40851 to 0.39019, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3753 - acc: 0.8698 - val_loss: 0.3780 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39019 to 0.37803, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3648 - acc: 0.8708 - val_loss: 0.3694 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37803 to 0.36945, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3569 - acc: 0.8718 - val_loss: 0.3631 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36945 to 0.36305, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3508 - acc: 0.8724 - val_loss: 0.3580 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36305 to 0.35801, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3461 - acc: 0.8728 - val_loss: 0.3540 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35801 to 0.35397, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3423 - acc: 0.8731 - val_loss: 0.3507 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35397 to 0.35075, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3391 - acc: 0.8735 - val_loss: 0.3480 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.35075 to 0.34800, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3366 - acc: 0.8738 - val_loss: 0.3457 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34800 to 0.34570, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3343 - acc: 0.8738 - val_loss: 0.3436 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34570 to 0.34359, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3324 - acc: 0.8741 - val_loss: 0.3420 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34359 to 0.34197, saving model to Post_val_weights1.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3309 - acc: 0.8740 - val_loss: 0.3405 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34197 to 0.34050, saving model to Post_val_weights1.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8742 - val_loss: 0.3393 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34050 to 0.33929, saving model to Post_val_weights1.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3283 - acc: 0.8743 - val_loss: 0.3381 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33929 to 0.33813, saving model to Post_val_weights1.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3272 - acc: 0.8743 - val_loss: 0.3371 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33813 to 0.33709, saving model to Post_val_weights1.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8742 - val_loss: 0.3362 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33709 to 0.33620, saving model to Post_val_weights1.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3253 - acc: 0.8746 - val_loss: 0.3354 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33620 to 0.33537, saving model to Post_val_weights1.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3245 - acc: 0.8746 - val_loss: 0.3346 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33537 to 0.33463, saving model to Post_val_weights1.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3237 - acc: 0.8748 - val_loss: 0.3339 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33463 to 0.33387, saving model to Post_val_weights1.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8748 - val_loss: 0.3332 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33387 to 0.33323, saving model to Post_val_weights1.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8750 - val_loss: 0.3326 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33323 to 0.33259, saving model to Post_val_weights1.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8751 - val_loss: 0.3322 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33259 to 0.33221, saving model to Post_val_weights1.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8752 - val_loss: 0.3316 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33221 to 0.33159, saving model to Post_val_weights1.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8753 - val_loss: 0.3311 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33159 to 0.33111, saving model to Post_val_weights1.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8755 - val_loss: 0.3306 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33111 to 0.33058, saving model to Post_val_weights1.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8753 - val_loss: 0.3303 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33058 to 0.33027, saving model to Post_val_weights1.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8756 - val_loss: 0.3298 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33027 to 0.32982, saving model to Post_val_weights1.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8755 - val_loss: 0.3296 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.32982 to 0.32957, saving model to Post_val_weights1.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8756 - val_loss: 0.3292 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.32957 to 0.32922, saving model to Post_val_weights1.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8756 - val_loss: 0.3290 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.32922 to 0.32904, saving model to Post_val_weights1.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8758 - val_loss: 0.3287 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.32904 to 0.32874, saving model to Post_val_weights1.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8760 - val_loss: 0.3287 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.32874 to 0.32869, saving model to Post_val_weights1.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8759 - val_loss: 0.3284 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.32869 to 0.32845, saving model to Post_val_weights1.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8763 - val_loss: 0.3285 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.32845\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8763 - val_loss: 0.3283 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.32845 to 0.32830, saving model to Post_val_weights1.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8766 - val_loss: 0.3284 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.32830\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8769 - val_loss: 0.3283 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.32830 to 0.32826, saving model to Post_val_weights1.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8770 - val_loss: 0.3284 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.32826\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8772 - val_loss: 0.3283 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.32826\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3140 - acc: 0.8771 - val_loss: 0.3285 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.32826\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8770 - val_loss: 0.3285 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.32826\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8772 - val_loss: 0.3287 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.32826\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8773 - val_loss: 0.3288 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.32826\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8772 - val_loss: 0.3290 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.32826\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8772 - val_loss: 0.3291 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.32826\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8773 - val_loss: 0.3293 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32826\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8775 - val_loss: 0.3294 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.32826\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8777 - val_loss: 0.3297 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.32826\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8778 - val_loss: 0.3296 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.32826\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8780 - val_loss: 0.3299 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32826\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8783 - val_loss: 0.3299 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.32826\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8781 - val_loss: 0.3305 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.32826\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8780 - val_loss: 0.3304 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.32826\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8778 - val_loss: 0.3307 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.32826\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8783 - val_loss: 0.3309 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32826\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8783 - val_loss: 0.3311 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32826\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8785 - val_loss: 0.3312 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.32826\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8784 - val_loss: 0.3316 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32826\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8785 - val_loss: 0.3317 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.32826\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8784 - val_loss: 0.3320 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.32826\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8785 - val_loss: 0.3321 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.32826\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8786 - val_loss: 0.3324 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32826\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8785 - val_loss: 0.3326 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.32826\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8785 - val_loss: 0.3330 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.32826\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8785 - val_loss: 0.3331 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.32826\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8786 - val_loss: 0.3336 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.32826\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8785 - val_loss: 0.3335 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.32826\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8785 - val_loss: 0.3337 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.32826\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8785 - val_loss: 0.3337 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.32826\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8785 - val_loss: 0.3342 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32826\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8786 - val_loss: 0.3340 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.32826\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8786 - val_loss: 0.3347 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32826\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8787 - val_loss: 0.3345 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32826\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8786 - val_loss: 0.3348 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32826\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8788 - val_loss: 0.3351 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.32826\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8788 - val_loss: 0.3355 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.32826\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8791 - val_loss: 0.3354 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.32826\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8791 - val_loss: 0.3359 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32826\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8792 - val_loss: 0.3359 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.32826\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8793 - val_loss: 0.3364 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.32826\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8794 - val_loss: 0.3366 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.32826\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3055 - acc: 0.8796 - val_loss: 0.3369 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32826\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8797 - val_loss: 0.3369 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.32826\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8797 - val_loss: 0.3375 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.32826\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3050 - acc: 0.8799 - val_loss: 0.3375 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.32826\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8800 - val_loss: 0.3377 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32826\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8802 - val_loss: 0.3379 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.32826\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8802 - val_loss: 0.3379 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32826\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8802 - val_loss: 0.3382 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.32826\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8802 - val_loss: 0.3384 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32826\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8804 - val_loss: 0.3385 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32826\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3040 - acc: 0.8805 - val_loss: 0.3388 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32826\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8804 - val_loss: 0.3391 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32826\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 4096\n",
      "Fold: 0\n",
      "best val loss: 0.32826085590479664\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  74.41466522216797\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.0688 - acc: 0.5133 - val_loss: 0.9182 - val_acc: 0.6147\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.91818, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8366 - acc: 0.6758 - val_loss: 0.7522 - val_acc: 0.7384\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.91818 to 0.75218, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6941 - acc: 0.7615 - val_loss: 0.6299 - val_acc: 0.7953\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.75218 to 0.62991, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5838 - acc: 0.8099 - val_loss: 0.5343 - val_acc: 0.8318\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62991 to 0.53425, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5013 - acc: 0.8395 - val_loss: 0.4684 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53425 to 0.46844, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4469 - acc: 0.8551 - val_loss: 0.4286 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46844 to 0.42860, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4126 - acc: 0.8636 - val_loss: 0.4041 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42860 to 0.40413, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3902 - acc: 0.8668 - val_loss: 0.3878 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.40413 to 0.38785, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3753 - acc: 0.8694 - val_loss: 0.3768 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38785 to 0.37678, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3647 - acc: 0.8709 - val_loss: 0.3686 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37678 to 0.36858, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3569 - acc: 0.8714 - val_loss: 0.3621 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36858 to 0.36206, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3508 - acc: 0.8722 - val_loss: 0.3569 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36206 to 0.35688, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3459 - acc: 0.8728 - val_loss: 0.3527 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35688 to 0.35270, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3421 - acc: 0.8730 - val_loss: 0.3494 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35270 to 0.34937, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3389 - acc: 0.8736 - val_loss: 0.3467 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34937 to 0.34666, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3363 - acc: 0.8736 - val_loss: 0.3445 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34666 to 0.34450, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3341 - acc: 0.8738 - val_loss: 0.3427 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34450 to 0.34268, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3321 - acc: 0.8738 - val_loss: 0.3411 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34268 to 0.34108, saving model to Post_val_weights2.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3305 - acc: 0.8738 - val_loss: 0.3399 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34108 to 0.33985, saving model to Post_val_weights2.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3291 - acc: 0.8740 - val_loss: 0.3386 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33985 to 0.33865, saving model to Post_val_weights2.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3279 - acc: 0.8743 - val_loss: 0.3377 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33865 to 0.33767, saving model to Post_val_weights2.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8742 - val_loss: 0.3367 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33767 to 0.33674, saving model to Post_val_weights2.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3258 - acc: 0.8743 - val_loss: 0.3360 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33674 to 0.33595, saving model to Post_val_weights2.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3249 - acc: 0.8744 - val_loss: 0.3353 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33595 to 0.33526, saving model to Post_val_weights2.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3241 - acc: 0.8745 - val_loss: 0.3346 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33526 to 0.33458, saving model to Post_val_weights2.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8746 - val_loss: 0.3340 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33458 to 0.33397, saving model to Post_val_weights2.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8748 - val_loss: 0.3335 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33397 to 0.33345, saving model to Post_val_weights2.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8750 - val_loss: 0.3330 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33345 to 0.33297, saving model to Post_val_weights2.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8750 - val_loss: 0.3325 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33297 to 0.33252, saving model to Post_val_weights2.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8750 - val_loss: 0.3322 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33252 to 0.33216, saving model to Post_val_weights2.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8751 - val_loss: 0.3318 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33216 to 0.33175, saving model to Post_val_weights2.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8753 - val_loss: 0.3314 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33175 to 0.33143, saving model to Post_val_weights2.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8751 - val_loss: 0.3312 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33143 to 0.33115, saving model to Post_val_weights2.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8753 - val_loss: 0.3309 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33115 to 0.33091, saving model to Post_val_weights2.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8756 - val_loss: 0.3307 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33091 to 0.33070, saving model to Post_val_weights2.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8756 - val_loss: 0.3306 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33070 to 0.33055, saving model to Post_val_weights2.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8755 - val_loss: 0.3304 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33055 to 0.33039, saving model to Post_val_weights2.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8755 - val_loss: 0.3303 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33039 to 0.33032, saving model to Post_val_weights2.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8758 - val_loss: 0.3302 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33032 to 0.33019, saving model to Post_val_weights2.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8760 - val_loss: 0.3302 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33019\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8760 - val_loss: 0.3301 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33019 to 0.33012, saving model to Post_val_weights2.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8762 - val_loss: 0.3302 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33012\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8763 - val_loss: 0.3302 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33012\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8764 - val_loss: 0.3302 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33012\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8766 - val_loss: 0.3303 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33012\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8766 - val_loss: 0.3304 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33012\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8764 - val_loss: 0.3305 - val_acc: 0.8708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33012\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8765 - val_loss: 0.3305 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33012\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8765 - val_loss: 0.3308 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33012\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8764 - val_loss: 0.3308 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33012\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8765 - val_loss: 0.3309 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33012\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8767 - val_loss: 0.3313 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33012\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8768 - val_loss: 0.3311 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33012\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8768 - val_loss: 0.3318 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33012\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8769 - val_loss: 0.3315 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33012\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8770 - val_loss: 0.3321 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33012\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8771 - val_loss: 0.3323 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33012\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8771 - val_loss: 0.3323 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33012\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8772 - val_loss: 0.3328 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33012\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8774 - val_loss: 0.3328 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33012\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8774 - val_loss: 0.3332 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33012\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8774 - val_loss: 0.3336 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33012\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8774 - val_loss: 0.3335 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33012\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8776 - val_loss: 0.3340 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33012\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8777 - val_loss: 0.3341 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33012\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8777 - val_loss: 0.3345 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33012\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8777 - val_loss: 0.3348 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33012\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8778 - val_loss: 0.3350 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33012\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8781 - val_loss: 0.3352 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33012\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8780 - val_loss: 0.3356 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33012\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8781 - val_loss: 0.3358 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33012\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8781 - val_loss: 0.3360 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33012\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8782 - val_loss: 0.3363 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33012\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8781 - val_loss: 0.3366 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33012\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8781 - val_loss: 0.3367 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33012\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8781 - val_loss: 0.3371 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33012\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8783 - val_loss: 0.3374 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33012\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8782 - val_loss: 0.3377 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33012\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8783 - val_loss: 0.3380 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33012\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8783 - val_loss: 0.3382 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33012\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8783 - val_loss: 0.3383 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33012\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8785 - val_loss: 0.3387 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33012\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8786 - val_loss: 0.3390 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33012\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8788 - val_loss: 0.3391 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33012\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8789 - val_loss: 0.3395 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33012\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8789 - val_loss: 0.3398 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33012\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8789 - val_loss: 0.3398 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33012\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8791 - val_loss: 0.3402 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33012\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8792 - val_loss: 0.3402 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33012\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8793 - val_loss: 0.3405 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33012\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8796 - val_loss: 0.3411 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33012\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8795 - val_loss: 0.3411 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33012\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3051 - acc: 0.8796 - val_loss: 0.3417 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33012\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3050 - acc: 0.8795 - val_loss: 0.3418 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33012\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8797 - val_loss: 0.3420 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33012\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8799 - val_loss: 0.3419 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33012\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8801 - val_loss: 0.3422 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33012\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8800 - val_loss: 0.3425 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33012\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8802 - val_loss: 0.3428 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33012\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8802 - val_loss: 0.3429 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33012\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 4096\n",
      "Fold: 1\n",
      "best val loss: 0.3301164361538246\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZgcd33n8fe3zzmlGc1II1s3tmzrwPiYxzhrMMIQVjZgcwY7ZBOzYGW9NjgkJBFP8gDrJBuycQx4I2AV8AJejPGagAUrxwTHYEhs8PhSdPgQli2NztHomHumj+/+UdUzrfGMpiX1qNXdn9fz9NNdVb+q+tWU9Klf/7oOc3dERKT8RUpdARERKQ4FuohIhVCgi4hUCAW6iEiFUKCLiFQIBbqISIWYMtDN7G4zO2BmmyeZfoGZPW5mw2b2qeJXUUREClFIC/0bwOrjTD8EfAK4oxgVEhGRkxObqoC7P2Zmi48z/QBwwMzeeSIrbm1t9cWLJ12siIhM4Kmnnjro7rMnmjZloE+XxYsX09HRUarVi4iUJTN7dbJpp/VHUTNbY2YdZtbR1dV1OlctIlLxTmugu/t6d2939/bZsyf8xiAiIidJpy2KiFSIKfvQzew7wCqg1cw6gc8CcQB3/6qZzQU6gBlA1sz+AFju7j3TVmsROeOkUik6OzsZGhoqdVUqQk1NDfPnzycejxc8TyFnudwwxfR9wPyC1ygiFamzs5PGxkYWL16MmZW6OmXN3enu7qazs5MlS5YUPJ+6XESkKIaGhmhpaVGYF4GZ0dLScsLfdhToIlI0CvPiOZm/ZdkF+vP7erjj4Rc41D9S6qqIyBnkyJEjfPnLXz7h+a655hqOHDkyDTU6/cou0Hd09fP3j25n31H98CIiYyYL9HQ6fdz5Nm7cSFNT03RV67Qq2ZWiJ6s+GVS5f+T4O0lEqsvatWv59a9/zUUXXUQ8Hqempobm5maef/55XnzxRd7znvewa9cuhoaGuO2221izZg0wdtV6X18fV199NW9605v4t3/7N+bNm8eDDz5IbW1tibescGXXQs8Fet+wAl1Exnz+85/nnHPO4dlnn+Vv//Zvefrpp/nSl77Eiy++CMDdd9/NU089RUdHB3fddRfd3d2vWcZLL73ELbfcwpYtW2hqauJ73/ve6d6MU1J2LfSGXAtdgS5yxvpvP9zC1j3FvRRl+dkz+Oy7VxRc/rLLLjvmlL+77rqL73//+wDs2rWLl156iZaWlmPmWbJkCRdddBEAl156Ka+88sqpV/w0KrtAr09GAQW6iBxffX396Oef/vSn/OQnP+Hxxx+nrq6OVatWTXhKYDKZHP0cjUYZHBw8LXUtlrIL9IbRLpdMiWsiIpM5kZZ0sTQ2NtLb2zvhtKNHj9Lc3ExdXR3PP/88TzzxxGmu3elRdoFery4XEZlAS0sLV1xxBStXrqS2tpa2trbRaatXr+arX/0qy5Yt4/zzz+fyyy8vYU2nT9kFejwaIRmLKNBF5DXuvffeCccnk0keeuihCafl+slbW1vZvHnsSZuf+lT5PVGz7M5ygaDbpVeBLiJyjLIM9PpkTC10EZFxFOgiIhWiLAO9IRnVhUUiIuOUZaAHLXSdtigikq+MA10tdBGRfFMGupndbWYHzGzzJNPNzO4ys+1mtsnMLil+NY/VmIypy0VETklDQwMAe/bs4QMf+MCEZVatWkVHR8dxl/PFL36RgYGB0eFS3o63kBb6N4DVx5l+NbA0fK0BvnLq1To+tdBFpFjOPvtsHnjggZOef3ygl/J2vFMGurs/Bhw6TpHrgG954AmgyczOKlYFJ1KfjNE/kiGb9elcjYiUkbVr17Ju3brR4c997nP85V/+JW9729u45JJLeP3rX8+DDz74mvleeeUVVq5cCcDg4CDXX389y5Yt473vfe8x93K5+eabaW9vZ8WKFXz2s58Fght+7dmzh7e+9a289a1vBYLb8R48eBCAO++8k5UrV7Jy5Uq++MUvjq5v2bJl3HTTTaxYsYJ3vOMdxbtnjLtP+QIWA5snmfYj4E15w48A7VMt89JLL/WT9b9+tt0X/emPvGdw5KSXISLFtXXr1pKu/+mnn/Yrr7xydHjZsmW+c+dOP3r0qLu7d3V1+TnnnOPZbNbd3evr693dfceOHb5ixQp3d/+7v/s7/8hHPuLu7s8995xHo1F/8skn3d29u7vb3d3T6bS/5S1v8eeee87d3RctWuRdXV2j680Nd3R0+MqVK72vr897e3t9+fLl/vTTT/uOHTs8Go36M8884+7uH/zgB/2ee+6ZcJsm+psCHT5Jrp7WS//NbA1BtwwLFy486eWM3c8lQ2NNvCh1E5Eiemgt7Pv34i5z7uvh6s9POvniiy/mwIED7Nmzh66uLpqbm5k7dy6f/OQneeyxx4hEIuzevZv9+/czd+7cCZfx2GOP8YlPfAKACy+8kAsvvHB02v3338/69etJp9Ps3buXrVu3HjN9vF/84he8973vHb3r4/ve9z5+/vOfc+21107bbXqLEei7gQV5w/PDca/h7uuB9QDt7e0n3V/SoIdciMgEPvjBD/LAAw+wb98+PvShD/Htb3+brq4unnrqKeLxOIsXL57wtrlT2bFjB3fccQdPPvkkzc3N3HjjjSe1nJzpuk1vMQJ9A3Crmd0HvBE46u57i7DcSdUndMdFkTPacVrS0+lDH/oQN910EwcPHuRnP/sZ999/P3PmzCEej/Poo4/y6quvHnf+K6+8knvvvZerrrqKzZs3s2nTJgB6enqor69n5syZ7N+/n4ceeohVq1YBY7ftbW1tPWZZb37zm7nxxhtZu3Yt7s73v/997rnnnmnZ7pwpA93MvgOsAlrNrBP4LBAHcPevAhuBa4DtwADwkemqbI5uoSsiE1mxYgW9vb3MmzePs846iw9/+MO8+93v5vWvfz3t7e1ccMEFx53/5ptv5iMf+QjLli1j2bJlXHrppQC84Q1v4OKLL+aCCy5gwYIFXHHFFaPzrFmzhtWrV3P22Wfz6KOPjo6/5JJLuPHGG7nssssA+NjHPsbFF188rU9BsqCP/fRrb2/3qc7vnMzm3Ud51//8Bev/06W8Y8XEfWEicnpt27aNZcuWlboaFWWiv6mZPeXu7ROVL9srRQH6R9RCFxHJKdNAD54rqsfQiYiMKctAHz3LZUgtdBGRnLIM9Np4lIjpR1GRM02pfpOrRCfztyzLQDcz6hO6QZfImaSmpobu7m6FehG4O93d3dTU1JzQfGX3kOgc3aBL5Mwyf/58Ojs76erqKnVVKkJNTQ3z588/oXnKONCjOstF5AwSj8dZsmRJqatR1cqyywWgoSaus1xERPKUb6Ano+pyERHJU7aBXp9QH7qISL6yDfQGPYZOROQYZRvo9Qp0EZFjlHWgq8tFRGRM2QZ6QzJKKuMMp3Wmi4gIlHGg5z+GTkREyjHQ9zwLG/+YFo4Cup+LiEhO+QX60U741Xpast2AnisqIpJTUKCb2Woze8HMtpvZ2gmmLzKzR8xsk5n91MxO7AYEJ6K2GYBG7wPUQhcRyZky0M0sCqwDrgaWAzeY2fJxxe4AvuXuFwK3A39d7IqOCgO9IdsDqIUuIpJTSAv9MmC7u7/s7iPAfcB148osB/4l/PzoBNOLp25W8JbpBfSjqIhITiGBPg/YlTfcGY7L9xzwvvDze4FGM2s59epNIGyh16aDH0X7hlPTshoRkXJTrB9FPwW8xcyeAd4C7AZe03Q2szVm1mFmHSd9z+RYEuL1JFO5QFcLXUQECgv03cCCvOH54bhR7r7H3d/n7hcDfxaOOzJ+Qe6+3t3b3b199uzZJ1/r2mYSKZ22KCKSr5BAfxJYamZLzCwBXA9syC9gZq1mllvWp4G7i1vNcWqbiQwdIRmLKNBFREJTBrq7p4FbgYeBbcD97r7FzG43s2vDYquAF8zsRaAN+Ktpqm+grhkGDumOiyIieQp6BJ27bwQ2jhv3mbzPDwAPFLdqx1HbDAee1w26RETylN+VohAE+uDh8Ba6+lFURATKNtBnweAhGhLqQxcRySnTQG+GbJqWREp96CIiofINdGB2bEAtdBGRUHkGenj5f2ukXy10EZFQeQZ62EJvifarhS4iEirrQG+yfvpHMmSzXuIKiYiUXpkGetDlMtODOy4OpHTqoohImQZ6EwCNnruFrrpdRETKM9DDOy42ZINA1w+jIiLlGugAdbOoywRPLVILXUSknAO9tonadBDoPYMKdBGRMg70ZmrCQO/uHy5xZURESq+MA30WiZHgGRqH+kdKXBkRkdIr40BvJjJ8hGjE6O5ToIuIlHWg2+BhmmtjdKuFLiJSxoFeNwuyaRbUZzmkPnQRkcIC3cxWm9kLZrbdzNZOMH2hmT1qZs+Y2SYzu6b4VR0nvPx/fs2QulxERCgg0M0sCqwDrgaWAzeY2fJxxf6c4FmjFxM8RPrLxa7oa4SBPq9mSD+KiohQWAv9MmC7u7/s7iPAfcB148o4MCP8PBPYU7wqTiK8n8tZ8QEO9qnLRUSkkIdEzwN25Q13Am8cV+ZzwI/N7ONAPfD2otTueEYfcjFIz1CaVCZLPFq+PwmIiJyqYiXgDcA33H0+cA1wj5m9ZtlmtsbMOsyso6ur69TWmHdPdIDD6nYRkSpXSKDvBhbkDc8Px+X7KHA/gLs/DtQAreMX5O7r3b3d3dtnz559cjXOCQO9mT4ADuqHURGpcoUE+pPAUjNbYmYJgh89N4wrsxN4G4CZLSMI9FNsgk8hloBEw+gtdPXDqIhUuykD3d3TwK3Aw8A2grNZtpjZ7WZ2bVjsj4CbzOw54DvAje4+/Y8Rqm2mPryFru7nIiLVrpAfRXH3jcDGceM+k/d5K3BFcatWgNpmatJHAXQuuohUvfI+LaS2mfjwUaIRU5eLiFS9sg90GzpMc11C93MRkapX3oFeNwsGD9NSn6BbFxeJSJUr70CvbYbBw8yqi6vLRUSqXvkHejbNvLq0Al1Eql6ZB3pwP5d5ySHdz0VEql6ZB3pwtejcxNj9XEREqlV5B3p9cHeBtmjwsGjdz0VEqll5B3rDHABaCR4Wrfu5iEg1K/NAnwtAc/YQoPu5iEh1K+9Aj9dAzUwa00Gg634uIlLNyjvQARrmUjcc3NhR93MRkWpW/oHe2EZ8oEv3cxGRqlf+gd4wF+vbF97PRV0uIlK9yj/QG9ugbz8tdXF1uYhIVSv/QG9og/QQC+pT6nIRkapWAYEenLq4KNGrW+iKSFUrKNDNbLWZvWBm281s7QTTv2Bmz4avF83sSPGrOonGNgAWxHt0C10RqWpTPoLOzKLAOuA3gU7gSTPbED52DgB3/2Re+Y8DF09DXScWttDnRnvoGWplJJ0lESv/Lx4iIieqkOS7DNju7i+7+whwH3DdccrfQPCg6NMjbKHP5jAAhwfU7SIi1amQQJ8H7Mob7gzHvYaZLQKWAP9y6lUrUHIGxGpHL//XmS4iUq2K3TdxPfCAu2cmmmhma8ysw8w6urq6irNGM2hsY0Za93MRkepWSKDvBhbkDc8Px03keo7T3eLu69293d3bZ8+eXXgtp9Iwl/qR4ABxoHeoeMsVESkjhQT6k8BSM1tiZgmC0N4wvpCZXQA0A48Xt4oFaJhDcigI9H09CnQRqU5TBrq7p4FbgYeBbcD97r7FzG43s2vzil4P3OfuPj1VPY7GuUT6DjCjJsa+owp0EalOU562CODuG4GN48Z9Ztzw54pXrRPU0AbDR1k0I6JAF5GqVRknbDcG56Kf3zCgLhcRqVqVEejhxUWvS/aqhS4iVasyAj28uGhhopeuvmFSmWyJKyQicvpVRqCPXv5/FHc40Kt7uohI9amMQK9rgUiMVoJ7gqnbRUSqUWUEeiQC9XNoynQDCnQRqU6VEegADXOoHzkI6OIiEalOlRPojXOJDRygJh5h39HBUtdGROS0q5xAb2jD+vYzd0YNe9XlIiJVqHICvXEu9B/k7Blx9qvLRUSqUOUEekMb4CytG1ALXUSqUuUEenj5/5Kafg70DJPNnv57hImIlFLlBHp4cdGC+FFGMlkO6VF0IlJlKifQZ84H4Cx0LrqIVKfKCfSGORCroTWzD1Cgi0j1qZxAN4OZ85kxtBeAvTrTRUSqTEGBbmarzewFM9tuZmsnKfNbZrbVzLaY2b3FrWaBmhaS7O8kGjH2q4UuIlVmyicWmVkUWAf8JtAJPGlmG9x9a16ZpcCngSvc/bCZzZmuCh9X00Js7ybaGpM6dVFEqk4hLfTLgO3u/rK7jwD3AdeNK3MTsM7dDwO4+4HiVrNATQth4CALZ8C+Hl3+LyLVpZBAnwfsyhvuDMflOw84z8z+1cyeMLPVxargCWlaBMDy2iP6UVREqk6xfhSNAUuBVcANwD+YWdP4Qma2xsw6zKyjq6urSKvO07QQgHMShxToIlJ1Cgn03cCCvOH54bh8ncAGd0+5+w7gRYKAP4a7r3f3dndvnz179snWeXIzg2ouihykfyRD71Cq+OsQETlDFRLoTwJLzWyJmSWA64EN48r8gKB1jpm1EnTBvFzEehamoQ2iCeaGXfhqpYtINZky0N09DdwKPAxsA+539y1mdruZXRsWexjoNrOtwKPAH7t793RVelKRCMxcQHNqP4DOdBGRqjLlaYsA7r4R2Dhu3GfyPjvwh+GrtJoW0tC/B4C9etCFiFSRyrlSNKdpIYm+TmIR49XugVLXRkTktKnAQF+A9XdxbnOUV7r7S10bEZHTpgIDPTgX/ZKZPew4qBa6iFSPCgz04Fz0FXVHebW7n6B7X0Sk8lVsoJ+TOMTASIYDvcMlrpCIyOlReYHeMBcicc4muBL1lYPqRxeR6lB5gR6JQNMCWsJz0fXDqIhUi8oLdICZC6gb2E08avphVESqRmUGetNC7MhOFsyqU5eLiFSNCg30RdB/gPOaY+pyEZGqUaGBHpzpcuGMXl7p7ieb1amLIlL5KjrQz0seZiiVZX+vbtIlIpWvMgO9ObhadIkFZ7rsUD+6iFSBygz0xrOgZiZtQ78G0E26RKQqVGagm0HbSuqPvEAiFtGZLiJSFSoz0AHaVmAHtrKouUZdLiJSFSo40FfCSB+XzuzVqYsiUhUKCnQzW21mL5jZdjNbO8H0G82sy8yeDV8fK35VT1DbSgDaazp5tXtApy6KSMWbMtDNLAqsA64GlgM3mNnyCYp+190vCl9fK3I9T9ycCwDjPHYynM6yt0enLopIZSukhX4ZsN3dX3b3EeA+4LrprVYRJOph1uuYN/wyoLsuikjlKyTQ5wG78oY7w3Hjvd/MNpnZA2a2oCi1O1VzVzKz90VA56KLSOUr1o+iPwQWu/uFwD8D35yokJmtMbMOM+vo6uoq0qqPo20l0SOv0FaTZsuenulfn4hICRUS6LuB/Bb3/HDcKHfvdvfco4G+Blw60YLcfb27t7t7++zZs0+mviembQWGc03bYZ7ZeXj61yciUkKFBPqTwFIzW2JmCeB6YEN+ATM7K2/wWmBb8ap4CtpWAHBFwz5e3N9L33C6xBUSEZk+Uwa6u6eBW4GHCYL6fnffYma3m9m1YbFPmNkWM3sO+ARw43RV+IQ0LYJEI8siu8g6bOo8UuoaiYhMm1ghhdx9I7Bx3LjP5H3+NPDp4latCMygbQVtgy8B8MzOI/yHc1pLXCkRkelRuVeK5rStINa1jde11vHMTrXQRaRyVX6gz10Jwz1cNXeEZ3cdwV1XjIpIZar8QA9vAXDFjH0c7Bum8/BgiSskIjI9Kj/Q5ywDi7DSw370Xep2EZHKVPmBnmyEBW+kdc9PqY1HdT66iFSsyg90gPNWY/v/nVVnjeiHURGpWFUT6ADX1W1m654ehtOZEldIRKT4qiPQZ58PTYu4ZPiXjGSyuq+LiFSk6gh0Mzj/amYfeIIahnn6VfWji0jlqY5ABzjvP2KZIT7QvJ1Hth0odW1ERIquegJ90Zsg0cBvzdjKEzu62a8nGIlIhameQI8l4JyrWN73OO7OjzbtLXWNRESKqnoCHeC81cT693HtnC5++NyeUtdGRKSoqivQl74DMG5s3sSzu46ws3ug1DUSESma6gr0htlw/jVctO8faWCAH25SK11EKkd1BTrAlZ8iMnyEta3/yoZnFegiUjmqL9DnXQLnvp0PDP+Anfu7eGFfb6lrJCJSFAUFupmtNrMXzGy7ma09Trn3m5mbWXvxqjgNrvwTalKH+e3Yo3z/md1TlxcRKQNTBrqZRYF1wNXAcuAGM1s+QblG4Dbgl8WuZNEtfCMsfjMfT27ku4+/SHffcKlrJCJyygppoV8GbHf3l919BLgPuG6Ccn8B/A1QHlfsvOVPaMp0c13mJ/z9o9tLXRsRkVNWSKDPA3blDXeG40aZ2SXAAnf/f0Ws2/Ra/GZY8hY+nbyfXzzxS3Yd0imMIlLeTvlHUTOLAHcCf1RA2TVm1mFmHV1dXae66lNjBu/5CvFEDV+I3cVdP95c2vqIiJyiQgJ9N7Agb3h+OC6nEVgJ/NTMXgEuBzZM9MOou69393Z3b589e/bJ17pYZs4j8p51rLQdnL/5Tp7fp9vqikj5KiTQnwSWmtkSM0sA1wMbchPd/ai7t7r7YndfDDwBXOvuHdNS42K74J0MX/JRPhZ7iAe/+3XSmWypayQiclKmDHR3TwO3Ag8D24D73X2Lmd1uZtdOdwVPh+TV/50jMy7gtkN/xQPf+XqpqyMiclLM3Uuy4vb2du/oOIMa8f0H2f331zBnYDvPtf817e/+/VLXSETkNczsKXef8Fqf6rtSdDL1rcz5+I95IbmCSzr+lP0P3wElOtiJiJwMBXqeeF0Tc27+IT+LXEbb439B39feDUd1JamIlAcF+jhzmpuY9/sP8D9iv0+k81ek1l0Oz94LWf1YKiJnNgX6BM6bO4Pf/fjt3DLjLjYNzYUf3Iz/wyp4+WelrpqIyKQU6JOYO7OGL93yfr6w4Ev8wch/5VDXXvjWtfCt98D2R9S/LiJnHAX6ccyoifPNj/4GK1bfxKqhO7iT32Fw9yb4P++DdW+EX/0DDBwqdTVFRACdtliwl7v6+NPvbeK5Vw7wn5ue5ubkj5l5dBtE4nDu22Dl++Hct0PdrFJXVUQq2PFOW1Sgn4Bs1nl4yz6+8JMXeXF/L1e3HuDW1mdZ1v1jIr17AQseoHHOVbDwN2B+O9TMLHW1RaSCKNCLLJN1frRpD+sfe5kte3qoTxg3n3uEd9VvY+Ghx4nseQo8CxjMWQ5nXQhtK6BtJbSeBzPODm4OJiJyghTo08Td2dR5lHt/uZMfbdpD/0iGGTUx3nleA+9q2cNFvEB91zOwbzP07RubMV4PLefArNfBrCXQvBhmzIfGudB4VtBto8AXKYw7ZEYgmwE8GM6mID0C6aGwcRXKZoJx6WFID8JIP4z0BWXz5x3uC8anBsZOgPBsMH82FbybAeH/02wKMmnIDAfLzoyE76lwWgo8EyzLs3Dx78Bv3HJSm6tAPw2GUhl+/tJB/mnzPh55fj9HBlIAnN/WyKWLm3njnCzttXs5K7WLyKHtcPAlOPwKHNkZ7PB80QQ0zA0CvmEO1LVAfSvUtQaf61qgthlqm6CmKejWicZO/0ZL5ckFTjYdvNJhQKWHgpDKvbKZYwNutNxwGGpDQUjmz5NJjS03mw7nTY8txzOQGswL3OGJ58ukwnWMBO+Zken7e0QTYBFGgzsah0gMItHw7xUeLCLxoGw0BrGa4HMsGbxHYsF8Fg3mM4ML3g1v+NBJVUmBfpplss7WPT38fHsXj/+6m2d3HqF3OA1AbTzKBWc1suLsGZzX1si5rbWcV9dLS+Yg1rsPeveGr/BzXxcMHISB7mNbGuPF6yA5A2pmBO/JxrFXogGSDZCoD74dJOqC8vG64HOsFuLhK5YM/kHm3qMJfVs4Udls0LLLDy0Y+zumh4KWYWog74K1sJWZGgpajvlBekwLMx3MNzIQhJn72DpyoZtrGY6GbzqvpZgO30fGlp8eCVud6bG6Fp3lhWE8CLZcMFoUIpHgPV4b/vurgVgCosljQ9SiwfhYTTAtlgiDNBGGrAV/50g8/DecDObJ/Y0jsbx/4zXB/41EfbCc/HmTDcG0XHCfQRToJZbNOi8f7OOZnUfYsqeHrXt72LanZzTkAeoTURa21LNoVh3zm2uZ11zL2U21nD2zlrYZSVrq40SHj8LgYeg/GLwPHYWhIzB4BIZ7guHhHhjuDV5DPcHXxuE+GOk9/gFhUhb8J8tvcYy+4mPvuVZIJDbuP2p0bJxFwvFhiyd/2MadQWuW1zLyievuPtaiHP/KzXPM9Ny/dR9rWWbSY1+FGbes/K/Q2UwYOpGg7Ehf8DdODR7bAst9hWe6/19ZEEi5v18kOq5lmAxai/ktx0gsb3/F8w7cyWO3IRrPC8+8YD1m/8fG9tvosvLKxWqC5eTqkmuZyik7XqDre/ppEIkY585p5Nw5jXwwHOfu7O8Z5qUDvWw/0Mer3QPsPDTASwd6efSFAwynjw2waMRoqU/Q2pCktTFJa/1cWhoW0tKQZFZDguY5CZrr4jTVJWiqizOzNk48mheS7kEwpQbC1uFg8Dk1EH4eHPu6mxkOW4rhKzWY1/LL+wqda9nlvhKnh/K+HodfoY/5Wp3O6+fMC85sdlxg+7EBO3oAsGO3xyJj/Zi5Fl7+gcAsHBfJK5vbKdEw7OLHLueYg0w0aKXVtQSBl+saMAu/9TQGB7tseqwbIveNKFE/9nU7EhmrM4Qtw7rg21Ik779gND7WQs0/iEZiY/NGosE3q1hSASmvoUAvETNj7swa5s6s4c1Lj316k7tzqH+E3UcG2Xd0iP09Q+zrGeJg7wgH+4Y52DfMy119HOwbZig1eau7PhGlsSbOjNpY8F4TY0ZtnBk1ceqTMRprGqhPzKQ+GaMhGaO+JkZ9MkZdIkp9IkZdMniviUcwhYfIGU+BfgYyM1oakrQ0JLlw/uTl3J3+kQyH+0c4PDDC4YEURwZGODqY4nB/iqODKXqHUvQOpekZSnGwb4SXD/bTM5iibzhNKlNYt0DEgr7/2kSUmniUukSUukSM+mSU2niM2kSU2niE2niUmkQ0eI9HqWhQlPcAAAf7SURBVIlFqMmbL39c8Ao+J8NxiWiESEQHDpGTpUAvY2ZGQ9i6XjCr7oTnH05n6BtK0z+coW84Tf9Imv7hNIMjwfBgKkP/cIaBkTRDqQwDIxkGRzLB+JEM/cNpDvcPjk4bSgfTx3cXnYhELEIyFiEZC4I+Gc/7HIuQDIM/GY+QDN8T0QiJWCScNxp8PmZcMBwPxwXvduxwOD0eNeJ55aM6wEgZKSjQzWw18CUgCnzN3T8/bvp/AW4BMkAfsMbdtxa5rlJkyViUZEOUlobiLjeTdYbTGYZSWQZTGYbyXoMj2dFpQ6ngIJD7PJLOMpwOP2eyDKeyDKUzDKeCeYZTWY4OpsJyY+VHwtdwOkO2yL9FRgxiYeDHokYsEoR+NGKjgR+LGLGohQeE8KAQjRCLREanBe/BtGAZY8uJRYxIZKxMLPwcDT/nygTvkXBdNrr8aN4rFokQiUAsEhkbb0YkwuhwPDK2LbmyEUPdahVgykA3syiwDvhNoBN40sw2jAvse939q2H5a4E7gdXTUF8pA9GIUZeIUZc4/etOZ7KMZLKk0s5wJpMX9llSmeAVfHZS6bBsJiiTzjojYbncMtLZYz+nMk46kyWTddLZsXGZrI8ufyiVpXcoTToTTA/eg/lSufdMUD63nDNB7gATtfDgEB6w4nmfj51+7PDoASNX1oxoNHgfPSDlHaTMGC0Tzz8AveYgFhzwIjbxukenRSAaHuQiYbmIMXqwzC03YrkXo8PRvDrl1hPJjSMYNzotXO6ZeAAspIV+GbDd3V8GMLP7gOuA0UB395688vVM/zlbIhOKRSPEohFIAMRLXZ2CZSc4QKSzQeDnXsFBITgQ5A4Q+dMy7mTCg0fWxw4iWYes5y8jOMhkcuMyTiYbLvOY9WXDA1W4LofMaJ0YnSdXfjidHVfXLBn30W3LLSuTDesU1jl/GeUkd0CKhN+Act90Rg8auQNOeFDJHYDM4IbLFvKxN7+u6HUqJNDnAbvyhjuBN44vZGa3AH9I8F/pqqLUTqRKRCJGImIkqviO1h4eYHIHmkzeQcB9bHw2C6nwm0/Ww1eWvANUcCBxZ2x54YEut5zRA0o4PZv10QNfNm/92XA5TrAsD+fNTQvK8pp5jn0fO3jl1jG7MTktf8Oi/Sjq7uuAdWb228CfA783voyZrQHWACxcuLBYqxaRCmAW/t5Q6oqUsUKaA7uBBXnD88Nxk7kPeM9EE9x9vbu3u3v77NmzJyoiIiInqZBAfxJYamZLzCwBXA9syC9gZkvzBt8JvFS8KoqISCGm/Hbj7mkzuxV4mOC0xbvdfYuZ3Q50uPsG4FYzezuQAg4zQXeLiIhMr4K6q9x9I7Bx3LjP5H2+rcj1EhGRE1S9P6mLiFQYBbqISIVQoIuIVAgFuohIhSjZE4vMrAt49SRnbwUOFrE65aIat7satxmqc7urcZvhxLd7kbtPeCFPyQL9VJhZx2SPYKpk1bjd1bjNUJ3bXY3bDMXdbnW5iIhUCAW6iEiFKNdAX1/qCpRINW53NW4zVOd2V+M2QxG3uyz70EVE5LXKtYUuIiLjlF2gm9lqM3vBzLab2dpS12c6mNkCM3vUzLaa2RYzuy0cP8vM/tnMXgrfm0td1+lgZlEze8bMfhQOLzGzX4b7/LvhXT8rhpk1mdkDZva8mW0zs9+ohn1tZp8M/31vNrPvmFlNJe5rM7vbzA6Y2ea8cRPuXwvcFW7/JjO75ETWVVaBnvd806uB5cANZra8tLWaFmngj9x9OXA5cEu4nWuBR9x9KfBIOFyJbgO25Q3/DfAFdz+X4G6eHy1JrabPl4B/cvcLgDcQbHtF72szmwd8Amh395UEd3K9nsrc19/gtc9Ynmz/Xg0sDV9rgK+cyIrKKtDJe76pu48QPEzjuhLXqejcfa+7Px1+7iX4Dz6PYFu/GRb7JpM8SKScmdl8gnvqfy0cNoJHGj4QFqmo7TazmcCVwNcB3H3E3Y9QBfua4G6vtWYWA+qAvVTgvnb3x4BD40ZPtn+vA77lgSeAJjM7q9B1lVugT/R803klqstpYWaLgYuBXwJt7r43nLQPaCtRtabTF4E/AbLhcAtwxN3T4XCl7fMlQBfwv8Nupq+ZWT0Vvq/dfTdwB7CTIMiPAk9R2fs632T795QyrtwCvaqYWQPwPeAP3L0nf5oHpydV1ClKZvYu4IC7P1XqupxGMeAS4CvufjHQz7julQrd180ErdElwNlAPa/tlqgKxdy/5RboJ/p807JlZnGCMP+2u/9jOHp/7utX+H6gVPWbJlcA15rZKwTdaVcR9C83hV/LofL2eSfQ6e6/DIcfIAj4St/Xbwd2uHuXu6eAfyTY/5W8r/NNtn9PKePKLdCnfL5pJQj7jb8ObHP3O/MmbWDs8X6/Bzx4uus2ndz90+4+390XE+zbf3H3DwOPAh8Ii1XUdrv7PmCXmZ0fjnobsJUK39cEXS2Xm1ld+O89t90Vu6/HmWz/bgB+Nzzb5XLgaF7XzNTcvaxewDXAi8CvgT8rdX2maRvfRPAVbBPwbPi6hqA/+RGCh3D/BJhV6rpO499gFfCj8PPrgF8B24H/CyRLXb8ib+tFQEe4v38ANFfDvgb+G/A8sBm4B0hW4r4GvkPwO0GK4BvZRyfbv4ARnMn3a+DfCc4CKnhdulJURKRClFuXi4iITEKBLiJSIRToIiIVQoEuIlIhFOgiIhVCgS4iUiEU6CIiFUKBLiJSIf4/ADexJTfKRmwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  73.47715997695923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f67902cbb00>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.0680 - acc: 0.5145 - val_loss: 0.9240 - val_acc: 0.6151\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92405, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8357 - acc: 0.6767 - val_loss: 0.7592 - val_acc: 0.7239\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.92405 to 0.75922, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6927 - acc: 0.7636 - val_loss: 0.6379 - val_acc: 0.7832\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.75922 to 0.63785, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5819 - acc: 0.8116 - val_loss: 0.5448 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63785 to 0.54483, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4996 - acc: 0.8403 - val_loss: 0.4814 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54483 to 0.48143, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4458 - acc: 0.8559 - val_loss: 0.4409 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48143 to 0.44088, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4118 - acc: 0.8642 - val_loss: 0.4137 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44088 to 0.41367, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3897 - acc: 0.8674 - val_loss: 0.3951 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41367 to 0.39514, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3748 - acc: 0.8695 - val_loss: 0.3826 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39514 to 0.38258, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3643 - acc: 0.8710 - val_loss: 0.3737 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38258 to 0.37366, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3565 - acc: 0.8718 - val_loss: 0.3669 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37366 to 0.36689, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3503 - acc: 0.8726 - val_loss: 0.3616 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36689 to 0.36164, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3455 - acc: 0.8732 - val_loss: 0.3575 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36164 to 0.35746, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3416 - acc: 0.8737 - val_loss: 0.3543 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35746 to 0.35425, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3384 - acc: 0.8739 - val_loss: 0.3516 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.35425 to 0.35158, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3357 - acc: 0.8742 - val_loss: 0.3495 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.35158 to 0.34949, saving model to Post_val_weights3.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3334 - acc: 0.8747 - val_loss: 0.3477 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34949 to 0.34769, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3316 - acc: 0.8746 - val_loss: 0.3463 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34769 to 0.34634, saving model to Post_val_weights3.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3299 - acc: 0.8745 - val_loss: 0.3450 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34634 to 0.34501, saving model to Post_val_weights3.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8745 - val_loss: 0.3440 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34501 to 0.34401, saving model to Post_val_weights3.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3273 - acc: 0.8748 - val_loss: 0.3431 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34401 to 0.34306, saving model to Post_val_weights3.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3262 - acc: 0.8749 - val_loss: 0.3423 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.34306 to 0.34228, saving model to Post_val_weights3.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8749 - val_loss: 0.3416 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34228 to 0.34157, saving model to Post_val_weights3.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8751 - val_loss: 0.3409 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34157 to 0.34088, saving model to Post_val_weights3.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8752 - val_loss: 0.3403 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34088 to 0.34029, saving model to Post_val_weights3.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8750 - val_loss: 0.3398 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34029 to 0.33975, saving model to Post_val_weights3.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8753 - val_loss: 0.3393 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33975 to 0.33930, saving model to Post_val_weights3.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8752 - val_loss: 0.3389 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33930 to 0.33891, saving model to Post_val_weights3.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8755 - val_loss: 0.3386 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33891 to 0.33864, saving model to Post_val_weights3.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8755 - val_loss: 0.3382 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33864 to 0.33819, saving model to Post_val_weights3.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8753 - val_loss: 0.3379 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33819 to 0.33791, saving model to Post_val_weights3.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8755 - val_loss: 0.3376 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33791 to 0.33762, saving model to Post_val_weights3.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8755 - val_loss: 0.3374 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33762 to 0.33739, saving model to Post_val_weights3.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8756 - val_loss: 0.3372 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33739 to 0.33723, saving model to Post_val_weights3.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8757 - val_loss: 0.3372 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33723 to 0.33717, saving model to Post_val_weights3.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8757 - val_loss: 0.3369 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33717 to 0.33691, saving model to Post_val_weights3.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8757 - val_loss: 0.3368 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33691 to 0.33681, saving model to Post_val_weights3.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8759 - val_loss: 0.3366 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33681 to 0.33663, saving model to Post_val_weights3.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8763 - val_loss: 0.3365 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33663 to 0.33652, saving model to Post_val_weights3.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8761 - val_loss: 0.3364 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33652 to 0.33643, saving model to Post_val_weights3.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8763 - val_loss: 0.3365 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33643\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8763 - val_loss: 0.3363 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33643 to 0.33630, saving model to Post_val_weights3.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8762 - val_loss: 0.3363 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33630 to 0.33629, saving model to Post_val_weights3.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8763 - val_loss: 0.3362 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33629 to 0.33621, saving model to Post_val_weights3.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8764 - val_loss: 0.3362 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33621\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8765 - val_loss: 0.3362 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33621\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3133 - acc: 0.8767 - val_loss: 0.3363 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33621\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8769 - val_loss: 0.3363 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33621\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8769 - val_loss: 0.3364 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33621\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8771 - val_loss: 0.3365 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33621\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8772 - val_loss: 0.3365 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33621\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8773 - val_loss: 0.3366 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33621\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8773 - val_loss: 0.3368 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33621\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8774 - val_loss: 0.3368 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33621\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8773 - val_loss: 0.3369 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33621\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8774 - val_loss: 0.3371 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33621\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8776 - val_loss: 0.3374 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33621\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8776 - val_loss: 0.3376 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33621\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8776 - val_loss: 0.3379 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33621\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8777 - val_loss: 0.3380 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33621\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8777 - val_loss: 0.3382 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33621\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8777 - val_loss: 0.3385 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33621\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8779 - val_loss: 0.3386 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33621\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8777 - val_loss: 0.3388 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33621\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8778 - val_loss: 0.3391 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33621\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8782 - val_loss: 0.3392 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33621\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8781 - val_loss: 0.3396 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33621\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8781 - val_loss: 0.3395 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33621\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8783 - val_loss: 0.3399 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33621\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8785 - val_loss: 0.3399 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33621\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8785 - val_loss: 0.3401 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33621\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8788 - val_loss: 0.3401 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33621\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8789 - val_loss: 0.3403 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33621\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8787 - val_loss: 0.3405 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33621\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8790 - val_loss: 0.3406 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33621\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8790 - val_loss: 0.3408 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33621\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8790 - val_loss: 0.3409 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33621\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8790 - val_loss: 0.3409 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33621\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8791 - val_loss: 0.3411 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33621\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8790 - val_loss: 0.3412 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33621\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8791 - val_loss: 0.3414 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33621\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8792 - val_loss: 0.3415 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33621\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8793 - val_loss: 0.3416 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33621\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8793 - val_loss: 0.3419 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33621\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8794 - val_loss: 0.3419 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33621\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8795 - val_loss: 0.3421 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33621\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8797 - val_loss: 0.3422 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33621\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3050 - acc: 0.8796 - val_loss: 0.3425 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33621\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8798 - val_loss: 0.3424 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33621\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8797 - val_loss: 0.3426 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33621\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8799 - val_loss: 0.3428 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33621\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8799 - val_loss: 0.3431 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33621\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8800 - val_loss: 0.3432 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33621\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8801 - val_loss: 0.3434 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33621\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8801 - val_loss: 0.3435 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33621\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8804 - val_loss: 0.3436 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33621\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8805 - val_loss: 0.3438 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33621\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8805 - val_loss: 0.3440 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33621\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8804 - val_loss: 0.3440 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33621\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8806 - val_loss: 0.3443 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33621\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 4096\n",
      "Fold: 2\n",
      "best val loss: 0.3362120342394065\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  76.9073052406311\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.0688 - acc: 0.5144 - val_loss: 0.9277 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92768, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8362 - acc: 0.6748 - val_loss: 0.7628 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.92768 to 0.76276, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6932 - acc: 0.7626 - val_loss: 0.6376 - val_acc: 0.7858\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76276 to 0.63760, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5833 - acc: 0.8110 - val_loss: 0.5396 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63760 to 0.53960, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5014 - acc: 0.8396 - val_loss: 0.4721 - val_acc: 0.8498\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53960 to 0.47205, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4473 - acc: 0.8549 - val_loss: 0.4305 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47205 to 0.43050, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4130 - acc: 0.8633 - val_loss: 0.4047 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43050 to 0.40466, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3908 - acc: 0.8668 - val_loss: 0.3872 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.40466 to 0.38722, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3759 - acc: 0.8691 - val_loss: 0.3749 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38722 to 0.37492, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3653 - acc: 0.8706 - val_loss: 0.3662 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37492 to 0.36625, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3574 - acc: 0.8714 - val_loss: 0.3597 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36625 to 0.35968, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3513 - acc: 0.8722 - val_loss: 0.3547 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35968 to 0.35470, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3464 - acc: 0.8725 - val_loss: 0.3508 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35470 to 0.35075, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3425 - acc: 0.8729 - val_loss: 0.3476 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35075 to 0.34764, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3393 - acc: 0.8733 - val_loss: 0.3450 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34764 to 0.34495, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3368 - acc: 0.8733 - val_loss: 0.3430 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34495 to 0.34295, saving model to Post_val_weights4.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3345 - acc: 0.8736 - val_loss: 0.3411 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34295 to 0.34108, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3326 - acc: 0.8736 - val_loss: 0.3396 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34108 to 0.33961, saving model to Post_val_weights4.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3309 - acc: 0.8738 - val_loss: 0.3382 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33961 to 0.33822, saving model to Post_val_weights4.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8739 - val_loss: 0.3371 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33822 to 0.33708, saving model to Post_val_weights4.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8739 - val_loss: 0.3362 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33708 to 0.33615, saving model to Post_val_weights4.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3271 - acc: 0.8739 - val_loss: 0.3353 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33615 to 0.33527, saving model to Post_val_weights4.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3261 - acc: 0.8739 - val_loss: 0.3345 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33527 to 0.33452, saving model to Post_val_weights4.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3251 - acc: 0.8741 - val_loss: 0.3339 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33452 to 0.33390, saving model to Post_val_weights4.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8741 - val_loss: 0.3333 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33390 to 0.33330, saving model to Post_val_weights4.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3235 - acc: 0.8743 - val_loss: 0.3328 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33330 to 0.33279, saving model to Post_val_weights4.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8742 - val_loss: 0.3323 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33279 to 0.33233, saving model to Post_val_weights4.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8743 - val_loss: 0.3319 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33233 to 0.33195, saving model to Post_val_weights4.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8744 - val_loss: 0.3316 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33195 to 0.33160, saving model to Post_val_weights4.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8744 - val_loss: 0.3313 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33160 to 0.33125, saving model to Post_val_weights4.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8745 - val_loss: 0.3310 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33125 to 0.33098, saving model to Post_val_weights4.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8747 - val_loss: 0.3307 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33098 to 0.33072, saving model to Post_val_weights4.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8748 - val_loss: 0.3307 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33072 to 0.33067, saving model to Post_val_weights4.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8748 - val_loss: 0.3303 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33067 to 0.33029, saving model to Post_val_weights4.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8749 - val_loss: 0.3303 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33029\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8749 - val_loss: 0.3303 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33029 to 0.33025, saving model to Post_val_weights4.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8749 - val_loss: 0.3299 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33025 to 0.32992, saving model to Post_val_weights4.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8751 - val_loss: 0.3300 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.32992\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8752 - val_loss: 0.3300 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.32992\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8753 - val_loss: 0.3297 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.32992 to 0.32975, saving model to Post_val_weights4.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8756 - val_loss: 0.3298 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.32975\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8756 - val_loss: 0.3299 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.32975\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8758 - val_loss: 0.3297 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.32975 to 0.32965, saving model to Post_val_weights4.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8758 - val_loss: 0.3298 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.32965\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8760 - val_loss: 0.3301 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.32965\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8760 - val_loss: 0.3299 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.32965\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8761 - val_loss: 0.3299 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.32965\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3132 - acc: 0.8762 - val_loss: 0.3303 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.32965\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8761 - val_loss: 0.3300 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.32965\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8763 - val_loss: 0.3303 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.32965\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8763 - val_loss: 0.3306 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.32965\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8763 - val_loss: 0.3307 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.32965\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8763 - val_loss: 0.3308 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32965\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8764 - val_loss: 0.3309 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.32965\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8765 - val_loss: 0.3314 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.32965\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8768 - val_loss: 0.3314 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.32965\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8768 - val_loss: 0.3315 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32965\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8767 - val_loss: 0.3317 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.32965\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8768 - val_loss: 0.3320 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.32965\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8769 - val_loss: 0.3321 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.32965\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8770 - val_loss: 0.3323 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.32965\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8771 - val_loss: 0.3325 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32965\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8772 - val_loss: 0.3330 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32965\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8774 - val_loss: 0.3332 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.32965\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8774 - val_loss: 0.3333 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32965\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8775 - val_loss: 0.3335 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.32965\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8776 - val_loss: 0.3336 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.32965\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8776 - val_loss: 0.3340 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.32965\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8777 - val_loss: 0.3341 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32965\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8778 - val_loss: 0.3344 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.32965\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8779 - val_loss: 0.3347 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.32965\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8779 - val_loss: 0.3347 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.32965\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8779 - val_loss: 0.3351 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.32965\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8781 - val_loss: 0.3353 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.32965\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8782 - val_loss: 0.3356 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.32965\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8782 - val_loss: 0.3358 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.32965\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8783 - val_loss: 0.3361 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32965\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8783 - val_loss: 0.3364 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.32965\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8784 - val_loss: 0.3366 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32965\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8785 - val_loss: 0.3369 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32965\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8787 - val_loss: 0.3372 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32965\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8788 - val_loss: 0.3374 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.32965\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8788 - val_loss: 0.3378 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.32965\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8790 - val_loss: 0.3378 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.32965\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8791 - val_loss: 0.3384 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32965\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3055 - acc: 0.8790 - val_loss: 0.3386 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.32965\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8792 - val_loss: 0.3387 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.32965\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8793 - val_loss: 0.3389 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.32965\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3051 - acc: 0.8792 - val_loss: 0.3393 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32965\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3050 - acc: 0.8794 - val_loss: 0.3394 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.32965\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8794 - val_loss: 0.3397 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.32965\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8796 - val_loss: 0.3398 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.32965\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8796 - val_loss: 0.3401 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32965\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8797 - val_loss: 0.3403 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.32965\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8797 - val_loss: 0.3405 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32965\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8798 - val_loss: 0.3406 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.32965\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8796 - val_loss: 0.3408 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32965\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8799 - val_loss: 0.3410 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32965\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8798 - val_loss: 0.3412 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32965\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8800 - val_loss: 0.3412 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32965\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 4096\n",
      "Fold: 3\n",
      "best val loss: 0.32965048246913486\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  75.51373052597046\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.0689 - acc: 0.5152 - val_loss: 0.9261 - val_acc: 0.6015\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92605, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8365 - acc: 0.6737 - val_loss: 0.7578 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.92605 to 0.75783, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6927 - acc: 0.7630 - val_loss: 0.6342 - val_acc: 0.7906\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.75783 to 0.63415, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5816 - acc: 0.8121 - val_loss: 0.5403 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63415 to 0.54030, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4993 - acc: 0.8404 - val_loss: 0.4780 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54030 to 0.47801, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4456 - acc: 0.8559 - val_loss: 0.4388 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47801 to 0.43881, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4119 - acc: 0.8635 - val_loss: 0.4128 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43881 to 0.41284, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3897 - acc: 0.8676 - val_loss: 0.3951 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41284 to 0.39512, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3747 - acc: 0.8697 - val_loss: 0.3828 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39512 to 0.38284, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3641 - acc: 0.8713 - val_loss: 0.3738 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38284 to 0.37385, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3562 - acc: 0.8722 - val_loss: 0.3673 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37385 to 0.36728, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3501 - acc: 0.8729 - val_loss: 0.3620 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36728 to 0.36204, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3452 - acc: 0.8733 - val_loss: 0.3580 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36204 to 0.35800, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3414 - acc: 0.8735 - val_loss: 0.3544 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35800 to 0.35436, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3382 - acc: 0.8740 - val_loss: 0.3521 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.35436 to 0.35211, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3356 - acc: 0.8743 - val_loss: 0.3495 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.35211 to 0.34953, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3334 - acc: 0.8745 - val_loss: 0.3481 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34953 to 0.34814, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3316 - acc: 0.8745 - val_loss: 0.3463 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34814 to 0.34630, saving model to Post_val_weights5.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3300 - acc: 0.8746 - val_loss: 0.3450 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34630 to 0.34502, saving model to Post_val_weights5.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8746 - val_loss: 0.3439 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34502 to 0.34386, saving model to Post_val_weights5.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3274 - acc: 0.8748 - val_loss: 0.3427 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34386 to 0.34267, saving model to Post_val_weights5.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8747 - val_loss: 0.3418 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.34267 to 0.34178, saving model to Post_val_weights5.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3253 - acc: 0.8748 - val_loss: 0.3410 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34178 to 0.34097, saving model to Post_val_weights5.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3245 - acc: 0.8747 - val_loss: 0.3402 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34097 to 0.34019, saving model to Post_val_weights5.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3237 - acc: 0.8749 - val_loss: 0.3398 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34019 to 0.33984, saving model to Post_val_weights5.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8750 - val_loss: 0.3391 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33984 to 0.33912, saving model to Post_val_weights5.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8749 - val_loss: 0.3385 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33912 to 0.33848, saving model to Post_val_weights5.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8748 - val_loss: 0.3381 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33848 to 0.33812, saving model to Post_val_weights5.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8748 - val_loss: 0.3377 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33812 to 0.33771, saving model to Post_val_weights5.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8750 - val_loss: 0.3372 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33771 to 0.33724, saving model to Post_val_weights5.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8750 - val_loss: 0.3371 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33724 to 0.33711, saving model to Post_val_weights5.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8750 - val_loss: 0.3367 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33711 to 0.33669, saving model to Post_val_weights5.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8752 - val_loss: 0.3362 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33669 to 0.33623, saving model to Post_val_weights5.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8753 - val_loss: 0.3361 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33623 to 0.33607, saving model to Post_val_weights5.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8753 - val_loss: 0.3357 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33607 to 0.33572, saving model to Post_val_weights5.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8753 - val_loss: 0.3356 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33572 to 0.33560, saving model to Post_val_weights5.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8753 - val_loss: 0.3353 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33560 to 0.33528, saving model to Post_val_weights5.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8756 - val_loss: 0.3354 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33528\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8756 - val_loss: 0.3348 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33528 to 0.33483, saving model to Post_val_weights5.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8756 - val_loss: 0.3356 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33483\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8757 - val_loss: 0.3348 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33483 to 0.33476, saving model to Post_val_weights5.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8758 - val_loss: 0.3347 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33476 to 0.33472, saving model to Post_val_weights5.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8759 - val_loss: 0.3345 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33472 to 0.33455, saving model to Post_val_weights5.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8762 - val_loss: 0.3347 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33455\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8765 - val_loss: 0.3346 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33455\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8767 - val_loss: 0.3347 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33455\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3140 - acc: 0.8768 - val_loss: 0.3344 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33455 to 0.33442, saving model to Post_val_weights5.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8768 - val_loss: 0.3348 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33442\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8769 - val_loss: 0.3345 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33442\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8769 - val_loss: 0.3347 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33442\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8772 - val_loss: 0.3345 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33442\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8775 - val_loss: 0.3346 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33442\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8777 - val_loss: 0.3348 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33442\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8777 - val_loss: 0.3348 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33442\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8778 - val_loss: 0.3349 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33442\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8778 - val_loss: 0.3350 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33442\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8780 - val_loss: 0.3351 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33442\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8778 - val_loss: 0.3352 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33442\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8778 - val_loss: 0.3354 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33442\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8778 - val_loss: 0.3356 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33442\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8779 - val_loss: 0.3357 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33442\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8780 - val_loss: 0.3360 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33442\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8780 - val_loss: 0.3361 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33442\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8780 - val_loss: 0.3363 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33442\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8781 - val_loss: 0.3366 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33442\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8782 - val_loss: 0.3367 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33442\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8784 - val_loss: 0.3368 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33442\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8784 - val_loss: 0.3371 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33442\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8787 - val_loss: 0.3373 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33442\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8788 - val_loss: 0.3375 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33442\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8790 - val_loss: 0.3379 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33442\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8791 - val_loss: 0.3378 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33442\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8792 - val_loss: 0.3381 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33442\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8793 - val_loss: 0.3382 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33442\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8792 - val_loss: 0.3384 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33442\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8791 - val_loss: 0.3387 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33442\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8791 - val_loss: 0.3389 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33442\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8791 - val_loss: 0.3391 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33442\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8792 - val_loss: 0.3394 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33442\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8795 - val_loss: 0.3394 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33442\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8794 - val_loss: 0.3399 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33442\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8792 - val_loss: 0.3399 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33442\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8792 - val_loss: 0.3401 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33442\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8793 - val_loss: 0.3404 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33442\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8794 - val_loss: 0.3406 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33442\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8795 - val_loss: 0.3409 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33442\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8795 - val_loss: 0.3409 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33442\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8794 - val_loss: 0.3414 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33442\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8796 - val_loss: 0.3413 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33442\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8796 - val_loss: 0.3419 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33442\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8799 - val_loss: 0.3417 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33442\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3051 - acc: 0.8800 - val_loss: 0.3421 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33442\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3050 - acc: 0.8799 - val_loss: 0.3420 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33442\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8801 - val_loss: 0.3423 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33442\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8801 - val_loss: 0.3424 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33442\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8800 - val_loss: 0.3427 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33442\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8802 - val_loss: 0.3429 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33442\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8805 - val_loss: 0.3431 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33442\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8807 - val_loss: 0.3432 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33442\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8806 - val_loss: 0.3436 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33442\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 4096\n",
      "Fold: 4\n",
      "best val loss: 0.3344200807844686\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXhc9X3v8fd3Fs1osyXb8oLlLYTgDYNBcWhIAmQ1JIGQFZqnLXkSfMsNJc1ye52nfUJKep/Q2yRNeEqauoQmoSGUmqa4uSbcJoGQ3EBqYZaAzWJsjGVjW5Ztydo1M9/7xzkjjWTZGtsjj2fm83qeeTTnnN+c8z0a6XN+c+Ys5u6IiEjpixS7ABERKQwFuohImVCgi4iUCQW6iEiZUKCLiJQJBbqISJmYMNDN7C4z229mzx5j+mIze8zMBszsC4UvUURE8pFPD/17wOrjTD8I3Ax8rRAFiYjIyYlN1MDdHzWzhceZvh/Yb2bvPZEFz5gxwxcuPOZsRURkHE888cQBd28ab9qEgT5ZFi5cSGtra7EWLyJSksxs57GmndYvRc1sjZm1mllre3v76Vy0iEjZO62B7u7r3L3F3Vuamsb9xCAiIidJhy2KiJSJCfehm9mPgMuAGWbWBtwCxAHc/TtmNhtoBaYAGTP7U2Cpu3dNWtUicsYZGhqira2N/v7+YpdSFpLJJM3NzcTj8bxfk89RLtdNMH0v0Jz3EkWkLLW1tVFfX8/ChQsxs2KXU9LcnY6ODtra2li0aFHer9MuFxEpiP7+fqZPn64wLwAzY/r06Sf8aUeBLiIFozAvnJP5XZZcoD+/t4uvPfQCB3sGi12KiJxBDh8+zLe//e0Tft2VV17J4cOHJ6Gi06/kAn1Hew9/9/A29nbqixcRGXGsQE+lUsd93caNG2loaJissk6rop0perJqE0HJPYPHf5NEpLKsXbuWl19+mQsuuIB4PE4ymaSxsZHnn3+eF198kQ984APs2rWL/v5+PvOZz7BmzRpg5Kz17u5urrjiCt7ylrfwm9/8hrlz5/LAAw9QXV1d5DXLX8n10LOB3j2gQBeREbfddhtnn302Tz31FH/zN3/D5s2b+da3vsWLL74IwF133cUTTzxBa2srt99+Ox0dHUfN46WXXuLTn/40zz33HA0NDdx///2nezVOScn10OuyPXQFusgZ6y//4zm27CnsqShLz5rCLe9flnf7VatWjTrk7/bbb+fHP/4xALt27eKll15i+vTpo16zaNEiLrjgAgAuuugiXnnllVMv/DQquUCvTUQBBbqIHF9tbe3w80ceeYSf/exnPPbYY9TU1HDZZZeNe0hgIpEYfh6NRunr6zsttRZKyQV63fAul3SRKxGRYzmRnnSh1NfXc+TIkXGndXZ20tjYSE1NDc8//zyPP/74aa7u9Ci5QK/VLhcRGcf06dO55JJLWL58OdXV1cyaNWt42urVq/nOd77DkiVLOPfcc7n44ouLWOnkKblAj0cjJGIRBbqIHOWee+4Zd3wikeDBBx8cd1p2P/mMGTN49tmRO21+4Quld0fNkjvKBYLdLkcU6CIio5RkoNcmYuqhi4iMoUAXESkTJRnodYmoTiwSERmjJAM96KHrsEURkVwlHOjqoYuI5Jow0M3sLjPbb2bPHmO6mdntZrbNzJ4xswsLX+ZodVUx7XIRkVNSV1cHwJ49e/jwhz88bpvLLruM1tbW487nm9/8Jr29vcPDxbwcbz499O8Bq48z/QrgnPCxBvj7Uy/r+OqS6qGLSGGcddZZrF+//qRfPzbQi3k53gkD3d0fBQ4ep8nVwA888DjQYGZzClXgeGoTMXoG02QyPpmLEZESsnbtWu64447h4S9/+cv81V/9Fe94xzu48MILOe+883jggQeOet0rr7zC8uXLAejr6+Paa69lyZIlXHPNNaOu5XLjjTfS0tLCsmXLuOWWW4Dggl979uzh8ssv5/LLLweCy/EeOHAAgG984xssX76c5cuX881vfnN4eUuWLOGGG25g2bJlvPvd7y7cNWPcfcIHsBB49hjTfgK8JWf450DLRPO86KKL/GT9wy+3+YL/+RPv6hs86XmISGFt2bKlqMvfvHmzv+1tbxseXrJkib/66qve2dnp7u7t7e1+9tlneyaTcXf32tpad3ffsWOHL1u2zN3dv/71r/snPvEJd3d/+umnPRqN+qZNm9zdvaOjw93dU6mUX3rppf7000+7u/uCBQu8vb19eLnZ4dbWVl++fLl3d3f7kSNHfOnSpb5582bfsWOHR6NRf/LJJ93d/SMf+Yjffffd467TeL9ToNWPkaun9dR/M1tDsFuG+fPnn/R8Rq7nkqY+GS9IbSJSQA+uhb2/K+w8Z58HV9x2zMkrV65k//797Nmzh/b2dhobG5k9ezaf/exnefTRR4lEIuzevZt9+/Yxe/bscefx6KOPcvPNNwOwYsUKVqxYMTztvvvuY926daRSKV577TW2bNkyavpYv/71r7nmmmuGr/r4wQ9+kF/96ldcddVVk3aZ3kIE+m5gXs5wczjuKO6+DlgH0NLSctL7S+p0kwsRGcdHPvIR1q9fz969e/nYxz7GD3/4Q9rb23niiSeIx+MsXLhw3MvmTmTHjh187WtfY9OmTTQ2NnL99def1HyyJusyvYUI9A3ATWZ2L/AmoNPdXyvAfI+ptkpXXBQ5ox2nJz2ZPvaxj3HDDTdw4MABfvnLX3Lfffcxc+ZM4vE4Dz/8MDt37jzu69/2trdxzz338Pa3v51nn32WZ555BoCuri5qa2uZOnUq+/bt48EHH+Syyy4DRi7bO2PGjFHzeutb38r111/P2rVrcXd+/OMfc/fdd0/KemdNGOhm9iPgMmCGmbUBtwBxAHf/DrARuBLYBvQCn5isYrN0CV0RGc+yZcs4cuQIc+fOZc6cOXz84x/n/e9/P+eddx4tLS0sXrz4uK+/8cYb+cQnPsGSJUtYsmQJF110EQDnn38+K1euZPHixcybN49LLrlk+DVr1qxh9erVnHXWWTz88MPD4y+88EKuv/56Vq1aBcCnPvUpVq5cOal3QbJgH/vp19LS4hMd33ksv2vr5P1/92vW/cFFvHvZ+PvCROT02rp1K0uWLCl2GWVlvN+pmT3h7i3jtS/JM0XrkmEPfVA9dBGRrJIM9Ox9RXUbOhGRESUZ6HXahy4icpSSDPTqeJSIQXe/Al3kTFKs7+TK0cn8Lksy0M2MWl2gS+SMkkwm6ejoUKgXgLvT0dFBMpk8odeV3E2is3QJXZEzS3NzM21tbbS3txe7lLKQTCZpbm4+odeUcKBHdZSLyBkkHo+zaNGiYpdR0UpylwsEX4zqKBcRkRGlG+i6JrqIyCglG+i1VQp0EZFcJRvowS4XBbqISFbJBrqOchERGa2kA109dBGREaUX6Ls3w4ababLDDKWdgZSOdBERgVIM9K49sPn7zPBDQHAbOhERKcVAr24EYKp1A7pAl4hIVukGugeBrv3oIiKBvALdzFab2Qtmts3M1o4zfYGZ/dzMnjGzR8zsxC5AcCJqpgFQl+kC1EMXEcmaMNDNLArcAVwBLAWuM7OlY5p9DfiBu68AbgW+WuhChyUbAKhJHwHUQxcRycqnh74K2Obu2919ELgXuHpMm6XAL8LnD48zvXDiSYjXUJ3O9tD1paiICOQX6HOBXTnDbeG4XE8DHwyfXwPUm9n0Uy/vGKobSQx1AtrlIiKSVagvRb8AXGpmTwKXAruBo7rOZrbGzFrNrPWUrplc3UjVYBDoRxToIiJAfoG+G5iXM9wcjhvm7nvc/YPuvhL483Dc4bEzcvd17t7i7i1NTU0nX3V1I9HBYPbqoYuIBPIJ9E3AOWa2yMyqgGuBDbkNzGyGmWXn9UXgrsKWOUZ1A5G+w1TFIgp0EZHQhIHu7ingJuAhYCtwn7s/Z2a3mtlVYbPLgBfM7EVgFvC/JqneQHUj9B2iXtdzEREZltct6Nx9I7BxzLgv5TxfD6wvbGnHEQZ6bVVUPXQRkVDpnSkKUD0N0gNMS6R1GzoRkVCJBnpw+v+seK966CIioZIO9JmxXnoGFegiIlDigT492qsvRUVEQqUd6NZDd78CXUQESjzQG6xH+9BFREIlHujd9AymyWS8yAWJiBRfaQZ6vBqiCeo9uIRu75AOXRQRKc1AN4PqRuoyQaBrt4uISKkGOkB1o25yISKSo3QDvWYayZRuQyciklW6gV7dSCIVXBO9q0+BLiJSwoHeMHyTi46egSIXIyJSfCUc6I3EBoKbXBzsGSxyMSIixVfSgW6pPqptUIEuIkKJBzrA/OpBOhToIiLlEOgDHOxWoIuI5BXoZrbazF4ws21mtnac6fPN7GEze9LMnjGzKwtf6hhhoM9N9GuXi4gIeQS6mUWBO4ArgKXAdWa2dEyzvyC41+hKgptIf7vQhR4lDPQ5iT4d5SIiQn499FXANnff7u6DwL3A1WPaODAlfD4V2FO4Eo+hehoAM2N92ocuIkJ+N4meC+zKGW4D3jSmzZeB/2tmfwLUAu8sSHXHM3yTix4O9w6RSmeIRUv3KwERkVNVqAS8DvieuzcDVwJ3m9lR8zazNWbWamat7e3tp7bEqlqIxGm0HgAO9Q6d2vxEREpcPoG+G5iXM9wcjsv1SeA+AHd/DEgCM8bOyN3XuXuLu7c0NTWdXMVZ4RUXp9AN6OQiEZF8An0TcI6ZLTKzKoIvPTeMafMq8A4AM1tCEOin2AXPQ3UjteEldPXFqIhUugkD3d1TwE3AQ8BWgqNZnjOzW83sqrDZ54EbzOxp4EfA9e4++bcRqm6kOrzionroIlLp8vlSFHffCGwcM+5LOc+3AJcUtrQ8VDeSOBx8X9uhk4tEpMKV9mEh1Y1EBw5jhg5dFJGKV/KBbn2HaaiOc1D70EWkwpV8oDPYzcwa0z50Eal4pR3oNdkLdA1pH7qIVLzSDvTsBbqSukCXiEhZBPpZVb0KdBGpeKUd6LUzAZgT7eJg7yDpzOQf+i4icqYq7UCvmwVAk3XiDod71UsXkcpV2oFeMx0iMab5IUBni4pIZSvtQI9EoHYmU9MHAZ1cJCKVrbQDHaBuJrWDBwD10EWkspV+oNfPJtEfXNhRPXQRqWSlH+h1M4n1hYHerdP/RaRylUGgz8Z62mlMRrTLRUQqWukHev0s8Axn1+hm0SJS2Uo/0MNj0Rcluzmo67mISAUrg0CfDcC8qiPa5SIiFS2vQDez1Wb2gpltM7O140z/WzN7Kny8aGaHC1/qMdQFp//PjXVql4uIVLQJb0FnZlHgDuBdQBuwycw2hLedA8DdP5vT/k+AlZNQ6/jCXS4zrZNDvYNkMk4kYqdt8SIiZ4p8euirgG3uvt3dB4F7gauP0/46ghtFnx7xJCQbmO6HSGeczr6h07ZoEZEzST6BPhfYlTPcFo47ipktABYBvzj10k5A3SwaMsH1XLTbRUQqVaG/FL0WWO/u6fEmmtkaM2s1s9b29vbCLbV+lk7/F5GKl0+g7wbm5Qw3h+PGcy3H2d3i7uvcvcXdW5qamvKvciJ1s6geCAL9gM4WFZEKlU+gbwLOMbNFZlZFENobxjYys8VAI/BYYUvMQ90s4n3tgLOvq/+0L15E5EwwYaC7ewq4CXgI2Arc5+7PmdmtZnZVTtNrgXvd/fTfNqh+NpbqY1psgL0KdBGpUBMetgjg7huBjWPGfWnM8JcLV9YJCg9dXFLXw95OBbqIVKbSP1MUhgP9nOpeBbqIVKzyCPT64PT/hclu7XIRkYpVHoEenv7fHOtkb2c/xdiNLyJSbOUR6MkGiCaYGelkIJXhcK/OFhWRylMegW4GdbOYFp4tqt0uIlKJyiPQAepnMSV9EFCgi0hlKp9Ar5tF9UBwOQEd6SIilaisAj3Wux8zBbqIVKbyCfT62VjfIebURhToIlKRyifQw0MXF9f1aR+6iFSkMgr04OSi19f06AJdIlKRyifQ64PT/xdWdfGadrmISAUqn0CfOh+AedEOOvuG6Bsc9x4bIiJlq3wCvWYaxGuZndkH6Fh0Eak85RPoZtC4gGlDewEduigilad8Ah2gYT51fcHd8fZ29RW5GBGR0yuvQDez1Wb2gpltM7O1x2jzUTPbYmbPmdk9hS0zTw3zqepuA5y9nbq3qIhUlgnvWGRmUeAO4F1AG7DJzDa4+5acNucAXwQucfdDZjZzsgo+roYF2MAR5iYHdOiiiFScfHroq4Bt7r7d3QeBe4Grx7S5AbjD3Q8BuPv+wpaZp4bgSJcVtZ281qldLiJSWfIJ9LnArpzhtnBcrjcAbzCz/2dmj5vZ6kIVeEIaFwCwOHmQvV3a5SIilaVQX4rGgHOAy4DrgH80s4axjcxsjZm1mllre3t7gRadI+yhvy7WwV710EWkwuQT6LuBeTnDzeG4XG3ABncfcvcdwIsEAT+Ku69z9xZ3b2lqajrZmo+tuhESU2m2dtqPDJBKZwq/DBGRM1Q+gb4JOMfMFplZFXAtsGFMm38n6J1jZjMIdsFsL2Cd+WuYz8z0PjIO7d3a7SIilWPCQHf3FHAT8BCwFbjP3Z8zs1vN7Kqw2UNAh5ltAR4G/oe7d0xW0cfVMJ+pA68BOrlIRCrLhIctArj7RmDjmHFfynnuwOfCR3E1LqDm5V8ArkMXRaSilNeZogAN84mk+pjGEdoO6YtREakcZRjowaGLS5IH2XGgp8jFiIicPmUY6MGhi+fXd/FKhwJdRCpH2Qb6kuRBXjnQW+RiREROn/IL9OQUqG5kQbSDPZ199A/pRhciUhnKL9ABGhYwK7MPd3j1oHrpIlIZyjTQR45F1xejIlIpyjbQEz27AecVBbqIVIjyDPTGhViqnzfU9OpIFxGpGOUZ6OGRLhdO7dIuFxGpGGUa6MHJRctrDunQRRGpGOUZ6NMWQSTGYmtjb1c/fYM6dFFEyl95BnosAU2LmT+4DUD70UWkIpRnoAPMXsG0I8+jI11EpFKUb6DPWUGs7wBNHGaHeugiUgHKN9BnrwDgzTW71UMXkYpQxoF+HgAX17TpSBcRqQh5BbqZrTazF8xsm5mtHWf69WbWbmZPhY9PFb7UE5ScAo2LWBbZqV0uIlIRJgx0M4sCdwBXAEuB68xs6ThN/8XdLwgfdxa4zpMzZwULBrfRfmSA7oFUsasREZlU+fTQVwHb3H27uw8C9wJXT25ZBTJ7BVP7d1NPr/aji0jZyyfQ5wK7cobbwnFjfcjMnjGz9WY2ryDVnao55wOw1HbqWHQRKXuF+lL0P4CF7r4C+E/g++M1MrM1ZtZqZq3t7e0FWvRxhEe6LIu+wrb93ZO/PBGRIson0HcDuT3u5nDcMHfvcPeBcPBO4KLxZuTu69y9xd1bmpqaTqbeE1M/C+pmcXH1bp589fDkL09EpIjyCfRNwDlmtsjMqoBrgQ25DcxsTs7gVcDWwpV4imav4LzoTp7adZhMxotdjYjIpJkw0N09BdwEPEQQ1Pe5+3NmdquZXRU2u9nMnjOzp4Gbgesnq+ATNmcFswZ20tfXy3Z9MSoiZSyWTyN33whsHDPuSznPvwh8sbClFcjs84h4ijfYLja/eojXz6wrdkUiIpOifM8UzQq/GH1j4lXtRxeRslb+gd64CGpnsrrmBZ589VCxqxERmTTlH+iRCJy7mgsGWtm+7xBH+oeKXZGIyKQo/0AHOPdKEuke3mhbeaats9jViIhMisoI9EWX4rEk74xsZvNO7XYRkfJUGYFeVYO97nKuiD/J5p0Hi12NiMikqIxABzj3Cmb7fo7segZ3nWAkIuWncgL9DasBeNPgf7FDJxiJSBmqnECvn0XfzAt4V/QJNut4dBEpQ5UT6EBi2fu4IPIyT219vtiliIgUXEUFemTxlcHPFx+id1B3MBKR8lJRgc7MpfRNPZsP85/8bMu+YlcjIlJQlRXoZiTeejMrIjt44fGNE7cXESkhlRXoQOT8a+mOT2PVnrs51DNY7HJERAqm4gKdeJKe8z/JpZGn+c1jvyx2NSIiBVN5gQ7MfPt/p48kdU98p9iliIgUTEUGutVM44WzruHNvQ+zd9fLxS5HRKQg8gp0M1ttZi+Y2TYzW3ucdh8yMzezlsKVODlmvOuzGE77g18tdikiIgUxYaCbWRS4A7gCWApcZ2ZLx2lXD3wG+G2hi5wMzYvO5ed172PZnvX0bftVscsRETll+fTQVwHb3H27uw8C9wJXj9PuK8BfA/0FrG9SzfrgV9mVaWJg/R/DoK7vIiKlLZ9AnwvsyhluC8cNM7MLgXnu/n8KWNuku+DsZv61+Ys09LfR9+CXJn6BiMgZ7JS/FDWzCPAN4PN5tF1jZq1m1tre3n6qiy6ID3zgI/xT6j1UP3kn7Hi02OWIiJy0fAJ9NzAvZ7g5HJdVDywHHjGzV4CLgQ3jfTHq7uvcvcXdW5qamk6+6gJ6/cx6tp//eXb4bNL/8oewb0uxSxIROSn5BPom4BwzW2RmVcC1wIbsRHfvdPcZ7r7Q3RcCjwNXuXvrpFQ8CT797vNZk17LkaEI/oOr4cBLxS5JROSETRjo7p4CbgIeArYC97n7c2Z2q5ldNdkFng6zpyb56Lsv5UO9a+kbTMH33w8Htxe7LBGRE2LFuh1bS0uLt7aeOZ14d+emHz3J9md/y4a624jHYvChO+Hsy4tdmojIMDN7wt3HPdenIs8UHY+Z8b8/tIJM0zI+OnQLQ8lpcPc18MhtkEkXuzwRkQkp0HPUJmL8wx9cxMs+l6sHvkLP4g/BI1+F770P9jxV7PJERI5LgT7Gwhm1fPf6N9LWY1y+7Vp2X/p1OPACrLsU7r8BDr9a7BJFRMalQB/HGxdOY/2NbyYajbD6kXk89t6fw1s+C1s3wO0r4f5Pwe7NxS5TRGQUBfoxvGFWPfff+GbmNCT5/X/ewlf6P0r/H/8XrPpv8MJP4R8vhzvfCb9dB0d0OzsRKT4d5TKBnoEUtz34PHc/vpOF02v46w+t4E1nxeHJf4Yn74b9WwCDBZfA4vfC4iuhcWGxyxaRMnW8o1wU6Hn6zbYD/Nn9z9B2qI/Lz23ic+86l/Oap8L+5+G5H8OWB6B9a9B4xrkw90KYvQJmnwdnXQCJ+uKugIiUBQV6gfQOpvjeb17hH365nc6+Id65ZBZ/9OYFXHL2DCIRC05GeuFBePlh2Ps76N4bvNAi0LQkCPlpr4OpzcFj+uuhtgnMirtiIlIyFOgF1tU/xHd/tYMfPPYKh3qHWDi9hmtXzed9K+bQ3Fgz0rB7P7z2NLS1wu5W2PMk9HaMnllyKkw/BxrmwZS5UD8H6mdD3azgZ/1s9e5FykUmDUN9QSevqmbi9uNQoE+S/qE0P312Lz/87U42vXIIgBXNU3nPstlc+oYmls6ZEvTccw32QOfu4PDHjm1w4EXoeCkY17UHUn1HLyheGwR7bRPUTIeaRqhuhGRD8LO6IXzeAIkpEK2CWBLiSaiqh4i++5YzWHooCLnUAHgmHOnB+EwqeKQHg+npIfB0EIyeDoZTA8H04dcCqX4Y7IXB7mB8JAoWDdoNdgf/h+khiMSCae6QHhhZhkWCBz4y/+wyPBMsP5MK2qYHR//MpEbX6BnIZIKaMkNBfW/5HLzzlpP6dSnQT4OdHT389Nm9bHx2L0/vOgxAQ02c33vddC5a0MjK+Y0sO2sKyXj02DNxh/7DcGRv8OjeN/Kza0/Qu+89CH0Hoe9Q8AcyIYPkFEhMDXr6iTqoqgsCPxYGfywJ8erwZ03wPF498sduUYglxm8TjQfTI7HgeSwB0UQ4XruSTop7EAbZEMmkwnDIhEERDqeHwhDKDZt0TuiEw8OBkxs2qdGhlBoIOhOpgWD5ZoCF7bKvTY8Oq+F5ZMMst20438zQ6PHDNWQAHwns0ykSC/4HovGR0IXwfyERTHcf2UDk/k1HoiNhH4kFnadoPPxZldMmOvLTIsHzWAJi1UFHq/mNsODNJ1W+Av0029/Vz29e7uDX2w7w2Msd7D4c9LrjUeP1M+tZOmcKS+bU8/qZdbxuRh1zG6uJju3J52OoP9gA9B2CvsPB84Hu8J+8P+j19HdBfycMdMHAkeAx2B3+Aw+M/kce6i38P1c27GOJ4A8+Eh0JHItAVe3Ip4j+rqDOof5gV1T2E4dFgoDJ/UeKREf3gCwy8s+Dj0yz6Mg/WiYd/F7Sg8E/bDT8h4SRgIJw/rFgXtngGe6VpUf3BHOnZddr7GNUGOeGcrb3mRodlBTnf5JIPAg1s+D3gwe/50g8DKqcDXz2dxSJhNOrRtpE4+G42OjX5rYZfj+jIx2EWGJkQwIj84nEgs7HqNdHRt7b7DTL6SzFEsHfVrxm9N9KtCqYVsIU6EW2v6ufJ3cd5qldh9myp4str3XRfmRgeHpVNMK8adUsmF7Lguk1zG2o5qyGauZMTTJnajUz6qqIRU/TbpPsx9+hvtG9uVTORiL3kcnpuQ33GPtHh19mKOxFDgTjsr2cTCr8WNwTtElODQI8loSBzmAjNdAV9pY8JyDDunJDfDhA04CNBE/2Y3l6KAifWDLobcFIzxJGAgpG90QtEswvd0NiY96L3F6b5fbgIuOPj2Y3GNHRQTkcVJGRIBwOtZz5ZGuNxoJ1iWU/EeUuO3d52TCMjbx2eNnZDW4yeC5nvOMFeux0F1OJZk5J8p5ls3nPstnD4w50D7DjQA/b27vZfqCHnQd62Xmwl8e3d9A7OPpiYBGDpvoEM+uTzKiroqk+wfS6BNNqqphWGzymVMeZmvOoip3kBiAbIskpp7LKIlIECvQimVGXYEZdgjcunDZqvLvT2TfE7sN9vHa4n71d/ezr6mdvZz/t3QO0dw+w9bUjdPQMMJQ+9qer2qooU6rj1CZi1CZi1CdiTKmOUZ+IU58MxtWF02oTUWqqYtRWRamuilKbiFEdj1ITPk/EIpj2h4uc8RToZxgzo6GmioaaKpadNfWY7dydIwMpDnYPcqh3kM6+oZFH7xCHeofo6h+iZyBF90CKnoEU+7r66eof4kh/6qhPAccTMUjEoiTjEZLxIPRrqqLUxGMkq6IkY+H4cFoyHrTNviYRi1JdFSEZC6YlYhES4fhELPwZj1AVjVAVCx6xiGkjInKCFOglygW0R3IAAAfsSURBVMyYkowzJRlnIbUn/Pp0xukdTNEzkKZnMEXfYJrugeBn72CanoEUvYMpeofS9A6k6R9KM5DK0DeUDh6DaXoHU3T2DbE/HNcfju8fyjCYzkxcxASqohHiURveCCTjURLDzyPEoxES4QYgEYtSFY0ctWGoigXDiVjQvir8GY8asUiEWNSG2ydi0XC6Db8uHo0QD8fFI5GjD0MVOYPkFehmthr4FhAF7nT328ZM/2Pg00Aa6AbWuLvutnwGi0aM+mSc+mR8UuafzjiDqQz9Q2n6U0HI94fBP5jKMJDKMBBuJIJHMD77GEpnGMo4A0PBtP6hDP2p9PDwwFCGI0MpOlLBxiP7uv6c+aQyhf/CPxYx4tFgQxCPBp8ksuFfFRsZH49EiMeCjcbwBiQaIR6xkTbh66PhxiIaseF2sYiF07KvCcdFg/ERyz4P5xFOi0YiRM1ylj3SNhoZ2YhlXxO14Kc+DZWHCQPdzKLAHcC7gDZgk5ltGBPY97j7d8L2VwHfAFZPQr1SIqIRozrcJ18s6YwzlA42GMMbiXT2uZPKBD+z43LbDaYyDKQzpNLZ1/moeWRfn0r7qA1KKlxmKmzfnU4zlMqMapsKlzmUzgQ1ZpxUOsMkbH/yFg03ILGIEcluILIbjnBcbMyGJbsxGP2IDL8uGoFY+KkmljPPkZ/BxiViRsQYtZxIzvJHzd/C+sKN1Nj6su0iZhjBJ9mIQSQS/rSR6bltY0etR87vYsxrIsYZuwHMp4e+Ctjm7tsBzOxe4GpgONDdvSunfS1FO5BWZETwjxk9/slcZ5BMxkllwg1Fxkmlg6Affh6OT4eP4HmwcUnnjM9uKLIbj7TntM/Ob5z5ZJeTzjgZD8ZnjmoXzD87Pds+7c7gYJq0p4fXI53JhPOCVCYTnCyZyakp7QyF47PzKyW5mT6yoYocvQEKNyjZYTO4btV8PvXW1xW8pnwCfS6wK2e4DXjT2EZm9mngc0AV8PaCVCdSQSIRoypiVFXwbQoymZENUHZDkQ43AJmcjcqoDY4HG5bsuHQ43gk2FDhknOF5ZMbOP2ejlTvf3I1etg4n+OSXe/5OdlywscvOI5Mzz5H1ynhQU1P95JzcVLAvRd39DuAOM/t94C+APxrbxszWAGsA5s+fX6hFi0iZiESMCEaJfKg64+TTFdgNzMsZbg7HHcu9wAfGm+Du69y9xd1bmpqa8q9SREQmlE+gbwLOMbNFZlYFXAtsyG1gZufkDL4XeKlwJYqISD4m3OXi7ikzuwl4iOCwxbvc/TkzuxVodfcNwE1m9k5gCDjEOLtbRERkcuW1D93dNwIbx4z7Us7zzxS4LhEROUGV+3W6iEiZUaCLiJQJBbqISJlQoIuIlImi3bHIzNqBnSf58hnAgQKWUyoqcb0rcZ2hMte7EtcZTny9F7j7uCfyFC3QT4WZtR7rFkzlrBLXuxLXGSpzvStxnaGw661dLiIiZUKBLiJSJko10NcVu4AiqcT1rsR1hspc70pcZyjgepfkPnQRETlaqfbQRURkjJILdDNbbWYvmNk2M1tb7Homg5nNM7OHzWyLmT1nZp8Jx08zs/80s5fCn43FrnUymFnUzJ40s5+Ew4vM7Lfhe/4v4VU/y4aZNZjZejN73sy2mtnvVcJ7bWafDf++nzWzH5lZshzfazO7y8z2m9mzOePGfX8tcHu4/s+Y2YUnsqySCvSc+5teASwFrjOzpcWtalKkgM+7+1LgYuDT4XquBX7u7ucAPw+Hy9FngK05w38N/K27v57gap6fLEpVk+dbwE/dfTFwPsG6l/V7bWZzgZuBFndfTnAl12spz/f6exx9j+Vjvb9XAOeEjzXA35/Igkoq0Mm5v6m7DxLcTOPqItdUcO7+mrtvDp8fIfgHn0uwrt8Pm32fY9xIpJSZWTPBNfXvDIeN4JaG68MmZbXeZjYVeBvwXQB3H3T3w1TAe01wtddqM4sBNcBrlOF77e6PAgfHjD7W+3s18AMPPA40mNmcfJdVaoE+3v1N5xapltPCzBYCK4HfArPc/bVw0l5gVpHKmkzfBP4MyITD04HD7p4Kh8vtPV8EtAP/FO5mutPMainz99rddwNfA14lCPJO4AnK+73Odaz395QyrtQCvaKYWR1wP/Cn7t6VO82Dw5PK6hAlM3sfsN/dnyh2LadRDLgQ+Ht3Xwn0MGb3Spm+140EvdFFwFlALUfvlqgIhXx/Sy3QT/T+piXLzOIEYf5Dd/+3cPS+7Mev8Of+YtU3SS4BrjKzVwh2p72dYP9yQ/ixHMrvPW8D2tz9t+HweoKAL/f3+p3ADndvd/ch4N8I3v9yfq9zHev9PaWMK7VAn/D+puUg3G/8XWCru38jZ9IGRm7v90fAA6e7tsnk7l9092Z3X0jw3v7C3T8OPAx8OGxWVuvt7nuBXWZ2bjjqHcAWyvy9JtjVcrGZ1YR/79n1Ltv3eoxjvb8bgD8Mj3a5GOjM2TUzMXcvqQdwJfAi8DLw58WuZ5LW8S0EH8GeAZ4KH1cS7E/+OcFNuH8GTCt2rZP4O7gM+En4/HXAfwHbgH8FEsWur8DregHQGr7f/w40VsJ7Dfwl8DzwLHA3kCjH9xr4EcH3BEMEn8g+eaz3FzCCI/leBn5HcBRQ3svSmaIiImWi1Ha5iIjIMSjQRUTKhAJdRKRMKNBFRMqEAl1EpEwo0EVEyoQCXUSkTCjQRUTKxP8Hhi65Nq7wx0EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  76.29154253005981\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.1469 - acc: 0.4693 - val_loss: 1.0315 - val_acc: 0.5241\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03152, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.9770 - acc: 0.5660 - val_loss: 0.9036 - val_acc: 0.6199\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03152 to 0.90358, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8634 - acc: 0.6563 - val_loss: 0.8104 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.90358 to 0.81041, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7764 - acc: 0.7161 - val_loss: 0.7353 - val_acc: 0.7342\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81041 to 0.73525, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7031 - acc: 0.7577 - val_loss: 0.6703 - val_acc: 0.7715\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73525 to 0.67035, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6384 - acc: 0.7872 - val_loss: 0.6124 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67035 to 0.61241, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5814 - acc: 0.8113 - val_loss: 0.5613 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61241 to 0.56127, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5325 - acc: 0.8293 - val_loss: 0.5178 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56127 to 0.51779, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4924 - acc: 0.8417 - val_loss: 0.4826 - val_acc: 0.8425\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51779 to 0.48255, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4605 - acc: 0.8514 - val_loss: 0.4551 - val_acc: 0.8511\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48255 to 0.45509, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4360 - acc: 0.8575 - val_loss: 0.4340 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.45509 to 0.43402, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4169 - acc: 0.8625 - val_loss: 0.4175 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43402 to 0.41751, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4019 - acc: 0.8655 - val_loss: 0.4043 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.41751 to 0.40428, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3900 - acc: 0.8673 - val_loss: 0.3937 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40428 to 0.39367, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3804 - acc: 0.8689 - val_loss: 0.3854 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.39367 to 0.38544, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3727 - acc: 0.8700 - val_loss: 0.3789 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38544 to 0.37888, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3664 - acc: 0.8709 - val_loss: 0.3734 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37888 to 0.37342, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3612 - acc: 0.8717 - val_loss: 0.3688 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37342 to 0.36882, saving model to Post_val_weights1.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3567 - acc: 0.8721 - val_loss: 0.3649 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36882 to 0.36493, saving model to Post_val_weights1.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3528 - acc: 0.8725 - val_loss: 0.3616 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36493 to 0.36158, saving model to Post_val_weights1.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3494 - acc: 0.8729 - val_loss: 0.3587 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36158 to 0.35867, saving model to Post_val_weights1.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3465 - acc: 0.8732 - val_loss: 0.3561 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35867 to 0.35610, saving model to Post_val_weights1.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3439 - acc: 0.8734 - val_loss: 0.3538 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35610 to 0.35385, saving model to Post_val_weights1.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3416 - acc: 0.8735 - val_loss: 0.3519 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35385 to 0.35185, saving model to Post_val_weights1.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3396 - acc: 0.8737 - val_loss: 0.3501 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35185 to 0.35007, saving model to Post_val_weights1.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3379 - acc: 0.8742 - val_loss: 0.3486 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35007 to 0.34857, saving model to Post_val_weights1.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3363 - acc: 0.8743 - val_loss: 0.3471 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34857 to 0.34708, saving model to Post_val_weights1.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3349 - acc: 0.8741 - val_loss: 0.3458 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34708 to 0.34585, saving model to Post_val_weights1.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3336 - acc: 0.8741 - val_loss: 0.3446 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34585 to 0.34464, saving model to Post_val_weights1.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3324 - acc: 0.8742 - val_loss: 0.3436 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34464 to 0.34361, saving model to Post_val_weights1.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3313 - acc: 0.8742 - val_loss: 0.3426 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34361 to 0.34264, saving model to Post_val_weights1.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3304 - acc: 0.8743 - val_loss: 0.3418 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.34264 to 0.34180, saving model to Post_val_weights1.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8743 - val_loss: 0.3410 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.34180 to 0.34101, saving model to Post_val_weights1.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3287 - acc: 0.8743 - val_loss: 0.3404 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.34101 to 0.34035, saving model to Post_val_weights1.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3279 - acc: 0.8744 - val_loss: 0.3397 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34035 to 0.33967, saving model to Post_val_weights1.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3272 - acc: 0.8745 - val_loss: 0.3391 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33967 to 0.33907, saving model to Post_val_weights1.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3266 - acc: 0.8745 - val_loss: 0.3385 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33907 to 0.33848, saving model to Post_val_weights1.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3259 - acc: 0.8746 - val_loss: 0.3380 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33848 to 0.33795, saving model to Post_val_weights1.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3254 - acc: 0.8746 - val_loss: 0.3374 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33795 to 0.33744, saving model to Post_val_weights1.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8747 - val_loss: 0.3370 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33744 to 0.33697, saving model to Post_val_weights1.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8750 - val_loss: 0.3365 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33697 to 0.33652, saving model to Post_val_weights1.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8750 - val_loss: 0.3361 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33652 to 0.33611, saving model to Post_val_weights1.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8750 - val_loss: 0.3357 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33611 to 0.33571, saving model to Post_val_weights1.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8751 - val_loss: 0.3353 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33571 to 0.33535, saving model to Post_val_weights1.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3225 - acc: 0.8752 - val_loss: 0.3350 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33535 to 0.33501, saving model to Post_val_weights1.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3222 - acc: 0.8753 - val_loss: 0.3347 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33501 to 0.33470, saving model to Post_val_weights1.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8752 - val_loss: 0.3345 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33470 to 0.33445, saving model to Post_val_weights1.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8752 - val_loss: 0.3340 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33445 to 0.33403, saving model to Post_val_weights1.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8752 - val_loss: 0.3338 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33403 to 0.33379, saving model to Post_val_weights1.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8753 - val_loss: 0.3335 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33379 to 0.33346, saving model to Post_val_weights1.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8755 - val_loss: 0.3332 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33346 to 0.33321, saving model to Post_val_weights1.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8755 - val_loss: 0.3330 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33321 to 0.33296, saving model to Post_val_weights1.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8756 - val_loss: 0.3327 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33296 to 0.33273, saving model to Post_val_weights1.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8757 - val_loss: 0.3325 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.33273 to 0.33249, saving model to Post_val_weights1.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8756 - val_loss: 0.3323 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33249 to 0.33227, saving model to Post_val_weights1.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8757 - val_loss: 0.3321 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.33227 to 0.33206, saving model to Post_val_weights1.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8756 - val_loss: 0.3319 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33206 to 0.33187, saving model to Post_val_weights1.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8757 - val_loss: 0.3316 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.33187 to 0.33162, saving model to Post_val_weights1.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8758 - val_loss: 0.3315 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33162 to 0.33147, saving model to Post_val_weights1.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8758 - val_loss: 0.3313 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33147 to 0.33126, saving model to Post_val_weights1.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8758 - val_loss: 0.3311 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33126 to 0.33113, saving model to Post_val_weights1.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8758 - val_loss: 0.3310 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.33113 to 0.33101, saving model to Post_val_weights1.hdf5\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8759 - val_loss: 0.3309 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.33101 to 0.33090, saving model to Post_val_weights1.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8758 - val_loss: 0.3308 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.33090 to 0.33081, saving model to Post_val_weights1.hdf5\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8759 - val_loss: 0.3307 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.33081 to 0.33072, saving model to Post_val_weights1.hdf5\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8759 - val_loss: 0.3306 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.33072 to 0.33063, saving model to Post_val_weights1.hdf5\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8760 - val_loss: 0.3306 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.33063 to 0.33057, saving model to Post_val_weights1.hdf5\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8762 - val_loss: 0.3304 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.33057 to 0.33037, saving model to Post_val_weights1.hdf5\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8762 - val_loss: 0.3304 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.33037 to 0.33036, saving model to Post_val_weights1.hdf5\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8764 - val_loss: 0.3302 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.33036 to 0.33023, saving model to Post_val_weights1.hdf5\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8766 - val_loss: 0.3303 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33023\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8767 - val_loss: 0.3302 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.33023 to 0.33018, saving model to Post_val_weights1.hdf5\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8768 - val_loss: 0.3304 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33018\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8769 - val_loss: 0.3301 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.33018 to 0.33013, saving model to Post_val_weights1.hdf5\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8770 - val_loss: 0.3301 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33013\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8772 - val_loss: 0.3301 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.33013 to 0.33010, saving model to Post_val_weights1.hdf5\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8773 - val_loss: 0.3301 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33010\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8774 - val_loss: 0.3300 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.33010 to 0.33002, saving model to Post_val_weights1.hdf5\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8775 - val_loss: 0.3301 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33002\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8776 - val_loss: 0.3303 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33002\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8776 - val_loss: 0.3301 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33002\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8776 - val_loss: 0.3302 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33002\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8777 - val_loss: 0.3302 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33002\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8778 - val_loss: 0.3301 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33002\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8780 - val_loss: 0.3302 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33002\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8780 - val_loss: 0.3300 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33002\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8779 - val_loss: 0.3303 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33002\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8779 - val_loss: 0.3301 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33002\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8780 - val_loss: 0.3302 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33002\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8779 - val_loss: 0.3302 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33002\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8779 - val_loss: 0.3303 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33002\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8779 - val_loss: 0.3304 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33002\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8782 - val_loss: 0.3305 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33002\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8784 - val_loss: 0.3305 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33002\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8783 - val_loss: 0.3307 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33002\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8783 - val_loss: 0.3307 - val_acc: 0.8668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33002\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8782 - val_loss: 0.3311 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33002\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8783 - val_loss: 0.3310 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33002\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8783 - val_loss: 0.3313 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33002\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8783 - val_loss: 0.3313 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33002\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 8192\n",
      "Fold: 0\n",
      "best val loss: 0.3300208747317219\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  77.14819502830505\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.1471 - acc: 0.4695 - val_loss: 1.0334 - val_acc: 0.5242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03339, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.9771 - acc: 0.5663 - val_loss: 0.9039 - val_acc: 0.6276\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03339 to 0.90389, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8635 - acc: 0.6549 - val_loss: 0.8088 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.90389 to 0.80884, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7764 - acc: 0.7156 - val_loss: 0.7312 - val_acc: 0.7499\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.80884 to 0.73121, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7029 - acc: 0.7578 - val_loss: 0.6635 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73121 to 0.66348, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6381 - acc: 0.7868 - val_loss: 0.6033 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.66348 to 0.60331, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5810 - acc: 0.8112 - val_loss: 0.5510 - val_acc: 0.8253\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60331 to 0.55099, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5321 - acc: 0.8288 - val_loss: 0.5074 - val_acc: 0.8414\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55099 to 0.50741, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4920 - acc: 0.8416 - val_loss: 0.4731 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50741 to 0.47314, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4603 - acc: 0.8513 - val_loss: 0.4471 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47314 to 0.44714, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4358 - acc: 0.8572 - val_loss: 0.4275 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44714 to 0.42754, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4167 - acc: 0.8628 - val_loss: 0.4126 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42754 to 0.41260, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4017 - acc: 0.8657 - val_loss: 0.4008 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.41260 to 0.40084, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3897 - acc: 0.8670 - val_loss: 0.3914 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40084 to 0.39142, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3802 - acc: 0.8686 - val_loss: 0.3839 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.39142 to 0.38394, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3726 - acc: 0.8696 - val_loss: 0.3779 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38394 to 0.37786, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3663 - acc: 0.8707 - val_loss: 0.3727 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37786 to 0.37273, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3610 - acc: 0.8713 - val_loss: 0.3683 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37273 to 0.36828, saving model to Post_val_weights2.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3566 - acc: 0.8717 - val_loss: 0.3643 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36828 to 0.36435, saving model to Post_val_weights2.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3527 - acc: 0.8722 - val_loss: 0.3609 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36435 to 0.36090, saving model to Post_val_weights2.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3494 - acc: 0.8725 - val_loss: 0.3579 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36090 to 0.35787, saving model to Post_val_weights2.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3464 - acc: 0.8727 - val_loss: 0.3552 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35787 to 0.35521, saving model to Post_val_weights2.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3438 - acc: 0.8731 - val_loss: 0.3529 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35521 to 0.35286, saving model to Post_val_weights2.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3416 - acc: 0.8732 - val_loss: 0.3508 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35286 to 0.35078, saving model to Post_val_weights2.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3395 - acc: 0.8733 - val_loss: 0.3489 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35078 to 0.34893, saving model to Post_val_weights2.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3377 - acc: 0.8734 - val_loss: 0.3473 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34893 to 0.34727, saving model to Post_val_weights2.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3361 - acc: 0.8735 - val_loss: 0.3458 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34727 to 0.34580, saving model to Post_val_weights2.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3346 - acc: 0.8738 - val_loss: 0.3445 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34580 to 0.34449, saving model to Post_val_weights2.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3333 - acc: 0.8738 - val_loss: 0.3434 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34449 to 0.34335, saving model to Post_val_weights2.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3321 - acc: 0.8739 - val_loss: 0.3423 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34335 to 0.34235, saving model to Post_val_weights2.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3310 - acc: 0.8740 - val_loss: 0.3414 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34235 to 0.34143, saving model to Post_val_weights2.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3300 - acc: 0.8741 - val_loss: 0.3406 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.34143 to 0.34059, saving model to Post_val_weights2.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3290 - acc: 0.8744 - val_loss: 0.3398 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.34059 to 0.33983, saving model to Post_val_weights2.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8747 - val_loss: 0.3391 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33983 to 0.33914, saving model to Post_val_weights2.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3274 - acc: 0.8747 - val_loss: 0.3385 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33914 to 0.33851, saving model to Post_val_weights2.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3267 - acc: 0.8748 - val_loss: 0.3379 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33851 to 0.33792, saving model to Post_val_weights2.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3260 - acc: 0.8749 - val_loss: 0.3374 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33792 to 0.33738, saving model to Post_val_weights2.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3253 - acc: 0.8749 - val_loss: 0.3369 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33738 to 0.33685, saving model to Post_val_weights2.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8750 - val_loss: 0.3364 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33685 to 0.33639, saving model to Post_val_weights2.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8750 - val_loss: 0.3359 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33639 to 0.33591, saving model to Post_val_weights2.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3236 - acc: 0.8751 - val_loss: 0.3355 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33591 to 0.33551, saving model to Post_val_weights2.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8751 - val_loss: 0.3351 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33551 to 0.33507, saving model to Post_val_weights2.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8750 - val_loss: 0.3347 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33507 to 0.33473, saving model to Post_val_weights2.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8750 - val_loss: 0.3343 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33473 to 0.33433, saving model to Post_val_weights2.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8752 - val_loss: 0.3340 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33433 to 0.33402, saving model to Post_val_weights2.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3213 - acc: 0.8752 - val_loss: 0.3337 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33402 to 0.33366, saving model to Post_val_weights2.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8752 - val_loss: 0.3334 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33366 to 0.33339, saving model to Post_val_weights2.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8753 - val_loss: 0.3331 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33339 to 0.33307, saving model to Post_val_weights2.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8754 - val_loss: 0.3328 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33307 to 0.33282, saving model to Post_val_weights2.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8756 - val_loss: 0.3325 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33282 to 0.33255, saving model to Post_val_weights2.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8758 - val_loss: 0.3323 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33255 to 0.33232, saving model to Post_val_weights2.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8758 - val_loss: 0.3321 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33232 to 0.33209, saving model to Post_val_weights2.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8759 - val_loss: 0.3319 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33209 to 0.33189, saving model to Post_val_weights2.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8760 - val_loss: 0.3317 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.33189 to 0.33169, saving model to Post_val_weights2.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8762 - val_loss: 0.3315 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33169 to 0.33152, saving model to Post_val_weights2.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8762 - val_loss: 0.3314 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.33152 to 0.33136, saving model to Post_val_weights2.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8762 - val_loss: 0.3312 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33136 to 0.33121, saving model to Post_val_weights2.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8763 - val_loss: 0.3311 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.33121 to 0.33108, saving model to Post_val_weights2.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8762 - val_loss: 0.3310 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33108 to 0.33097, saving model to Post_val_weights2.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8762 - val_loss: 0.3309 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33097 to 0.33087, saving model to Post_val_weights2.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8762 - val_loss: 0.3308 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33087 to 0.33078, saving model to Post_val_weights2.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8761 - val_loss: 0.3307 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.33078 to 0.33070, saving model to Post_val_weights2.hdf5\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8761 - val_loss: 0.3306 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.33070 to 0.33064, saving model to Post_val_weights2.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8762 - val_loss: 0.3306 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.33064 to 0.33059, saving model to Post_val_weights2.hdf5\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8762 - val_loss: 0.3305 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.33059 to 0.33054, saving model to Post_val_weights2.hdf5\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8761 - val_loss: 0.3305 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.33054 to 0.33051, saving model to Post_val_weights2.hdf5\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8763 - val_loss: 0.3305 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.33051 to 0.33049, saving model to Post_val_weights2.hdf5\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8764 - val_loss: 0.3305 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.33049 to 0.33047, saving model to Post_val_weights2.hdf5\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8765 - val_loss: 0.3305 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.33047 to 0.33046, saving model to Post_val_weights2.hdf5\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8764 - val_loss: 0.3305 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.33046 to 0.33046, saving model to Post_val_weights2.hdf5\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8765 - val_loss: 0.3305 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33046\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8767 - val_loss: 0.3305 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33046\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8766 - val_loss: 0.3305 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33046\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8767 - val_loss: 0.3305 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33046\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8766 - val_loss: 0.3305 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33046\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8767 - val_loss: 0.3306 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33046\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8768 - val_loss: 0.3306 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33046\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8769 - val_loss: 0.3306 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33046\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8768 - val_loss: 0.3307 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33046\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8766 - val_loss: 0.3307 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33046\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8768 - val_loss: 0.3308 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33046\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8770 - val_loss: 0.3309 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33046\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8769 - val_loss: 0.3309 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33046\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8771 - val_loss: 0.3310 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33046\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8771 - val_loss: 0.3310 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33046\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8772 - val_loss: 0.3311 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33046\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8773 - val_loss: 0.3312 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33046\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8773 - val_loss: 0.3313 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33046\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8773 - val_loss: 0.3314 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33046\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8774 - val_loss: 0.3315 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33046\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8775 - val_loss: 0.3317 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33046\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8776 - val_loss: 0.3317 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33046\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8776 - val_loss: 0.3318 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33046\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8778 - val_loss: 0.3320 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33046\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8779 - val_loss: 0.3322 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33046\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8779 - val_loss: 0.3322 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33046\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8780 - val_loss: 0.3325 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33046\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3081 - acc: 0.8782 - val_loss: 0.3327 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33046\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8782 - val_loss: 0.3329 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33046\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8782 - val_loss: 0.3331 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33046\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 8192\n",
      "Fold: 1\n",
      "best val loss: 0.330462209139651\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  78.96147894859314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f678cc60668>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.1463 - acc: 0.4693 - val_loss: 1.0396 - val_acc: 0.5242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03963, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.9765 - acc: 0.5661 - val_loss: 0.9095 - val_acc: 0.6249\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03963 to 0.90946, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8626 - acc: 0.6557 - val_loss: 0.8151 - val_acc: 0.6898\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.90946 to 0.81510, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7754 - acc: 0.7172 - val_loss: 0.7381 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81510 to 0.73807, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7018 - acc: 0.7590 - val_loss: 0.6708 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73807 to 0.67078, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6369 - acc: 0.7878 - val_loss: 0.6115 - val_acc: 0.7950\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67078 to 0.61147, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5797 - acc: 0.8121 - val_loss: 0.5609 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61147 to 0.56095, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5309 - acc: 0.8302 - val_loss: 0.5193 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56095 to 0.51935, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4909 - acc: 0.8430 - val_loss: 0.4859 - val_acc: 0.8392\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51935 to 0.48585, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4593 - acc: 0.8519 - val_loss: 0.4596 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48585 to 0.45964, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4349 - acc: 0.8579 - val_loss: 0.4392 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.45964 to 0.43916, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4160 - acc: 0.8628 - val_loss: 0.4227 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43916 to 0.42266, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4011 - acc: 0.8657 - val_loss: 0.4091 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.42266 to 0.40915, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3892 - acc: 0.8674 - val_loss: 0.3983 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40915 to 0.39825, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3797 - acc: 0.8687 - val_loss: 0.3895 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.39825 to 0.38955, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3720 - acc: 0.8698 - val_loss: 0.3825 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38955 to 0.38252, saving model to Post_val_weights3.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3657 - acc: 0.8708 - val_loss: 0.3767 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.38252 to 0.37673, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3603 - acc: 0.8714 - val_loss: 0.3719 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37673 to 0.37191, saving model to Post_val_weights3.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3558 - acc: 0.8720 - val_loss: 0.3678 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37191 to 0.36782, saving model to Post_val_weights3.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3519 - acc: 0.8726 - val_loss: 0.3643 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36782 to 0.36432, saving model to Post_val_weights3.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3485 - acc: 0.8731 - val_loss: 0.3613 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36432 to 0.36128, saving model to Post_val_weights3.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3455 - acc: 0.8734 - val_loss: 0.3586 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36128 to 0.35862, saving model to Post_val_weights3.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3429 - acc: 0.8738 - val_loss: 0.3563 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35862 to 0.35629, saving model to Post_val_weights3.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3406 - acc: 0.8741 - val_loss: 0.3543 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35629 to 0.35428, saving model to Post_val_weights3.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3386 - acc: 0.8741 - val_loss: 0.3525 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35428 to 0.35252, saving model to Post_val_weights3.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3367 - acc: 0.8744 - val_loss: 0.3510 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35252 to 0.35100, saving model to Post_val_weights3.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3351 - acc: 0.8744 - val_loss: 0.3497 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.35100 to 0.34967, saving model to Post_val_weights3.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3337 - acc: 0.8746 - val_loss: 0.3485 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34967 to 0.34851, saving model to Post_val_weights3.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3323 - acc: 0.8749 - val_loss: 0.3474 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34851 to 0.34745, saving model to Post_val_weights3.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3312 - acc: 0.8748 - val_loss: 0.3466 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34745 to 0.34662, saving model to Post_val_weights3.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3301 - acc: 0.8748 - val_loss: 0.3457 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34662 to 0.34569, saving model to Post_val_weights3.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3291 - acc: 0.8751 - val_loss: 0.3449 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.34569 to 0.34495, saving model to Post_val_weights3.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3281 - acc: 0.8753 - val_loss: 0.3443 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.34495 to 0.34430, saving model to Post_val_weights3.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3273 - acc: 0.8755 - val_loss: 0.3437 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.34430 to 0.34366, saving model to Post_val_weights3.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3265 - acc: 0.8754 - val_loss: 0.3431 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34366 to 0.34315, saving model to Post_val_weights3.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3258 - acc: 0.8753 - val_loss: 0.3426 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.34315 to 0.34261, saving model to Post_val_weights3.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3251 - acc: 0.8754 - val_loss: 0.3422 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.34261 to 0.34221, saving model to Post_val_weights3.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3245 - acc: 0.8753 - val_loss: 0.3418 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.34221 to 0.34184, saving model to Post_val_weights3.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8753 - val_loss: 0.3415 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.34184 to 0.34146, saving model to Post_val_weights3.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3233 - acc: 0.8753 - val_loss: 0.3410 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.34146 to 0.34103, saving model to Post_val_weights3.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8752 - val_loss: 0.3408 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.34103 to 0.34077, saving model to Post_val_weights3.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8752 - val_loss: 0.3404 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.34077 to 0.34042, saving model to Post_val_weights3.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8753 - val_loss: 0.3401 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.34042 to 0.34015, saving model to Post_val_weights3.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8754 - val_loss: 0.3399 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.34015 to 0.33991, saving model to Post_val_weights3.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8755 - val_loss: 0.3397 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33991 to 0.33968, saving model to Post_val_weights3.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3204 - acc: 0.8754 - val_loss: 0.3395 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33968 to 0.33949, saving model to Post_val_weights3.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8756 - val_loss: 0.3393 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33949 to 0.33927, saving model to Post_val_weights3.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8756 - val_loss: 0.3391 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33927 to 0.33913, saving model to Post_val_weights3.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8756 - val_loss: 0.3389 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33913 to 0.33893, saving model to Post_val_weights3.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8755 - val_loss: 0.3388 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33893 to 0.33880, saving model to Post_val_weights3.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8754 - val_loss: 0.3387 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33880 to 0.33868, saving model to Post_val_weights3.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8756 - val_loss: 0.3385 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33868 to 0.33853, saving model to Post_val_weights3.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8757 - val_loss: 0.3384 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33853 to 0.33838, saving model to Post_val_weights3.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8758 - val_loss: 0.3382 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.33838 to 0.33818, saving model to Post_val_weights3.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8759 - val_loss: 0.3380 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33818 to 0.33803, saving model to Post_val_weights3.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8760 - val_loss: 0.3379 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.33803 to 0.33791, saving model to Post_val_weights3.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8760 - val_loss: 0.3378 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33791 to 0.33775, saving model to Post_val_weights3.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8760 - val_loss: 0.3376 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.33775 to 0.33761, saving model to Post_val_weights3.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8761 - val_loss: 0.3375 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33761 to 0.33750, saving model to Post_val_weights3.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8761 - val_loss: 0.3374 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33750 to 0.33744, saving model to Post_val_weights3.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8763 - val_loss: 0.3372 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33744 to 0.33725, saving model to Post_val_weights3.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8763 - val_loss: 0.3372 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.33725 to 0.33717, saving model to Post_val_weights3.hdf5\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8763 - val_loss: 0.3370 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.33717 to 0.33700, saving model to Post_val_weights3.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8764 - val_loss: 0.3369 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.33700 to 0.33688, saving model to Post_val_weights3.hdf5\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8765 - val_loss: 0.3368 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.33688 to 0.33677, saving model to Post_val_weights3.hdf5\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8765 - val_loss: 0.3366 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.33677 to 0.33663, saving model to Post_val_weights3.hdf5\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8764 - val_loss: 0.3366 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.33663 to 0.33656, saving model to Post_val_weights3.hdf5\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8765 - val_loss: 0.3365 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.33656 to 0.33647, saving model to Post_val_weights3.hdf5\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8764 - val_loss: 0.3364 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.33647 to 0.33638, saving model to Post_val_weights3.hdf5\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8765 - val_loss: 0.3364 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.33638 to 0.33636, saving model to Post_val_weights3.hdf5\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8765 - val_loss: 0.3362 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.33636 to 0.33624, saving model to Post_val_weights3.hdf5\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8765 - val_loss: 0.3362 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.33624 to 0.33622, saving model to Post_val_weights3.hdf5\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8766 - val_loss: 0.3361 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.33622 to 0.33612, saving model to Post_val_weights3.hdf5\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8766 - val_loss: 0.3361 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.33612 to 0.33607, saving model to Post_val_weights3.hdf5\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8764 - val_loss: 0.3361 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33607\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8768 - val_loss: 0.3360 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.33607 to 0.33602, saving model to Post_val_weights3.hdf5\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8768 - val_loss: 0.3361 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33602\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8770 - val_loss: 0.3360 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.33602 to 0.33601, saving model to Post_val_weights3.hdf5\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8770 - val_loss: 0.3361 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33601\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8772 - val_loss: 0.3360 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33601\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8772 - val_loss: 0.3361 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33601\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8773 - val_loss: 0.3360 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33601\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8774 - val_loss: 0.3361 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33601\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8776 - val_loss: 0.3360 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33601\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8776 - val_loss: 0.3362 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33601\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8777 - val_loss: 0.3361 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33601\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8776 - val_loss: 0.3364 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33601\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8776 - val_loss: 0.3363 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33601\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8775 - val_loss: 0.3366 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33601\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8776 - val_loss: 0.3365 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33601\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8777 - val_loss: 0.3367 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33601\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8777 - val_loss: 0.3367 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33601\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8778 - val_loss: 0.3368 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33601\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8780 - val_loss: 0.3370 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33601\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8780 - val_loss: 0.3372 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33601\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3078 - acc: 0.8784 - val_loss: 0.3373 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33601\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8784 - val_loss: 0.3374 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33601\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8785 - val_loss: 0.3375 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33601\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8785 - val_loss: 0.3377 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33601\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8785 - val_loss: 0.3378 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33601\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 8192\n",
      "Fold: 2\n",
      "best val loss: 0.3360145849094056\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZScdZ3v8fe3tt47vSaddAfSDJE0CYGEJqDIJowGEBARkXEZvCp3ODrqjM4dxnvP6MzoGT3Hw+V6L+JRx2W8KjJRBBXHKxrGNUwSlJB9XzqdpdOd3pfqqvrdP56nOtVJd9JJqlNdT31e59SpZ6unvk8/XZ/nqd+zlDnnEBGR/BfKdQEiIpIdCnQRkYBQoIuIBIQCXUQkIBToIiIBEcnVG9fV1bkFCxbk6u1FRPLS+vXrjznn6ical7NAX7BgAevWrcvV24uI5CUz2zfZODW5iIgEhAJdRCQgFOgiIgGRszZ0EQmW0dFR2traGB4eznUpgVBcXExTUxPRaHTKr1Ggi0hWtLW1UVFRwYIFCzCzXJeT15xzdHZ20tbWRnNz85RfpyYXEcmK4eFhamtrFeZZYGbU1tae9bcdBbqIZI3CPHvO5W+Zd4G+dm8Xn/v3raRSuu2viEimvAv0Vw508+SLu+gbTuS6FBGZQbq7u/niF7941q+744476O7unoaKLry8C/SashgAxwfjOa5ERGaSyQI9kTj9zt/zzz9PVVXVdJV1QeXdWS7VpV6gdw3GWUBZjqsRkZni0UcfZdeuXVx11VVEo1GKi4uprq5m69atbN++nbe85S0cOHCA4eFhPvKRj/Dwww8DJ25D0t/fz+23387rX/96fve739HY2Mizzz5LSUlJjpds6vIv0NN76APaQxeZqf7hR5vY3N6b1XlePq+ST961eNLxn/3sZ9m4cSN//OMfefHFF7nzzjvZuHHj2Gl/X/va16ipqWFoaIhrrrmG++67j9ra2nHz2LFjB9/97nf5yle+wtvf/na+//3v8653vSuryzGd8i7Qa0rTTS6jOa5ERGayFStWjDuH+wtf+ALPPPMMAAcOHGDHjh2nBHpzczNXXXUVAFdffTV79+69YPVmQ94FelWZd9WU9tBFZq7T7UlfKGVlJ5pkX3zxRV544QV+//vfU1pays033zzhOd5FRUVj3eFwmKGhoQtSa7bk3UHRiqIIkZDRpYOiIpKhoqKCvr6+Ccf19PRQXV1NaWkpW7duZc2aNRe4ugsj7/bQzYzqshjdCnQRyVBbW8v111/PkiVLKCkpYc6cOWPjVq5cyZe+9CVaWlq47LLLuO6663JY6fTJu0AHqC6N0qUmFxE5yXe+850JhxcVFfHTn/50wnHpdvK6ujo2btw4NvzjH/941uubbnnX5ALeqYs6KCoiMl5eBnpNWUwHRUVETpKXgV5VGtOVoiIiJ8nLQK8pi3J8cBTndIMuEZG0vAz06tIYyZSjVzfoEhEZk7eBDrq4SEQkU14Guu64KCLnq7y8HID29nbe9ra3TTjNzTffzLp16047n8cff5zBwcGx/lzejjcvA71agS4iWTJv3jxWrVp1zq8/OdBzeTve/Az0Uu9+Ll0DOhddRDyPPvooTzzxxFj/pz71KT796U9z6623snz5cq644gqeffbZU163d+9elixZAsDQ0BDveMc7aGlp4d577x13L5dHHnmE1tZWFi9ezCc/+UnAu+FXe3s7t9xyC7fccgvg3Y732LFjADz22GMsWbKEJUuW8Pjjj4+9X0tLCx/4wAdYvHgxb3zjG7N2z5j8vFLU30PX5f8iM9RPH4XDr2Z3ng1XwO2fnXT0Aw88wEc/+lE++MEPAvD000/zs5/9jA9/+MNUVlZy7NgxrrvuOu6+++5Jf6/zySefpLS0lC1btrBhwwaWL18+Nu4zn/kMNTU1JJNJbr31VjZs2MCHP/xhHnvsMVavXk1dXd24ea1fv56vf/3rvPTSSzjnuPbaa7npppuorq6ettv05uUe+tgNunRQVER8y5Yt4+jRo7S3t/PKK69QXV1NQ0MDn/jEJ1i6dCm33XYbBw8e5MiRI5PO41e/+tVYsC5dupSlS5eOjXv66adZvnw5y5YtY9OmTWzevPm09fzmN7/h3nvvpaysjPLyct761rfy61//Gpi+2/Tm5R66meniIpGZ7DR70tPp/vvvZ9WqVRw+fJgHHniAb3/723R0dLB+/Xqi0SgLFiyY8La5Z7Jnzx4+//nPs3btWqqrq3nooYfOaT5p03Wb3rzcQwf/4iK1oYtIhgceeICnnnqKVatWcf/999PT08Ps2bOJRqOsXr2affv2nfb1N95449gNvjZu3MiGDRsA6O3tpaysjFmzZnHkyJFxN/qa7La9N9xwAz/84Q8ZHBxkYGCAZ555hhtuuCGLS3uqvNxDB+9cdN0TXUQyLV68mL6+PhobG5k7dy7vfOc7ueuuu7jiiitobW1l0aJFp339I488wnvf+15aWlpoaWnh6quvBuDKK69k2bJlLFq0iPnz53P99dePvebhhx9m5cqVzJs3j9WrV48NX758OQ899BArVqwA4P3vfz/Lli2b1l9BslxdPt/a2urOdH7n6fzFt9azq6Ofn//1TVmsSkTO1ZYtW2hpacl1GYEy0d/UzNY751onmj7/9tCPboEDL1Fduly30BURyZB/beg7X4AffYSG4jjHB+O6QZeIiC//Ar28AYDGcLdu0CUyw2gHK3vO5W+Zf4Fe4QX6bPPulaCLi0RmhuLiYjo7OxXqWeCco7Ozk+Li4rN6Xf61oVfMBaDOHQdK6BqIc3FtWW5rEhGamppoa2ujo6Mj16UEQnFxMU1NTWf1mjwMdO+XvGcljgHzdHGRyAwRjUZpbm7OdRkFLf+aXIoqIFZORaITQBcXiYj48i/QASoaKBk+CugWuiIiaWcMdDP7mpkdNbONk4w3M/uCme00sw1mtnyi6bKqvIHI4FHdoEtEJMNU9tC/Aaw8zfjbgYX+42HgyfMv6wwqGrC+w/4NutTkIiICUwh059yvgK7TTHIP8K/OswaoMrO52SpwQhUN0HeYmtKIfldURMSXjTb0RuBARn+bP+wUZvawma0zs3XndWpTRQMkhphXMqobdImI+C7oQVHn3Jedc63Oudb6+vpzn5F/LvqCWJ8uLBIR8WUj0A8C8zP6m/xh08e/WrQp0qPfFRUR8WUj0J8D3uOf7XId0OOcO5SF+U7Ov59LQ+g43bpBl4gIMIUrRc3su8DNQJ2ZtQGfBKIAzrkvAc8DdwA7gUHgvdNV7Bj/atHZ1k0i5egbSVBZHJ32txURmcnOGOjOuQfPMN4BH8xaRVNRVAGxCmpS3tWiHX0jCnQRKXj5eaUoQMUcqpPe2ZSHe879x1pFRIIijwN9LmXxYwAc7M7OL2aLiOSzPA70BoqGvPu5HOrWHrqISP4GevkcrP8w9eUx2rWHLiKSx4FeMRcSwyysTNLeo0AXEcnjQPfORb+sbIBDOigqIpL/gX5JcR/t3UO6uEhECl4eB7p3P5f50V4G40l6hxI5LkhEJLfyN9DLvatFG0LdgE5dFBHJ30AvKh93teghHRgVkQKXv4EOUNFA5agX6O06MCoiBS7vA71ouINo2HQuuogUvLwPdOs7xJzKYg4p0EWkwOV9oNN3mHmVxWpyEZGCl9+BXt4AyREurRxVk4uIFLz8DvRZTQAsLO7hSO8wyZQuLhKRwpXfgV7TDMAloSOMJh3H+kdyXJCISO7kd6BXe4He6A4DqNlFRApafgd6cSWU1lEbPwigm3SJSEHL70AHqGmmYvAAoD10ESlsAQj0Swh376U0FqZdv1wkIgUs/wO9uhnrPchFlWHtoYtIQcv/QK+5BHAsLe/WDbpEpKAFINC9M11aYsd0taiIFLT8D3T/1MXm8FE6+kYYSSRzXJCISG7kf6CX1UGsYuxc9CM9urhIRApT/ge6GdQsoM4/F31/12COCxIRyY38D3SAmkuoGGoDYM+x/hwXIyKSG8EI9Opmwj37KY8ZuzoGcl2NiEhOBCPQa5qx1CjXVA+y55gCXUQKU0AC/RIAlpcfV6CLSMEKRqD7py4uKu6k7figTl0UkYIUjECvbIRwEQvsCCkH+zt1pouIFJ5gBHooBNUXUz/qnbq4W80uIlKAghHo4J26OJg+dVGBLiKFJziBXt1MuHsvdWUxdnfoXHQRKTzBCfSaZhgdYFlNXHvoIlKQAhTofwJAa/kxBbqIFKQpBbqZrTSzbWa208wenWD8RWa22sz+YGYbzOyO7Jd6BrMXAXB5tJ1j/XF6hkYveAkiIrl0xkA3szDwBHA7cDnwoJldftJk/wN42jm3DHgH8MVsF3pGlY1QVMnFyf2ADoyKSOGZyh76CmCnc263cy4OPAXcc9I0Dqj0u2cB7dkrcYrMoH4R9UO7Ad2kS0QKz1QCvRE4kNHf5g/L9CngXWbWBjwP/OVEMzKzh81snZmt6+joOIdyz2D2IoqPbydkjj26SZeIFJhsHRR9EPiGc64JuAP4lpmdMm/n3Jedc63Oudb6+vosvXWG2ZdjQ10srR5ll5pcRKTATCXQDwLzM/qb/GGZ3gc8DeCc+z1QDNRlo8CzUu8dGH1t+RHtoYtIwZlKoK8FFppZs5nF8A56PnfSNPuBWwHMrAUv0KehTeUMZnvHaq8sOsyeYwM45y54CSIiuXLGQHfOJYAPAT8DtuCdzbLJzP7RzO72J/sY8AEzewX4LvCQy0Wals+GkmoucQcYGk1yuHf4gpcgIpIrkalM5Jx7Hu9gZ+awv8/o3gxcn93SzoEZ1LfQ4J/psuvoAHNnleS4KBGRCyM4V4qmzW6hvHcn4Nh2pC/X1YiIXDCBDPTQSC8tpf1sO9yb62pERC6Y4AW6f6bLTTXH2HZYe+giUjiCF+izWwBYXnyEbUf6SKZ0pouIFIbgBXpZHZTVs9D2MzyaYn+Xfo5ORApD8AIdYHYLc4b3ArD1kNrRRaQwBDPQ61so6dlJyFJsVTu6iBSIYAb67EVYvJ9rqwd1YFRECkZAA30xADfMOspWnbooIgUimIE+ZzFgLIseYF/XIIPxRK4rEhGZdsEM9KJyqL2USxI7cQ52HNGPXYhI8AUz0AHmXklt31YANbuISEEIcKAvJdJ3kHmxAZ3pIiIFIcCBfiUAt1UfYeshBbqIBF9wA71hKQDXlbSx7UiffuxCRAIvuIFeWgNVF7HI7aFrIE5H/0iuKxIRmVbBDXSAhqXMHdwGoGYXEQm8YAf63Kso6dtLOYNsateZLiISbAEPdO/A6M2zjvDqwe4cFyMiMr0CHujegdGbKtt59WBPjosREZlewQ70igYon8PS8H4OdA1xfCCe64pERKZNsAMdYO6VNA1vB2Bju/bSRSS4gh/oDUsp7dlJEXE2tCnQRSS4gh/oc6/EXJKbqzrYqHZ0EQmw4Af6vKsAeENlm/bQRSTQgh/os+ZD+RyW2U4Odg/RpQOjIhJQwQ90M2i6hvmDmwB0+qKIBFbwAx2gqZWSvr1U06t2dBEJrAIJ9BUArKw6yIY2XTEqIsFUGIE+7yqwMDeV7WXjQd3TRUSCqTACPVYGcxZzRWobB7uH6NStdEUkgAoj0AHmr2BO/2ZCpHRgVEQCqXACvekaIqP9LAwd5I8H1I4uIsFTUIEOcPusA6zfdzzHxYiIZF/hBHrNJVBSww0le/jD/m6SKf3GqIgES+EEun+B0cL4FvpHEmw/op+kE5FgKZxAB2i6hsr+3VQywDo1u4hIwBRYoLcCcGPZfl5WoItIwEwp0M1spZltM7OdZvboJNO83cw2m9kmM/tOdsvMksarwcLcUbGbdfu6cl2NiEhWnTHQzSwMPAHcDlwOPGhml580zULg74DrnXOLgY9OQ63nr7gS5i3jareRA11DHO0dznVFIiJZM5U99BXATufcbudcHHgKuOekaT4APOGcOw7gnDua3TKzqPlGZvduoowhnb4oIoEylUBvBA5k9Lf5wzK9BniNmf3WzNaY2cqJZmRmD5vZOjNb19HRcW4Vn69LbsJcgtdFtyvQRSRQsnVQNAIsBG4GHgS+YmZVJ0/knPuyc67VOddaX1+fpbc+S/OvhXCMuyp26EwXEQmUqQT6QWB+Rn+TPyxTG/Ccc27UObcH2I4X8DNPtATmX8sKNrGpvYfh0WSuKxIRyYqpBPpaYKGZNZtZDHgH8NxJ0/wQb+8cM6vDa4LZncU6s6v5RuYMbqcs2avfGRWRwDhjoDvnEsCHgJ8BW4CnnXObzOwfzexuf7KfAZ1mthlYDfyNc65zuoo+b803YjiuDW1h7V6dvigiwRCZykTOueeB508a9vcZ3Q74a/8x8zVeDdEy7ozt4Hu7jvHBWy7NdUUiIuetsK4UTQtH4eLX8drQJtbuPa52dBEJhMIMdIDmG6kf3ktVopN1e3W2i4jkv4IOdIAbIpv49c4cnRMvIpJFhRvoDUuhtI63lG/htzuP5boaEZHzVriBHgrBZStZMbqW7e1ddA3Ec12RiMh5KdxAB1h0F0XJfq61zfxul/bSRSS/FXagX3ITLlrGm2Pr1ewiInmvsAM9WoJdeitvCr/Mb3fM3BtEiohMRWEHOkDLXVQlO6np3sS+zoFcVyMics4U6Av/FBeK8KbwWn69Q80uIpK/FOgl1bDg9dwRfZnVW9XsIiL5S4EO2KI3c7E7yMEdr9A7PJrrckREzokCHeCyOwB4Ay/xyy3aSxeR/KRAB5jViJv/Wh6I/oafvtqe62pERM6JAt1ny9/NxbTTt/3XDIwkcl2OiMhZU6CnLX4LiWg599kvWb1NzS4ikn8U6GmxMkJL7+fO8EusfmVnrqsRETlrCvQMoeXvppg4lTueZSiuH70QkfyiQM80bzkDVYu4l1/wH9t1j3QRyS8K9ExmFF/7XpaG9vCH//xVrqsRETkrCvSThK98OwmLcfGe73G0bzjX5YiITJkC/WSlNQy23M99oRf5yW/W57oaEZEpU6BPoPJP/5awOcrX/m+SKZfrckREpkSBPpHqiznU/FbuTr7Ab1/ekOtqRESmRIE+ibl3/nfClmL4xcdyXYqIyJQo0CcRqWtm65w3c1PfTziwd1euyxEROSMF+mk03PkJQqQ4/JPP5LoUEZEzUqCfRt1Fi1hTfRfLj/6Aru1rcl2OiMhpKdDP4KL7P0sHVYz84IOQ1I9fiMjMpUA/g4sb5/LL5r9h7vBOul7QAVIRmbkU6FNw233v4/+5FZSv+Tx06gCpiMxMCvQpmF1RzJ5rPslwKsLAv/0FJPUDGCIy8yjQp+jPbruWz4XeT9nh/8T9/O9zXY6IyCkU6FNUURxl6R0f4OuJN2FrnoBXV+W6JBGRcRToZ+HtrfNZc+lfsc5dRurZD8HhjbkuSURkjAL9LJgZn75vOX8X/jjHkyW4px6EnoO5LktEBFCgn7X6iiI+9tYb+fPhvybe1wnfvAv6Due6LBERBfq5WLmkgZblN/Lg4N+Q6DkE/3oPDBzLdVkiUuCmFOhmttLMtpnZTjN79DTT3Wdmzsxas1fizPRPb1lC+OJreWjkY6S69sA374aetlyXJSIF7IyBbmZh4AngduBy4EEzu3yC6SqAjwAvZbvImag4GuYr72mlvbqV/5r8W5Ld++HLt8CBtbkuTUQK1FT20FcAO51zu51zceAp4J4Jpvsn4HNAwfwQZ1VpjG88tII/RJbybj7DaLgEvnEnvPK9XJcmIgVoKoHeCBzI6G/zh40xs+XAfOfcT043IzN72MzWmdm6jo6Osy52JrqotpRvvHcF25LzeGP/p+ivXwbPPAyr/gsMdOa6PBEpIOd9UNTMQsBjwMfONK1z7svOuVbnXGt9ff35vvWMsaRxFqseeR2jRVVc3/6X7Fv6Udj8HHzxWtj8LDj9LqmITL+pBPpBYH5Gf5M/LK0CWAK8aGZ7geuA5wrhwGim5royvv/I65hbU8mt667le8u/hauYC0+/B77xZmhbl+sSRSTgphLoa4GFZtZsZjHgHcBz6ZHOuR7nXJ1zboFzbgGwBrjbOVdwCTanspin/+K1vGlxA3/7mxQPhT9L3xv+GY5tg6/eCt97Nxx8OddlikhAnTHQnXMJ4EPAz4AtwNPOuU1m9o9mdvd0F5hvKouj/J8/W8Y/v/UKXtrfy03/sZAfvP7HpG56FHathq/cAl9b6TXJ6AczRCSLzOWofbe1tdWtWxfsnfgdR/p49Aevsn7fca6cX8U/rbyIpUd/BC89Cd37obQOrrgfrnoQGpaCWa5LFpEZzszWO+cmbNJWoE8z5xzP/OEg//zTrXT0jXBbyxw+dPMCrhpeC3/8Dmz/d0jGoboZFt0Ji94MTddAOJLr0kVkBlKgzwD9Iwm++uvdfP23e+kZGuWGhXW89/oF3DQ/SnjLs7D1x7D7PyA1CkWzoPkGuORmWPB6qLsMQrpLg4go0GeU/pEE/3fNPv7lN3vo6BuhsaqEB1fM597lTTQWj8LOF2D3atj1IvTs915UXAXzr/X23Oct8x5ltTldDhHJDQX6DDSaTPHzzUf49kv7+O1O7wKk1ourufuqebzx8gYaKougazfsXwMH1njPx3YA/vqqbIQ5i2H25TC7BeoWQu1CKK7M3UKJyLRToM9w+zsH+dGGdp77YzvbjvQBsKSxkjcsmsONC+u4cn4V0XAIhnvh0CvQ/rL34xpHN0PHNq+ZJq1sNlQv8B8Xw6wm71HZBBUNUDxLB19F8pgCPY/sONLHC1uO8ostR3h5/3FSDspiYVY017CiuZarL65madMsiqNh7wWJOBzfC8e2Q+cOb6++a483rPcguNT4N4iUQMUcL/jL6qG83jvbpqwOSmu95p3iWVBSBSXVXn8kdqH/DCIyCQV6njo+EGfN7k5+t6uT3+46xu6OAQAiIWPR3AquaKziisZZLJ5XyWvmVFASC4+fQTIBfYe82/r2HvR+iKPvEPQfgf6jMNDhPQY7Tw3+TLFyKKqEogqvSSdWDkXl3nOsHGJlXn+0DKIlEC098RwrhUix/yjyH8UQjnnd4Zi+MYicBQV6QHQNxHl533HW7z/OhrZuXm3roXc4AXiZuKC2jIWzy7l0djl/Ul/OJfVlLKgto6o0ip0uNFMpGO72gn24x+se6oah4yeeR3pgpM9r9on3Q3wARvoh3ud1J+PnvmBhP+SjfuiHiyAchVDEC/xwzPuWkB4ejkIoemKaUGR8dygCoXDGc/REt4W8x8nTmoGFx09jIX9YKGNc+KT5RzKGhyZ4bXiCeWRMg/ndpg1bkDjnPVKj3gWEqcSJnSbnvB2daMk5zVqBHlDOOQ50DbH5UC9bD/ey9VAfOzv62XtsgETqxHqtLI5wUW0pTVWlNFWX0FhdwtxZJcydVczcWcXUlhcRDp1nmCRGYHQIRgchPgiJIa8/PgCJYW98+jkZn7g78zn9IUjGve7ECCRHvG8dybj/QUl406TS06a7k+CS5/nXzYH0hsbCGSHvP6eHj20Qwhnj0xupjI0Hdur4kzcg+OvcTpp23PAJXjPZhsdCgBt/M7rM1zjH2EF9b+Qk8/GHu9QE88LbAUn5635s2cz/H0iHp8sYnjzxP5Ken5k3//S8xupKv0fC+x9KJf3pkif60+E8NtzvxmXUfIZcvfMxuOZ9p59mEqcLdF29ksfMjItqS7motpSVSxrGho8mU+zrHGTvsQH2dQ2yr3OAfZ2D7Ozo58XtRxkeHd+8Eg4ZdeUxZlcUU1ceo76iiLryImrKYmPP6Ud1aezUph040ZxSUjXdiz01zp348I2Fvv/By/xgpj+c6Q9s+sOZ/rCPfahPes4MicwPffpDPe41J/WPTZMOAZdRV7qmzOEZ4zLrGhvnTn2vzPlm1jQ2PCNwTq7b+wOeCKax98kYnhnqmdONBb5lzCeV8ZrMcPfHjwt2d2KemWE9tixkfEMKj/8bpb/RhSLeRi09LhT2/jdDkfEbnbFvav77ZAbxuA1o5jeszG9kE2xUsfF1Z357tIwN7UXXncc/9+QU6AEUDYe41G96OZlzjq6BOId6hjnUM8zhniGO9o1wpHeYI70jHO0bYfOhXjr74+P28jMVRUJUlUapKokxqyRKZUmUypIIlcVRKosjVBRHqfCfy4sjlBeFKSuKUBaLUF4UobQoTFFkgo1CNpl5V9vqilspIPpvLzBmRm15EbXlRSxpnDXpdKmUo3d4lM6BOJ39cY4Pxjk+EKdrME7P4Cjdg6McH4zTOzzKwe4hthwapXd4lD6/Tf9MomGjNBahLBamtMh/jkUojYUpiYUp9ftLYmFKo96wkliY4oj/HA1RHAlTFA1RFPH6izL6iyIhiiKh0x87EAkYBbpMKBQyqkpjVJXG+JOz+C2SVMrRN5KgfyRB/3CCvuFR+kcSDIwkGRhJMBBPMBj3u0e87sF4kv6RBEPxJId7h/1h3riheHLSbwpTURQJURz1Az4aIhb2Aj8WCRHzQz8W9rqjGc9F/vhYRnd6fOb00bBNMCxELGJj3ZGwEQuHiPjTR0MhQud7zEJkAgp0yapQyJhVEmVWSTRr8xxNphge9cJ9eDTF4KgX/iOJFCMJb1w8o3vsOaN7eDRFPJnyp/OGxxMp+oYTjPrD48kUo4kU8aQjnkiOTX8e25NJhUNGJJQOeiMSDo11R8MhIiEb2xhEQyemifrDoxGvO3N45KTpo+HQ2Puku6NhI5Ke39h0Rjg08Twi6WHp9wqN707PXxuomUGBLjNeek+3ojh7G4mpcs6RSDniiRSJpGMk6W08RpNubEOQ3jjEkykSSW/cie7U2PSJ1InXjfrTJTKGj02fPNGfSJ14n4F4cmya9HxOeX3Ke56OjdCZRELmbzROBH3Yf4zfSHjfVCbdUPgbqLA/LBw2wmYn5hlOzzvz9UYoc5r0a/3xmcPDIcaNT2/Qxqb3N1CZ8wz73SePMzuxcZ4JzXsKdJHTMPM+8NFw+m6XF36jci5SKcdoKh34jmRqfOCPJr1ho/5GI5kav4HJ3FBkTpfwX58c1w3JVOrE+6RObIxSzo3VcMoGyH8eHk2RSHkbq0TyRN3JsfmlMrrduO6ZJB3s6dDP3KhFQiFCIbxng4/e9hruunJe1mtQoIsEUChkFHrG2/4AAAR9SURBVIXCFAX4E+5cxgbED/mU351y4zc+p24MvA1ReiOXTJ3YMI0mvdenX5NKOZLOf86Yj4Nx75nI3BC5E+/lbRBPzDOZclSVTs+OQYBXt4gEmVm6iSbXlcwc+tUEEZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhA5+8UiM+sA9p3jy+uAY1ksJ18U4nIX4jJDYS53IS4znP1yX+ycm/AeqDkL9PNhZusm+wmmICvE5S7EZYbCXO5CXGbI7nKryUVEJCAU6CIiAZGvgf7lXBeQI4W43IW4zFCYy12IywxZXO68bEMXEZFT5eseuoiInESBLiISEHkX6Ga20sy2mdlOM3s01/VMBzObb2arzWyzmW0ys4/4w2vM7OdmtsN/rs51rdlmZmEz+4OZ/djvbzazl/z1/T0zi+W6xmwzsyozW2VmW81si5m9tkDW9V/5/98bzey7ZlYctPVtZl8zs6NmtjFj2ITr1jxf8Jd9g5ktP9v3y6tAN7Mw8ARwO3A58KCZXZ7bqqZFAviYc+5y4Drgg/5yPgr8wjm3EPiF3x80HwG2ZPR/DvifzrlLgePA+3JS1fT6X8C/O+cWAVfiLX+g17WZNQIfBlqdc0uAMPAOgre+vwGsPGnYZOv2dmCh/3gYePJs3yyvAh1YAex0zu12zsWBp4B7clxT1jnnDjnnXva7+/A+4I14y/pNf7JvAm/JTYXTw8yagDuBr/r9BrwBWOVPEsRlngXcCPwLgHMu7pzrJuDr2hcBSswsApQChwjY+nbO/QroOmnwZOv2HuBfnWcNUGVmc8/m/fIt0BuBAxn9bf6wwDKzBcAy4CVgjnPukD/qMDAnR2VNl8eB/wak/P5aoNs5l/D7g7i+m4EO4Ot+U9NXzayMgK9r59xB4PPAfrwg7wHWE/z1DZOv2/POt3wL9IJiZuXA94GPOud6M8c573zTwJxzamZvBo4659bnupYLLAIsB550zi0DBjipeSVo6xrAbze+B2+DNg8o49SmicDL9rrNt0A/CMzP6G/yhwWOmUXxwvzbzrkf+IOPpL+C+c9Hc1XfNLgeuNvM9uI1pb0Br225yv9KDsFc321Am3PuJb9/FV7AB3ldA9wG7HHOdTjnRoEf4P0PBH19w+Tr9rzzLd8CfS2w0D8SHsM7iPJcjmvKOr/t+F+ALc65xzJGPQf8ud/958CzF7q26eKc+zvnXJNzbgHeev2lc+6dwGrgbf5kgVpmAOfcYeCAmV3mD7oV2EyA17VvP3CdmZX6/+/p5Q70+vZNtm6fA97jn+1yHdCT0TQzNc65vHoAdwDbgV3Af891PdO0jK/H+xq2Afij/7gDr035F8AO4AWgJte1TtPy3wz82O++BPhPYCfwb0BRruubhuW9Cljnr+8fAtWFsK6BfwC2AhuBbwFFQVvfwHfxjhGM4n0be99k6xYwvLP4dgGv4p0BdFbvp0v/RUQCIt+aXEREZBIKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQPx/UI8XCRqMQyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  84.40828347206116\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.1469 - acc: 0.4696 - val_loss: 1.0403 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04028, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.9767 - acc: 0.5665 - val_loss: 0.9130 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.04028 to 0.91305, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8627 - acc: 0.6552 - val_loss: 0.8192 - val_acc: 0.6854\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.91305 to 0.81923, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7753 - acc: 0.7174 - val_loss: 0.7409 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81923 to 0.74086, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7018 - acc: 0.7582 - val_loss: 0.6715 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.74086 to 0.67154, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6371 - acc: 0.7872 - val_loss: 0.6099 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67154 to 0.60994, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5804 - acc: 0.8113 - val_loss: 0.5565 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60994 to 0.55646, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5318 - acc: 0.8291 - val_loss: 0.5120 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55646 to 0.51204, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4919 - acc: 0.8419 - val_loss: 0.4765 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51204 to 0.47648, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4603 - acc: 0.8509 - val_loss: 0.4490 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47648 to 0.44895, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4359 - acc: 0.8575 - val_loss: 0.4281 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44895 to 0.42810, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4168 - acc: 0.8624 - val_loss: 0.4119 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42810 to 0.41191, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4019 - acc: 0.8652 - val_loss: 0.3991 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.41191 to 0.39908, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3901 - acc: 0.8666 - val_loss: 0.3889 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.39908 to 0.38892, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3807 - acc: 0.8685 - val_loss: 0.3809 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.38892 to 0.38086, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3731 - acc: 0.8699 - val_loss: 0.3743 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38086 to 0.37432, saving model to Post_val_weights4.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3669 - acc: 0.8706 - val_loss: 0.3689 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37432 to 0.36889, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3616 - acc: 0.8712 - val_loss: 0.3644 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.36889 to 0.36439, saving model to Post_val_weights4.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3571 - acc: 0.8717 - val_loss: 0.3606 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36439 to 0.36058, saving model to Post_val_weights4.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3533 - acc: 0.8719 - val_loss: 0.3573 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36058 to 0.35730, saving model to Post_val_weights4.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3499 - acc: 0.8723 - val_loss: 0.3545 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.35730 to 0.35445, saving model to Post_val_weights4.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3470 - acc: 0.8725 - val_loss: 0.3520 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35445 to 0.35196, saving model to Post_val_weights4.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3444 - acc: 0.8728 - val_loss: 0.3498 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35196 to 0.34982, saving model to Post_val_weights4.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3421 - acc: 0.8732 - val_loss: 0.3479 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34982 to 0.34792, saving model to Post_val_weights4.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3401 - acc: 0.8731 - val_loss: 0.3463 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34792 to 0.34628, saving model to Post_val_weights4.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3383 - acc: 0.8734 - val_loss: 0.3447 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34628 to 0.34474, saving model to Post_val_weights4.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3367 - acc: 0.8736 - val_loss: 0.3435 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34474 to 0.34349, saving model to Post_val_weights4.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3353 - acc: 0.8737 - val_loss: 0.3421 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34349 to 0.34214, saving model to Post_val_weights4.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3340 - acc: 0.8739 - val_loss: 0.3412 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34214 to 0.34125, saving model to Post_val_weights4.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3329 - acc: 0.8740 - val_loss: 0.3400 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34125 to 0.34000, saving model to Post_val_weights4.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3318 - acc: 0.8742 - val_loss: 0.3394 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34000 to 0.33939, saving model to Post_val_weights4.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3308 - acc: 0.8742 - val_loss: 0.3383 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33939 to 0.33829, saving model to Post_val_weights4.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3299 - acc: 0.8742 - val_loss: 0.3377 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33829 to 0.33769, saving model to Post_val_weights4.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3291 - acc: 0.8743 - val_loss: 0.3370 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33769 to 0.33701, saving model to Post_val_weights4.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8743 - val_loss: 0.3363 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33701 to 0.33632, saving model to Post_val_weights4.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3275 - acc: 0.8743 - val_loss: 0.3358 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33632 to 0.33579, saving model to Post_val_weights4.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8744 - val_loss: 0.3352 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33579 to 0.33517, saving model to Post_val_weights4.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3262 - acc: 0.8745 - val_loss: 0.3347 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33517 to 0.33472, saving model to Post_val_weights4.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8745 - val_loss: 0.3342 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33472 to 0.33415, saving model to Post_val_weights4.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3250 - acc: 0.8746 - val_loss: 0.3338 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33415 to 0.33383, saving model to Post_val_weights4.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8746 - val_loss: 0.3332 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33383 to 0.33325, saving model to Post_val_weights4.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8749 - val_loss: 0.3331 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33325 to 0.33306, saving model to Post_val_weights4.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8750 - val_loss: 0.3325 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33306 to 0.33249, saving model to Post_val_weights4.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8751 - val_loss: 0.3323 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33249 to 0.33230, saving model to Post_val_weights4.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3225 - acc: 0.8750 - val_loss: 0.3318 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33230 to 0.33179, saving model to Post_val_weights4.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3220 - acc: 0.8751 - val_loss: 0.3316 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33179 to 0.33163, saving model to Post_val_weights4.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8751 - val_loss: 0.3312 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33163 to 0.33124, saving model to Post_val_weights4.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8752 - val_loss: 0.3310 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33124 to 0.33099, saving model to Post_val_weights4.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8753 - val_loss: 0.3307 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33099 to 0.33069, saving model to Post_val_weights4.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8754 - val_loss: 0.3305 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33069 to 0.33047, saving model to Post_val_weights4.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8754 - val_loss: 0.3302 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33047 to 0.33019, saving model to Post_val_weights4.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8753 - val_loss: 0.3300 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33019 to 0.33002, saving model to Post_val_weights4.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8756 - val_loss: 0.3298 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33002 to 0.32981, saving model to Post_val_weights4.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8758 - val_loss: 0.3296 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.32981 to 0.32960, saving model to Post_val_weights4.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8759 - val_loss: 0.3295 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.32960 to 0.32954, saving model to Post_val_weights4.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8758 - val_loss: 0.3293 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.32954 to 0.32930, saving model to Post_val_weights4.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8757 - val_loss: 0.3292 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.32930 to 0.32919, saving model to Post_val_weights4.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8758 - val_loss: 0.3291 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.32919 to 0.32906, saving model to Post_val_weights4.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8758 - val_loss: 0.3289 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.32906 to 0.32886, saving model to Post_val_weights4.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8760 - val_loss: 0.3288 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.32886 to 0.32884, saving model to Post_val_weights4.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8760 - val_loss: 0.3286 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.32884 to 0.32864, saving model to Post_val_weights4.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8760 - val_loss: 0.3287 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32864\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8761 - val_loss: 0.3285 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.32864 to 0.32849, saving model to Post_val_weights4.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8760 - val_loss: 0.3285 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.32849\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8762 - val_loss: 0.3283 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.32849 to 0.32832, saving model to Post_val_weights4.hdf5\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8762 - val_loss: 0.3283 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.32832\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8762 - val_loss: 0.3282 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.32832 to 0.32820, saving model to Post_val_weights4.hdf5\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8763 - val_loss: 0.3282 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.32820 to 0.32819, saving model to Post_val_weights4.hdf5\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8764 - val_loss: 0.3282 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32819\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8765 - val_loss: 0.3281 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.32819 to 0.32815, saving model to Post_val_weights4.hdf5\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8765 - val_loss: 0.3281 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.32815 to 0.32812, saving model to Post_val_weights4.hdf5\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8765 - val_loss: 0.3282 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.32812\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8766 - val_loss: 0.3281 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.32812 to 0.32808, saving model to Post_val_weights4.hdf5\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8766 - val_loss: 0.3282 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.32808\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8765 - val_loss: 0.3281 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.32808\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8767 - val_loss: 0.3282 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.32808\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8768 - val_loss: 0.3282 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32808\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8768 - val_loss: 0.3282 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.32808\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8768 - val_loss: 0.3282 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32808\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8768 - val_loss: 0.3284 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32808\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8768 - val_loss: 0.3283 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32808\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8769 - val_loss: 0.3286 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.32808\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8771 - val_loss: 0.3285 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.32808\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8772 - val_loss: 0.3287 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.32808\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8773 - val_loss: 0.3287 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32808\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8773 - val_loss: 0.3289 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.32808\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8773 - val_loss: 0.3289 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.32808\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8774 - val_loss: 0.3291 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.32808\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8775 - val_loss: 0.3292 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32808\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8776 - val_loss: 0.3294 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.32808\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8775 - val_loss: 0.3294 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.32808\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8776 - val_loss: 0.3296 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.32808\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8775 - val_loss: 0.3296 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32808\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8776 - val_loss: 0.3298 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.32808\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8776 - val_loss: 0.3299 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32808\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8777 - val_loss: 0.3301 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.32808\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8776 - val_loss: 0.3301 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32808\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8777 - val_loss: 0.3303 - val_acc: 0.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32808\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8777 - val_loss: 0.3304 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32808\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8777 - val_loss: 0.3306 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32808\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 8192\n",
      "Fold: 3\n",
      "best val loss: 0.32807612699374816\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  78.46728777885437\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.1465 - acc: 0.4699 - val_loss: 1.0424 - val_acc: 0.5181\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04238, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.9769 - acc: 0.5661 - val_loss: 0.9108 - val_acc: 0.6122\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.04238 to 0.91081, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8631 - acc: 0.6542 - val_loss: 0.8148 - val_acc: 0.6909\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.91081 to 0.81484, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7757 - acc: 0.7171 - val_loss: 0.7362 - val_acc: 0.7395\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81484 to 0.73623, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7018 - acc: 0.7581 - val_loss: 0.6678 - val_acc: 0.7751\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73623 to 0.66779, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6365 - acc: 0.7879 - val_loss: 0.6076 - val_acc: 0.7999\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.66779 to 0.60762, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5791 - acc: 0.8120 - val_loss: 0.5563 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60762 to 0.55630, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5302 - acc: 0.8298 - val_loss: 0.5147 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55630 to 0.51467, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4901 - acc: 0.8428 - val_loss: 0.4819 - val_acc: 0.8430\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51467 to 0.48185, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4586 - acc: 0.8513 - val_loss: 0.4565 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48185 to 0.45646, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4345 - acc: 0.8581 - val_loss: 0.4364 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.45646 to 0.43642, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4157 - acc: 0.8626 - val_loss: 0.4204 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43642 to 0.42038, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4008 - acc: 0.8656 - val_loss: 0.4076 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.42038 to 0.40759, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3890 - acc: 0.8674 - val_loss: 0.3974 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40759 to 0.39739, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3796 - acc: 0.8686 - val_loss: 0.3892 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.39739 to 0.38923, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3720 - acc: 0.8700 - val_loss: 0.3827 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38923 to 0.38270, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3657 - acc: 0.8710 - val_loss: 0.3773 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.38270 to 0.37730, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3605 - acc: 0.8716 - val_loss: 0.3727 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37730 to 0.37267, saving model to Post_val_weights5.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3560 - acc: 0.8724 - val_loss: 0.3687 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37267 to 0.36871, saving model to Post_val_weights5.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3521 - acc: 0.8726 - val_loss: 0.3653 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36871 to 0.36531, saving model to Post_val_weights5.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3487 - acc: 0.8728 - val_loss: 0.3624 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36531 to 0.36239, saving model to Post_val_weights5.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3458 - acc: 0.8733 - val_loss: 0.3599 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36239 to 0.35987, saving model to Post_val_weights5.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3432 - acc: 0.8735 - val_loss: 0.3577 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35987 to 0.35768, saving model to Post_val_weights5.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3409 - acc: 0.8738 - val_loss: 0.3558 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35768 to 0.35577, saving model to Post_val_weights5.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3389 - acc: 0.8739 - val_loss: 0.3541 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35577 to 0.35411, saving model to Post_val_weights5.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3371 - acc: 0.8742 - val_loss: 0.3526 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35411 to 0.35263, saving model to Post_val_weights5.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3355 - acc: 0.8744 - val_loss: 0.3513 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.35263 to 0.35125, saving model to Post_val_weights5.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3340 - acc: 0.8745 - val_loss: 0.3500 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.35125 to 0.35004, saving model to Post_val_weights5.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3327 - acc: 0.8744 - val_loss: 0.3490 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.35004 to 0.34899, saving model to Post_val_weights5.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3316 - acc: 0.8743 - val_loss: 0.3479 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34899 to 0.34787, saving model to Post_val_weights5.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3305 - acc: 0.8745 - val_loss: 0.3470 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34787 to 0.34702, saving model to Post_val_weights5.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8747 - val_loss: 0.3462 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.34702 to 0.34622, saving model to Post_val_weights5.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8748 - val_loss: 0.3455 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.34622 to 0.34553, saving model to Post_val_weights5.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3278 - acc: 0.8747 - val_loss: 0.3448 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.34553 to 0.34480, saving model to Post_val_weights5.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3270 - acc: 0.8746 - val_loss: 0.3442 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34480 to 0.34421, saving model to Post_val_weights5.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8746 - val_loss: 0.3436 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.34421 to 0.34364, saving model to Post_val_weights5.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3256 - acc: 0.8747 - val_loss: 0.3431 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.34364 to 0.34313, saving model to Post_val_weights5.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3250 - acc: 0.8749 - val_loss: 0.3426 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.34313 to 0.34265, saving model to Post_val_weights5.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8750 - val_loss: 0.3422 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.34265 to 0.34219, saving model to Post_val_weights5.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8750 - val_loss: 0.3418 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.34219 to 0.34180, saving model to Post_val_weights5.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3233 - acc: 0.8750 - val_loss: 0.3416 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.34180 to 0.34156, saving model to Post_val_weights5.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8751 - val_loss: 0.3410 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.34156 to 0.34095, saving model to Post_val_weights5.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8752 - val_loss: 0.3407 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.34095 to 0.34072, saving model to Post_val_weights5.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8753 - val_loss: 0.3403 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.34072 to 0.34034, saving model to Post_val_weights5.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8753 - val_loss: 0.3400 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.34034 to 0.34004, saving model to Post_val_weights5.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3211 - acc: 0.8754 - val_loss: 0.3398 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.34004 to 0.33975, saving model to Post_val_weights5.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8754 - val_loss: 0.3396 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33975 to 0.33958, saving model to Post_val_weights5.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8754 - val_loss: 0.3391 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33958 to 0.33914, saving model to Post_val_weights5.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8756 - val_loss: 0.3390 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33914 to 0.33896, saving model to Post_val_weights5.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8756 - val_loss: 0.3387 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33896 to 0.33868, saving model to Post_val_weights5.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8755 - val_loss: 0.3385 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33868 to 0.33845, saving model to Post_val_weights5.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8754 - val_loss: 0.3383 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33845 to 0.33829, saving model to Post_val_weights5.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8755 - val_loss: 0.3381 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33829 to 0.33814, saving model to Post_val_weights5.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8756 - val_loss: 0.3378 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.33814 to 0.33783, saving model to Post_val_weights5.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8758 - val_loss: 0.3378 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33783 to 0.33777, saving model to Post_val_weights5.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8757 - val_loss: 0.3375 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.33777 to 0.33751, saving model to Post_val_weights5.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8759 - val_loss: 0.3374 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33751 to 0.33737, saving model to Post_val_weights5.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8760 - val_loss: 0.3373 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.33737 to 0.33727, saving model to Post_val_weights5.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8761 - val_loss: 0.3372 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33727 to 0.33717, saving model to Post_val_weights5.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8762 - val_loss: 0.3370 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33717 to 0.33695, saving model to Post_val_weights5.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8762 - val_loss: 0.3369 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33695 to 0.33692, saving model to Post_val_weights5.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8762 - val_loss: 0.3367 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.33692 to 0.33674, saving model to Post_val_weights5.hdf5\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8761 - val_loss: 0.3367 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.33674 to 0.33669, saving model to Post_val_weights5.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8762 - val_loss: 0.3366 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.33669 to 0.33659, saving model to Post_val_weights5.hdf5\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8764 - val_loss: 0.3366 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33659\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8765 - val_loss: 0.3364 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.33659 to 0.33640, saving model to Post_val_weights5.hdf5\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8766 - val_loss: 0.3368 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33640\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8766 - val_loss: 0.3364 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.33640 to 0.33635, saving model to Post_val_weights5.hdf5\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8767 - val_loss: 0.3363 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.33635 to 0.33630, saving model to Post_val_weights5.hdf5\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8767 - val_loss: 0.3363 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.33630 to 0.33626, saving model to Post_val_weights5.hdf5\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8769 - val_loss: 0.3362 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.33626 to 0.33622, saving model to Post_val_weights5.hdf5\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8770 - val_loss: 0.3363 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33622\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8770 - val_loss: 0.3363 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33622\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8772 - val_loss: 0.3362 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33622\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8774 - val_loss: 0.3363 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33622\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8775 - val_loss: 0.3362 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.33622 to 0.33618, saving model to Post_val_weights5.hdf5\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8776 - val_loss: 0.3362 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33618\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8775 - val_loss: 0.3362 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.33618 to 0.33618, saving model to Post_val_weights5.hdf5\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8777 - val_loss: 0.3363 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33618\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8779 - val_loss: 0.3361 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.33618 to 0.33612, saving model to Post_val_weights5.hdf5\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8779 - val_loss: 0.3362 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33612\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8779 - val_loss: 0.3362 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33612\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8781 - val_loss: 0.3362 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33612\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8782 - val_loss: 0.3362 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33612\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8781 - val_loss: 0.3364 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33612\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8782 - val_loss: 0.3362 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33612\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8785 - val_loss: 0.3365 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33612\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8784 - val_loss: 0.3365 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33612\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8785 - val_loss: 0.3366 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33612\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8786 - val_loss: 0.3368 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33612\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8788 - val_loss: 0.3366 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33612\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8788 - val_loss: 0.3369 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33612\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8789 - val_loss: 0.3371 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33612\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8789 - val_loss: 0.3370 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33612\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8790 - val_loss: 0.3374 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33612\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8788 - val_loss: 0.3374 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33612\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8789 - val_loss: 0.3377 - val_acc: 0.8641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33612\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8790 - val_loss: 0.3377 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33612\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8790 - val_loss: 0.3379 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33612\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8791 - val_loss: 0.3380 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33612\n",
      "#################################\n",
      "Number of units: 16\n",
      "Batch size: 8192\n",
      "Fold: 4\n",
      "best val loss: 0.33612065163969296\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686], [16, 8192, 0, 0.3300208747317219], [16, 8192, 1, 0.330462209139651], [16, 8192, 2, 0.3360145849094056], [16, 8192, 3, 0.32807612699374816], [16, 8192, 4, 0.33612065163969296]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  77.95448589324951\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7137 - acc: 0.8062 - val_loss: 0.4708 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47075, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4094 - acc: 0.8687 - val_loss: 0.3839 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.47075 to 0.38387, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3603 - acc: 0.8709 - val_loss: 0.3587 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38387 to 0.35873, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3437 - acc: 0.8717 - val_loss: 0.3488 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35873 to 0.34882, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3367 - acc: 0.8720 - val_loss: 0.3438 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34882 to 0.34384, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3329 - acc: 0.8724 - val_loss: 0.3407 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34384 to 0.34072, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3307 - acc: 0.8729 - val_loss: 0.3388 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34072 to 0.33881, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3292 - acc: 0.8730 - val_loss: 0.3377 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33881 to 0.33766, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3283 - acc: 0.8736 - val_loss: 0.3369 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33766 to 0.33692, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3275 - acc: 0.8738 - val_loss: 0.3364 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33692 to 0.33636, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3270 - acc: 0.8734 - val_loss: 0.3359 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33636 to 0.33592, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8740 - val_loss: 0.3356 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33592 to 0.33564, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3261 - acc: 0.8740 - val_loss: 0.3359 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33564\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3257 - acc: 0.8745 - val_loss: 0.3360 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33564\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3254 - acc: 0.8743 - val_loss: 0.3365 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33564\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3249 - acc: 0.8745 - val_loss: 0.3365 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33564\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8747 - val_loss: 0.3373 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33564\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8750 - val_loss: 0.3373 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33564\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8748 - val_loss: 0.3381 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33564\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8753 - val_loss: 0.3389 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33564\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8753 - val_loss: 0.3397 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33564\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8752 - val_loss: 0.3404 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33564\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8757 - val_loss: 0.3414 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33564\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8758 - val_loss: 0.3417 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33564\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8759 - val_loss: 0.3424 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33564\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8762 - val_loss: 0.3427 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33564\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8763 - val_loss: 0.3436 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33564\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8766 - val_loss: 0.3439 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33564\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8768 - val_loss: 0.3442 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33564\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3204 - acc: 0.8766 - val_loss: 0.3449 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33564\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8771 - val_loss: 0.3452 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33564\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.3199 - acc: 0.8774 - val_loss: 0.3459 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33564\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8777 - val_loss: 0.3467 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33564\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8780 - val_loss: 0.3474 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33564\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8780 - val_loss: 0.3484 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33564\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.3190 - acc: 0.8785 - val_loss: 0.3495 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33564\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8785 - val_loss: 0.3505 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33564\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8786 - val_loss: 0.3516 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33564\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8785 - val_loss: 0.3535 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33564\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8785 - val_loss: 0.3539 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33564\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8790 - val_loss: 0.3551 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33564\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.3181 - acc: 0.8793 - val_loss: 0.3552 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33564\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8797 - val_loss: 0.3566 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33564\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8802 - val_loss: 0.3569 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33564\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8802 - val_loss: 0.3573 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33564\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8807 - val_loss: 0.3583 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33564\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8808 - val_loss: 0.3583 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33564\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8811 - val_loss: 0.3594 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33564\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8812 - val_loss: 0.3595 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33564\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8813 - val_loss: 0.3587 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33564\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8815 - val_loss: 0.3588 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33564\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8821 - val_loss: 0.3593 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33564\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8820 - val_loss: 0.3595 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33564\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8824 - val_loss: 0.3605 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33564\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8818 - val_loss: 0.3611 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33564\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8822 - val_loss: 0.3618 - val_acc: 0.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33564\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8818 - val_loss: 0.3624 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33564\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8821 - val_loss: 0.3616 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33564\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8824 - val_loss: 0.3627 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33564\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8830 - val_loss: 0.3631 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33564\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8830 - val_loss: 0.3654 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33564\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8831 - val_loss: 0.3653 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33564\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8833 - val_loss: 0.3681 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33564\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8833 - val_loss: 0.3683 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33564\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8833 - val_loss: 0.3697 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33564\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8832 - val_loss: 0.3699 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33564\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8834 - val_loss: 0.3714 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33564\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8832 - val_loss: 0.3709 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33564\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8837 - val_loss: 0.3714 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33564\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8837 - val_loss: 0.3727 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33564\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8839 - val_loss: 0.3722 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33564\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8836 - val_loss: 0.3723 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33564\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8834 - val_loss: 0.3733 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33564\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8835 - val_loss: 0.3730 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33564\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8832 - val_loss: 0.3731 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33564\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8836 - val_loss: 0.3729 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33564\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8836 - val_loss: 0.3727 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33564\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8836 - val_loss: 0.3731 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33564\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8834 - val_loss: 0.3727 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33564\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8836 - val_loss: 0.3734 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33564\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8831 - val_loss: 0.3744 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33564\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8834 - val_loss: 0.3751 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33564\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8836 - val_loss: 0.3746 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33564\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8840 - val_loss: 0.3759 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33564\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8838 - val_loss: 0.3767 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33564\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8841 - val_loss: 0.3762 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33564\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8838 - val_loss: 0.3775 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33564\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8840 - val_loss: 0.3778 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33564\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8836 - val_loss: 0.3779 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33564\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8850 - val_loss: 0.3770 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33564\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8843 - val_loss: 0.3779 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33564\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8843 - val_loss: 0.3777 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33564\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8845 - val_loss: 0.3778 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33564\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8840 - val_loss: 0.3788 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33564\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8845 - val_loss: 0.3779 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33564\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8840 - val_loss: 0.3799 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33564\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8844 - val_loss: 0.3789 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33564\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8839 - val_loss: 0.3797 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33564\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8842 - val_loss: 0.3813 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33564\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8843 - val_loss: 0.3768 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33564\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 512\n",
      "Fold: 0\n",
      "best val loss: 0.33564156908040854\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  152.0707983970642\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7109 - acc: 0.8078 - val_loss: 0.4653 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46533, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4089 - acc: 0.8691 - val_loss: 0.3780 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46533 to 0.37805, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3597 - acc: 0.8710 - val_loss: 0.3536 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37805 to 0.35359, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3436 - acc: 0.8719 - val_loss: 0.3442 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35359 to 0.34419, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3366 - acc: 0.8722 - val_loss: 0.3398 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34419 to 0.33985, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3331 - acc: 0.8725 - val_loss: 0.3379 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33985 to 0.33787, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3308 - acc: 0.8724 - val_loss: 0.3368 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33787 to 0.33678, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3293 - acc: 0.8728 - val_loss: 0.3362 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33678 to 0.33624, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8730 - val_loss: 0.3363 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.33624\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3275 - acc: 0.8731 - val_loss: 0.3365 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33624\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3269 - acc: 0.8732 - val_loss: 0.3368 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.33624\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3262 - acc: 0.8738 - val_loss: 0.3371 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33624\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3258 - acc: 0.8743 - val_loss: 0.3370 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33624\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3254 - acc: 0.8747 - val_loss: 0.3374 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33624\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3250 - acc: 0.8747 - val_loss: 0.3379 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33624\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3246 - acc: 0.8747 - val_loss: 0.3373 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33624\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8749 - val_loss: 0.3378 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33624\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8750 - val_loss: 0.3386 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33624\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8755 - val_loss: 0.3391 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33624\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8756 - val_loss: 0.3396 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33624\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8761 - val_loss: 0.3413 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33624\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8765 - val_loss: 0.3407 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33624\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8765 - val_loss: 0.3420 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33624\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8767 - val_loss: 0.3422 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33624\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8769 - val_loss: 0.3439 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33624\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8770 - val_loss: 0.3434 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33624\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8770 - val_loss: 0.3442 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33624\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8771 - val_loss: 0.3443 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33624\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8771 - val_loss: 0.3452 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33624\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8773 - val_loss: 0.3453 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33624\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8776 - val_loss: 0.3463 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33624\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8777 - val_loss: 0.3469 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33624\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8780 - val_loss: 0.3476 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33624\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8789 - val_loss: 0.3486 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33624\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8786 - val_loss: 0.3489 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33624\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8792 - val_loss: 0.3492 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33624\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8792 - val_loss: 0.3502 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33624\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8795 - val_loss: 0.3522 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33624\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8795 - val_loss: 0.3536 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33624\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8796 - val_loss: 0.3528 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33624\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8795 - val_loss: 0.3537 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33624\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8795 - val_loss: 0.3545 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33624\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8796 - val_loss: 0.3554 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33624\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8796 - val_loss: 0.3555 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33624\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8799 - val_loss: 0.3560 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33624\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8805 - val_loss: 0.3571 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33624\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8806 - val_loss: 0.3560 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33624\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8807 - val_loss: 0.3562 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33624\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8806 - val_loss: 0.3570 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33624\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8811 - val_loss: 0.3576 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33624\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8811 - val_loss: 0.3592 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33624\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8815 - val_loss: 0.3595 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33624\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8819 - val_loss: 0.3602 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33624\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8817 - val_loss: 0.3602 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33624\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8819 - val_loss: 0.3616 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33624\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8822 - val_loss: 0.3634 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33624\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8822 - val_loss: 0.3644 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33624\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3140 - acc: 0.8822 - val_loss: 0.3647 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33624\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8823 - val_loss: 0.3643 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33624\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8825 - val_loss: 0.3655 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33624\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8822 - val_loss: 0.3641 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33624\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8828 - val_loss: 0.3661 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33624\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8827 - val_loss: 0.3679 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33624\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8827 - val_loss: 0.3683 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33624\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8828 - val_loss: 0.3681 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33624\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8828 - val_loss: 0.3693 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33624\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8828 - val_loss: 0.3711 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33624\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8829 - val_loss: 0.3710 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33624\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8833 - val_loss: 0.3728 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33624\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8832 - val_loss: 0.3720 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33624\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8832 - val_loss: 0.3726 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33624\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8833 - val_loss: 0.3726 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33624\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8842 - val_loss: 0.3724 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33624\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8841 - val_loss: 0.3732 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33624\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8842 - val_loss: 0.3752 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33624\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8843 - val_loss: 0.3754 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33624\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8837 - val_loss: 0.3772 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33624\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8837 - val_loss: 0.3752 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33624\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8844 - val_loss: 0.3777 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33624\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8843 - val_loss: 0.3778 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33624\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8838 - val_loss: 0.3772 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33624\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8841 - val_loss: 0.3796 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33624\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8840 - val_loss: 0.3804 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33624\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8844 - val_loss: 0.3793 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33624\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8839 - val_loss: 0.3794 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33624\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8847 - val_loss: 0.3773 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33624\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8843 - val_loss: 0.3757 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33624\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8849 - val_loss: 0.3753 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33624\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8845 - val_loss: 0.3748 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33624\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8852 - val_loss: 0.3761 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33624\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8852 - val_loss: 0.3778 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33624\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8852 - val_loss: 0.3799 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33624\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8848 - val_loss: 0.3794 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33624\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8848 - val_loss: 0.3813 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33624\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8845 - val_loss: 0.3807 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33624\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8850 - val_loss: 0.3805 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33624\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8846 - val_loss: 0.3834 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33624\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8848 - val_loss: 0.3822 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33624\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8847 - val_loss: 0.3824 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33624\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8842 - val_loss: 0.3840 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33624\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 512\n",
      "Fold: 1\n",
      "best val loss: 0.3362385708755917\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  152.6981680393219\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7094 - acc: 0.8090 - val_loss: 0.4712 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47124, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4080 - acc: 0.8692 - val_loss: 0.3828 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.47124 to 0.38277, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3587 - acc: 0.8718 - val_loss: 0.3586 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38277 to 0.35856, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3428 - acc: 0.8723 - val_loss: 0.3491 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35856 to 0.34907, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3358 - acc: 0.8725 - val_loss: 0.3447 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34907 to 0.34470, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3321 - acc: 0.8729 - val_loss: 0.3429 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34470 to 0.34288, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3302 - acc: 0.8731 - val_loss: 0.3416 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34288 to 0.34165, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3287 - acc: 0.8731 - val_loss: 0.3408 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34165 to 0.34079, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3278 - acc: 0.8732 - val_loss: 0.3404 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34079 to 0.34036, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3270 - acc: 0.8737 - val_loss: 0.3401 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34036 to 0.34014, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8737 - val_loss: 0.3401 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34014 to 0.34011, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3257 - acc: 0.8744 - val_loss: 0.3406 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34011\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8747 - val_loss: 0.3411 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34011\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8752 - val_loss: 0.3418 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34011\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8753 - val_loss: 0.3430 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34011\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8755 - val_loss: 0.3431 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34011\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3237 - acc: 0.8756 - val_loss: 0.3437 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34011\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8759 - val_loss: 0.3442 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34011\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3232 - acc: 0.8762 - val_loss: 0.3448 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34011\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8768 - val_loss: 0.3456 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34011\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8769 - val_loss: 0.3460 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34011\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8771 - val_loss: 0.3469 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34011\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8772 - val_loss: 0.3473 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34011\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8775 - val_loss: 0.3479 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34011\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8777 - val_loss: 0.3478 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34011\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8778 - val_loss: 0.3485 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34011\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8780 - val_loss: 0.3498 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34011\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8783 - val_loss: 0.3502 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34011\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8789 - val_loss: 0.3509 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34011\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8789 - val_loss: 0.3515 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34011\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8792 - val_loss: 0.3525 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34011\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8792 - val_loss: 0.3515 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34011\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8796 - val_loss: 0.3522 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34011\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8798 - val_loss: 0.3527 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34011\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8800 - val_loss: 0.3533 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34011\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8798 - val_loss: 0.3539 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34011\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8800 - val_loss: 0.3549 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34011\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8797 - val_loss: 0.3547 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34011\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8797 - val_loss: 0.3546 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34011\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8801 - val_loss: 0.3553 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34011\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8803 - val_loss: 0.3574 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34011\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8807 - val_loss: 0.3581 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34011\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8810 - val_loss: 0.3585 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34011\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8812 - val_loss: 0.3601 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34011\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8812 - val_loss: 0.3611 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34011\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8815 - val_loss: 0.3610 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34011\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8813 - val_loss: 0.3625 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34011\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8811 - val_loss: 0.3636 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34011\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8815 - val_loss: 0.3646 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34011\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8815 - val_loss: 0.3641 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34011\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8816 - val_loss: 0.3648 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34011\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8817 - val_loss: 0.3657 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34011\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8823 - val_loss: 0.3658 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34011\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8826 - val_loss: 0.3665 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34011\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8824 - val_loss: 0.3669 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34011\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8829 - val_loss: 0.3662 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34011\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3131 - acc: 0.8831 - val_loss: 0.3675 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34011\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8833 - val_loss: 0.3681 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34011\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8834 - val_loss: 0.3708 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34011\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8838 - val_loss: 0.3716 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34011\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8834 - val_loss: 0.3727 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34011\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8829 - val_loss: 0.3736 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34011\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8834 - val_loss: 0.3725 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34011\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8833 - val_loss: 0.3727 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34011\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3120 - acc: 0.8832 - val_loss: 0.3735 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34011\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8835 - val_loss: 0.3740 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34011\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8838 - val_loss: 0.3744 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34011\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8831 - val_loss: 0.3741 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34011\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8834 - val_loss: 0.3755 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34011\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8833 - val_loss: 0.3767 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34011\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8841 - val_loss: 0.3758 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34011\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8839 - val_loss: 0.3772 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34011\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8833 - val_loss: 0.3772 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34011\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8831 - val_loss: 0.3783 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34011\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8833 - val_loss: 0.3764 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34011\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8831 - val_loss: 0.3777 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34011\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8832 - val_loss: 0.3775 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34011\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8832 - val_loss: 0.3776 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34011\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8829 - val_loss: 0.3768 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34011\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8834 - val_loss: 0.3768 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34011\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8835 - val_loss: 0.3758 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34011\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8836 - val_loss: 0.3760 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34011\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8829 - val_loss: 0.3781 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34011\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8832 - val_loss: 0.3788 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34011\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8837 - val_loss: 0.3792 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34011\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8835 - val_loss: 0.3781 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34011\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8833 - val_loss: 0.3791 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34011\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8838 - val_loss: 0.3795 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34011\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8833 - val_loss: 0.3804 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34011\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8840 - val_loss: 0.3794 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34011\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8836 - val_loss: 0.3797 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34011\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8841 - val_loss: 0.3800 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34011\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8843 - val_loss: 0.3778 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34011\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8846 - val_loss: 0.3819 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34011\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8846 - val_loss: 0.3805 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34011\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8853 - val_loss: 0.3819 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34011\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8848 - val_loss: 0.3823 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34011\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8850 - val_loss: 0.3827 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34011\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8852 - val_loss: 0.3835 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34011\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8854 - val_loss: 0.3853 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34011\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 512\n",
      "Fold: 2\n",
      "best val loss: 0.34011004318270766\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  153.12201070785522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f676d3c2fd0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7101 - acc: 0.8075 - val_loss: 0.4658 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46579, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4084 - acc: 0.8689 - val_loss: 0.3773 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46579 to 0.37732, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3594 - acc: 0.8710 - val_loss: 0.3516 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37732 to 0.35159, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3433 - acc: 0.8714 - val_loss: 0.3421 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35159 to 0.34211, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3365 - acc: 0.8715 - val_loss: 0.3379 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34211 to 0.33792, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3329 - acc: 0.8719 - val_loss: 0.3362 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33792 to 0.33618, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3308 - acc: 0.8721 - val_loss: 0.3354 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33618 to 0.33541, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3293 - acc: 0.8727 - val_loss: 0.3355 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.33541\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3283 - acc: 0.8730 - val_loss: 0.3359 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.33541\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3274 - acc: 0.8732 - val_loss: 0.3368 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33541\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3269 - acc: 0.8734 - val_loss: 0.3369 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.33541\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3264 - acc: 0.8733 - val_loss: 0.3376 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33541\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3259 - acc: 0.8735 - val_loss: 0.3381 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33541\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3253 - acc: 0.8737 - val_loss: 0.3383 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33541\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3251 - acc: 0.8737 - val_loss: 0.3388 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33541\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8741 - val_loss: 0.3395 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33541\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8747 - val_loss: 0.3398 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33541\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8747 - val_loss: 0.3407 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33541\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3236 - acc: 0.8750 - val_loss: 0.3413 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33541\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3233 - acc: 0.8751 - val_loss: 0.3419 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33541\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8754 - val_loss: 0.3433 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33541\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8756 - val_loss: 0.3439 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33541\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8755 - val_loss: 0.3448 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33541\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8756 - val_loss: 0.3453 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33541\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8759 - val_loss: 0.3462 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33541\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8758 - val_loss: 0.3464 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33541\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8762 - val_loss: 0.3471 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33541\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8763 - val_loss: 0.3481 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33541\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8763 - val_loss: 0.3485 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33541\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.3202 - acc: 0.8771 - val_loss: 0.3489 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33541\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.3200 - acc: 0.8774 - val_loss: 0.3497 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33541\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8775 - val_loss: 0.3502 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33541\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8775 - val_loss: 0.3519 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33541\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8778 - val_loss: 0.3529 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33541\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8780 - val_loss: 0.3535 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33541\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8780 - val_loss: 0.3544 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33541\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8782 - val_loss: 0.3551 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33541\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8783 - val_loss: 0.3558 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33541\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8785 - val_loss: 0.3565 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33541\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8786 - val_loss: 0.3576 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33541\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8784 - val_loss: 0.3581 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33541\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8781 - val_loss: 0.3594 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33541\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8784 - val_loss: 0.3596 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33541\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8787 - val_loss: 0.3609 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33541\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8789 - val_loss: 0.3607 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33541\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8797 - val_loss: 0.3622 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33541\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8796 - val_loss: 0.3636 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33541\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8796 - val_loss: 0.3649 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33541\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8795 - val_loss: 0.3665 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33541\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8801 - val_loss: 0.3670 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33541\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8793 - val_loss: 0.3672 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33541\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8797 - val_loss: 0.3680 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33541\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8804 - val_loss: 0.3675 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33541\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8805 - val_loss: 0.3661 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33541\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8804 - val_loss: 0.3673 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33541\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8804 - val_loss: 0.3666 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33541\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8808 - val_loss: 0.3672 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33541\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8809 - val_loss: 0.3674 - val_acc: 0.8628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33541\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8810 - val_loss: 0.3657 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33541\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8807 - val_loss: 0.3665 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33541\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8805 - val_loss: 0.3662 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33541\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8808 - val_loss: 0.3671 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33541\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8813 - val_loss: 0.3677 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33541\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8812 - val_loss: 0.3682 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33541\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8813 - val_loss: 0.3719 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33541\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8813 - val_loss: 0.3709 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33541\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8812 - val_loss: 0.3712 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33541\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8818 - val_loss: 0.3701 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33541\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8821 - val_loss: 0.3680 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33541\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8816 - val_loss: 0.3675 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33541\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8821 - val_loss: 0.3683 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33541\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8821 - val_loss: 0.3694 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33541\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8820 - val_loss: 0.3693 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33541\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8819 - val_loss: 0.3706 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33541\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8817 - val_loss: 0.3722 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33541\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8817 - val_loss: 0.3716 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33541\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8819 - val_loss: 0.3703 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33541\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8822 - val_loss: 0.3719 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33541\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8822 - val_loss: 0.3725 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33541\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8825 - val_loss: 0.3727 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33541\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8829 - val_loss: 0.3728 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33541\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8831 - val_loss: 0.3720 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33541\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8832 - val_loss: 0.3724 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33541\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8837 - val_loss: 0.3741 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33541\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8837 - val_loss: 0.3737 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33541\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8836 - val_loss: 0.3722 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33541\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8828 - val_loss: 0.3740 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33541\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8830 - val_loss: 0.3726 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33541\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8835 - val_loss: 0.3745 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33541\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8838 - val_loss: 0.3747 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33541\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8839 - val_loss: 0.3756 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33541\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8841 - val_loss: 0.3756 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33541\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8845 - val_loss: 0.3754 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33541\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8837 - val_loss: 0.3764 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33541\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8840 - val_loss: 0.3768 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33541\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8834 - val_loss: 0.3762 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33541\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8831 - val_loss: 0.3737 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33541\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8834 - val_loss: 0.3743 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33541\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8828 - val_loss: 0.3751 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33541\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8824 - val_loss: 0.3749 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33541\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 512\n",
      "Fold: 3\n",
      "best val loss: 0.33541222581389357\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  153.95717525482178\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.7131 - acc: 0.8072 - val_loss: 0.4759 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47595, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.4077 - acc: 0.8695 - val_loss: 0.3855 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.47595 to 0.38547, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3583 - acc: 0.8718 - val_loss: 0.3609 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38547 to 0.36094, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3422 - acc: 0.8724 - val_loss: 0.3515 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36094 to 0.35152, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3354 - acc: 0.8728 - val_loss: 0.3471 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35152 to 0.34713, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3319 - acc: 0.8729 - val_loss: 0.3450 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34713 to 0.34499, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.3297 - acc: 0.8730 - val_loss: 0.3439 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34499 to 0.34386, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3281 - acc: 0.8733 - val_loss: 0.3432 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34386 to 0.34324, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.3271 - acc: 0.8736 - val_loss: 0.3429 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34324 to 0.34294, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.3263 - acc: 0.8739 - val_loss: 0.3433 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34294\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3257 - acc: 0.8740 - val_loss: 0.3434 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34294\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8741 - val_loss: 0.3436 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34294\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8744 - val_loss: 0.3437 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34294\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3246 - acc: 0.8746 - val_loss: 0.3441 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34294\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3241 - acc: 0.8751 - val_loss: 0.3444 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34294\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8754 - val_loss: 0.3450 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34294\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8755 - val_loss: 0.3448 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34294\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8762 - val_loss: 0.3451 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34294\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8759 - val_loss: 0.3457 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34294\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8761 - val_loss: 0.3464 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34294\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8764 - val_loss: 0.3470 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34294\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8767 - val_loss: 0.3483 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34294\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8768 - val_loss: 0.3487 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34294\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8772 - val_loss: 0.3499 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34294\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8773 - val_loss: 0.3501 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34294\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8776 - val_loss: 0.3510 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34294\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3204 - acc: 0.8777 - val_loss: 0.3515 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34294\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8775 - val_loss: 0.3531 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34294\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8779 - val_loss: 0.3532 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34294\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8776 - val_loss: 0.3547 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34294\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8780 - val_loss: 0.3559 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34294\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8781 - val_loss: 0.3558 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34294\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.3186 - acc: 0.8783 - val_loss: 0.3572 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34294\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8785 - val_loss: 0.3584 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34294\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8789 - val_loss: 0.3584 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34294\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8789 - val_loss: 0.3588 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34294\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8790 - val_loss: 0.3598 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34294\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8793 - val_loss: 0.3609 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34294\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8790 - val_loss: 0.3611 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34294\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8795 - val_loss: 0.3613 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34294\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8797 - val_loss: 0.3620 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34294\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8794 - val_loss: 0.3633 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34294\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8796 - val_loss: 0.3637 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34294\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8803 - val_loss: 0.3639 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34294\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8800 - val_loss: 0.3647 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34294\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8798 - val_loss: 0.3650 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34294\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8803 - val_loss: 0.3651 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34294\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8801 - val_loss: 0.3657 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34294\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.3152 - acc: 0.8805 - val_loss: 0.3666 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34294\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8805 - val_loss: 0.3665 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34294\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8803 - val_loss: 0.3672 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34294\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8806 - val_loss: 0.3674 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34294\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8803 - val_loss: 0.3687 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34294\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8803 - val_loss: 0.3688 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34294\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8806 - val_loss: 0.3684 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34294\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.3142 - acc: 0.8805 - val_loss: 0.3685 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34294\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8811 - val_loss: 0.3706 - val_acc: 0.8558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34294\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8812 - val_loss: 0.3712 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34294\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8817 - val_loss: 0.3726 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34294\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8819 - val_loss: 0.3716 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34294\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8819 - val_loss: 0.3709 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34294\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.3128 - acc: 0.8824 - val_loss: 0.3714 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34294\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8820 - val_loss: 0.3714 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34294\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8825 - val_loss: 0.3706 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34294\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8822 - val_loss: 0.3720 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34294\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8825 - val_loss: 0.3718 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34294\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8826 - val_loss: 0.3736 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34294\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8830 - val_loss: 0.3732 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34294\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8832 - val_loss: 0.3740 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34294\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8830 - val_loss: 0.3728 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34294\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8832 - val_loss: 0.3743 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34294\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8835 - val_loss: 0.3750 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34294\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8832 - val_loss: 0.3751 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34294\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8833 - val_loss: 0.3750 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34294\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8834 - val_loss: 0.3757 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34294\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8835 - val_loss: 0.3746 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34294\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8832 - val_loss: 0.3740 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34294\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8836 - val_loss: 0.3757 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34294\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8832 - val_loss: 0.3780 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34294\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8837 - val_loss: 0.3762 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34294\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8839 - val_loss: 0.3765 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34294\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8839 - val_loss: 0.3776 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34294\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8837 - val_loss: 0.3804 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34294\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8835 - val_loss: 0.3811 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34294\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8837 - val_loss: 0.3810 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34294\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8837 - val_loss: 0.3806 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34294\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8836 - val_loss: 0.3827 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34294\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8839 - val_loss: 0.3823 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34294\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8840 - val_loss: 0.3841 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34294\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8843 - val_loss: 0.3858 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34294\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.3102 - acc: 0.8843 - val_loss: 0.3852 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34294\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8844 - val_loss: 0.3849 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34294\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8841 - val_loss: 0.3834 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34294\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8837 - val_loss: 0.3834 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34294\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8844 - val_loss: 0.3813 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34294\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8842 - val_loss: 0.3806 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34294\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8846 - val_loss: 0.3818 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34294\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8850 - val_loss: 0.3820 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34294\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8849 - val_loss: 0.3815 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34294\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.3088 - acc: 0.8845 - val_loss: 0.3801 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34294\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 512\n",
      "Fold: 4\n",
      "best val loss: 0.3429361226684169\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686], [16, 8192, 0, 0.3300208747317219], [16, 8192, 1, 0.330462209139651], [16, 8192, 2, 0.3360145849094056], [16, 8192, 3, 0.32807612699374816], [16, 8192, 4, 0.33612065163969296], [32, 512, 0, 0.33564156908040854], [32, 512, 1, 0.3362385708755917], [32, 512, 2, 0.34011004318270766], [32, 512, 3, 0.33541222581389357], [32, 512, 4, 0.3429361226684169]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  155.92205452919006\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.8699 - acc: 0.7613 - val_loss: 0.6010 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60104, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4990 - acc: 0.8636 - val_loss: 0.4431 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60104 to 0.44311, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4033 - acc: 0.8704 - val_loss: 0.3895 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44311 to 0.38952, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3671 - acc: 0.8718 - val_loss: 0.3660 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38952 to 0.36596, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3501 - acc: 0.8722 - val_loss: 0.3539 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36596 to 0.35390, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3411 - acc: 0.8726 - val_loss: 0.3473 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35390 to 0.34732, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3357 - acc: 0.8733 - val_loss: 0.3432 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34732 to 0.34318, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3322 - acc: 0.8735 - val_loss: 0.3410 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34318 to 0.34103, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3298 - acc: 0.8735 - val_loss: 0.3396 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34103 to 0.33963, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3281 - acc: 0.8738 - val_loss: 0.3392 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33963 to 0.33916, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3266 - acc: 0.8742 - val_loss: 0.3385 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33916 to 0.33846, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3257 - acc: 0.8744 - val_loss: 0.3385 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33846\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8744 - val_loss: 0.3381 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33846 to 0.33812, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8745 - val_loss: 0.3383 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33812\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8749 - val_loss: 0.3382 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33812\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8753 - val_loss: 0.3385 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33812\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8758 - val_loss: 0.3385 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33812\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3217 - acc: 0.8759 - val_loss: 0.3388 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33812\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8760 - val_loss: 0.3391 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33812\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8762 - val_loss: 0.3398 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33812\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8763 - val_loss: 0.3397 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33812\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8765 - val_loss: 0.3400 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33812\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8768 - val_loss: 0.3411 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33812\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8768 - val_loss: 0.3409 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33812\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8772 - val_loss: 0.3418 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33812\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8775 - val_loss: 0.3422 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33812\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8776 - val_loss: 0.3427 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33812\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8780 - val_loss: 0.3438 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33812\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8784 - val_loss: 0.3440 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33812\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8785 - val_loss: 0.3443 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33812\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8785 - val_loss: 0.3457 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33812\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8788 - val_loss: 0.3462 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33812\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8789 - val_loss: 0.3464 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33812\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8794 - val_loss: 0.3468 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33812\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8792 - val_loss: 0.3474 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33812\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8796 - val_loss: 0.3481 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33812\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8801 - val_loss: 0.3483 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33812\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8804 - val_loss: 0.3486 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33812\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8802 - val_loss: 0.3496 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33812\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8802 - val_loss: 0.3502 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33812\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8805 - val_loss: 0.3506 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33812\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8807 - val_loss: 0.3517 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33812\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8808 - val_loss: 0.3522 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33812\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8812 - val_loss: 0.3525 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33812\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8813 - val_loss: 0.3533 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33812\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8818 - val_loss: 0.3535 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33812\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8819 - val_loss: 0.3540 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33812\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8821 - val_loss: 0.3553 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33812\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8826 - val_loss: 0.3560 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33812\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8829 - val_loss: 0.3563 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33812\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8833 - val_loss: 0.3569 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33812\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8828 - val_loss: 0.3576 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33812\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8833 - val_loss: 0.3583 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33812\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8838 - val_loss: 0.3587 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33812\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8839 - val_loss: 0.3588 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33812\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8839 - val_loss: 0.3603 - val_acc: 0.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33812\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8840 - val_loss: 0.3609 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33812\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8844 - val_loss: 0.3625 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33812\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8844 - val_loss: 0.3628 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33812\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8847 - val_loss: 0.3633 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33812\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8848 - val_loss: 0.3638 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33812\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8851 - val_loss: 0.3652 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33812\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8851 - val_loss: 0.3662 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33812\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8852 - val_loss: 0.3662 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33812\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8849 - val_loss: 0.3671 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33812\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8849 - val_loss: 0.3677 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33812\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3055 - acc: 0.8850 - val_loss: 0.3682 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33812\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8852 - val_loss: 0.3693 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33812\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8858 - val_loss: 0.3700 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33812\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8857 - val_loss: 0.3713 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33812\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8854 - val_loss: 0.3721 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33812\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8857 - val_loss: 0.3730 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33812\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3040 - acc: 0.8855 - val_loss: 0.3720 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33812\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8860 - val_loss: 0.3739 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33812\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8860 - val_loss: 0.3734 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33812\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8861 - val_loss: 0.3739 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33812\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8862 - val_loss: 0.3751 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33812\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8864 - val_loss: 0.3747 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33812\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8867 - val_loss: 0.3740 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33812\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8870 - val_loss: 0.3741 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33812\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3026 - acc: 0.8870 - val_loss: 0.3734 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33812\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3026 - acc: 0.8867 - val_loss: 0.3745 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33812\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8867 - val_loss: 0.3742 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33812\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8871 - val_loss: 0.3749 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33812\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8870 - val_loss: 0.3747 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33812\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8869 - val_loss: 0.3754 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33812\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8870 - val_loss: 0.3768 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33812\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8874 - val_loss: 0.3762 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33812\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3013 - acc: 0.8873 - val_loss: 0.3776 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33812\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3010 - acc: 0.8872 - val_loss: 0.3771 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33812\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3007 - acc: 0.8875 - val_loss: 0.3789 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33812\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3006 - acc: 0.8877 - val_loss: 0.3784 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33812\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8875 - val_loss: 0.3787 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33812\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3007 - acc: 0.8875 - val_loss: 0.3789 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33812\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3004 - acc: 0.8876 - val_loss: 0.3792 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33812\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3002 - acc: 0.8878 - val_loss: 0.3800 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33812\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8877 - val_loss: 0.3803 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33812\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3001 - acc: 0.8882 - val_loss: 0.3808 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33812\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8878 - val_loss: 0.3811 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33812\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8882 - val_loss: 0.3822 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33812\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 1024\n",
      "Fold: 0\n",
      "best val loss: 0.3381186140141292\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  100.947909116745\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.8674 - acc: 0.7634 - val_loss: 0.5934 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59336, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4976 - acc: 0.8646 - val_loss: 0.4384 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59336 to 0.43842, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4026 - acc: 0.8706 - val_loss: 0.3868 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43842 to 0.38679, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3666 - acc: 0.8720 - val_loss: 0.3641 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38679 to 0.36415, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3497 - acc: 0.8725 - val_loss: 0.3523 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36415 to 0.35232, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3409 - acc: 0.8729 - val_loss: 0.3458 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35232 to 0.34578, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3355 - acc: 0.8733 - val_loss: 0.3420 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34578 to 0.34204, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3322 - acc: 0.8734 - val_loss: 0.3396 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34204 to 0.33956, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3298 - acc: 0.8736 - val_loss: 0.3380 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33956 to 0.33795, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3279 - acc: 0.8739 - val_loss: 0.3374 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33795 to 0.33740, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3267 - acc: 0.8739 - val_loss: 0.3369 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33740 to 0.33694, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8743 - val_loss: 0.3372 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33694\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3246 - acc: 0.8747 - val_loss: 0.3375 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33694\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8748 - val_loss: 0.3378 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33694\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3233 - acc: 0.8753 - val_loss: 0.3382 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33694\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8754 - val_loss: 0.3385 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33694\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8757 - val_loss: 0.3386 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33694\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8757 - val_loss: 0.3390 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33694\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8761 - val_loss: 0.3392 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33694\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8764 - val_loss: 0.3394 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33694\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8764 - val_loss: 0.3400 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33694\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8764 - val_loss: 0.3408 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33694\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8764 - val_loss: 0.3409 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33694\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8769 - val_loss: 0.3416 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33694\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8771 - val_loss: 0.3424 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33694\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8773 - val_loss: 0.3425 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33694\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8778 - val_loss: 0.3430 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33694\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8779 - val_loss: 0.3437 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33694\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8780 - val_loss: 0.3441 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33694\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8783 - val_loss: 0.3448 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33694\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8784 - val_loss: 0.3458 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33694\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8788 - val_loss: 0.3463 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33694\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8789 - val_loss: 0.3472 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33694\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8792 - val_loss: 0.3492 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33694\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8793 - val_loss: 0.3500 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33694\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8793 - val_loss: 0.3512 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33694\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8795 - val_loss: 0.3522 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33694\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8797 - val_loss: 0.3536 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33694\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8803 - val_loss: 0.3548 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33694\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8809 - val_loss: 0.3556 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33694\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8812 - val_loss: 0.3573 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33694\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8813 - val_loss: 0.3582 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33694\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8815 - val_loss: 0.3596 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33694\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8818 - val_loss: 0.3611 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33694\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8824 - val_loss: 0.3616 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33694\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8826 - val_loss: 0.3639 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33694\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8826 - val_loss: 0.3640 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33694\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8832 - val_loss: 0.3642 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33694\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8831 - val_loss: 0.3645 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33694\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3101 - acc: 0.8835 - val_loss: 0.3653 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33694\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8833 - val_loss: 0.3666 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33694\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8837 - val_loss: 0.3668 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33694\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8841 - val_loss: 0.3682 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33694\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8844 - val_loss: 0.3679 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33694\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8845 - val_loss: 0.3683 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33694\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8849 - val_loss: 0.3697 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33694\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3082 - acc: 0.8848 - val_loss: 0.3699 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33694\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8851 - val_loss: 0.3703 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33694\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8851 - val_loss: 0.3705 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33694\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8851 - val_loss: 0.3703 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33694\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8850 - val_loss: 0.3709 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33694\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8854 - val_loss: 0.3713 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33694\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8850 - val_loss: 0.3716 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33694\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8848 - val_loss: 0.3711 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33694\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8847 - val_loss: 0.3714 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33694\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8848 - val_loss: 0.3713 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33694\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8850 - val_loss: 0.3714 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33694\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8849 - val_loss: 0.3723 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33694\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8852 - val_loss: 0.3730 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33694\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8855 - val_loss: 0.3731 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33694\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8857 - val_loss: 0.3731 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33694\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8859 - val_loss: 0.3736 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33694\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8861 - val_loss: 0.3743 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33694\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8862 - val_loss: 0.3745 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33694\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3050 - acc: 0.8862 - val_loss: 0.3751 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33694\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8868 - val_loss: 0.3751 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33694\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8866 - val_loss: 0.3757 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33694\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8864 - val_loss: 0.3770 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33694\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8869 - val_loss: 0.3773 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33694\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8870 - val_loss: 0.3776 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33694\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3036 - acc: 0.8869 - val_loss: 0.3786 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33694\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8871 - val_loss: 0.3789 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33694\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3033 - acc: 0.8871 - val_loss: 0.3783 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33694\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3028 - acc: 0.8872 - val_loss: 0.3792 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33694\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3028 - acc: 0.8873 - val_loss: 0.3795 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33694\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3027 - acc: 0.8870 - val_loss: 0.3796 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33694\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3022 - acc: 0.8875 - val_loss: 0.3803 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33694\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8872 - val_loss: 0.3812 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33694\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3023 - acc: 0.8873 - val_loss: 0.3810 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33694\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8873 - val_loss: 0.3812 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33694\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3022 - acc: 0.8871 - val_loss: 0.3808 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33694\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3022 - acc: 0.8875 - val_loss: 0.3818 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33694\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8876 - val_loss: 0.3828 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33694\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8876 - val_loss: 0.3820 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33694\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3020 - acc: 0.8875 - val_loss: 0.3832 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33694\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8876 - val_loss: 0.3830 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33694\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8878 - val_loss: 0.3828 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33694\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8886 - val_loss: 0.3832 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33694\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3015 - acc: 0.8887 - val_loss: 0.3832 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33694\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3013 - acc: 0.8886 - val_loss: 0.3837 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33694\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 1024\n",
      "Fold: 1\n",
      "best val loss: 0.3369432279519867\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZRc5X3m8e+v9t7VUmtfkHIsoIWQkRCLA9gQwCOwARMbI8eMg49tzXBMwI6dGTnJwR7GzjgzDiHOEBzs4GQ8xoSRY1ASOYyxxXgDLMkhspBYhBBWS0hqrb3X+s4f763qUqtb3ZKqVbrVz+ecOtV161bVe1Xw3Pf+7nvfMuccIiISfpFqN0BERCpDgS4iUiMU6CIiNUKBLiJSIxToIiI1IlatD25ra3Pz58+v1seLiITSpk2bDjjnpg73XNUCff78+WzcuLFaHy8iEkpm9uZIz6nkIiJSIxToIiI1QoEuIlIjqlZDF5Haks1m6ejoYGBgoNpNqQmpVIo5c+YQj8fH/BoFuohUREdHB01NTcyfPx8zq3ZzQs05x8GDB+no6GDBggVjfp1KLiJSEQMDA0yZMkVhXgFmxpQpU076aEeBLiIVozCvnFP5twxdoG/YeYg/+7+vkMsXqt0UEZGzSugC/V9/fZi//NF20jkFuogMOnLkCH/1V3910q+78cYbOXLkyDi06MwLXaAnor7JWfXQRaTMSIGey+VO+Lp169YxadKk8WrWGRW6US7xmA/0jAJdRMqsXr2a119/nYsuuoh4PE4qlaK1tZWXX36ZV199lfe9733s2rWLgYEB7r33XlatWgUMTkPS09PDDTfcwJVXXsnPf/5zZs+ezVNPPUVdXV2Vt2zswhfopR66fjpP5Gz1X/7xJbbu6aroey6a1cznb7pgxOe//OUvs2XLFl588UWeffZZ3vOe97Bly5bSsL9HH32UyZMn09/fzyWXXML73/9+pkyZcsx7vPbaa3znO9/h61//Oh/84Af57ne/yx133FHR7RhPoQv0UslFNXQROYFLL730mDHcX/3qV/ne974HwK5du3jttdeOC/QFCxZw0UUXAXDxxRezc+fOM9beSghdoMdVQxc5652oJ32mNDQ0lP5+9tlneeaZZ3juueeor6/n6quvHnaMdzKZLP0djUbp7+8/I22tlNCdFI1H/dhM1dBFpFxTUxPd3d3DPnf06FFaW1upr6/n5Zdf5vnnnz/DrTszwtdDj6mGLiLHmzJlCldccQWLFy+mrq6O6dOnl55bsWIFX/va12hvb+e8887j8ssvr2JLx0/oAr1YQ8+ohi4iQzz22GPDLk8mk3z/+98f9rlinbytrY0tW7aUln/2s5+tePvGWwhLLqqhi4gMJ4SBrhq6iMhwQhjoGrYoIjKc0AV6UidFRUSGFbpAVw1dRGR44Qt0zeUiIjKs8AV6cFJUPXQROR2NjY0A7Nmzhw984APDrnP11VezcePGE77Pgw8+SF9fX+lxNafjDV2gay4XEamkWbNmsWbNmlN+/dBAr+Z0vKELdM22KCLDWb16NQ899FDp8Re+8AW++MUvcu2117Js2TIuvPBCnnrqqeNet3PnThYvXgxAf38/K1eupL29nVtvvfWYuVzuuusuli9fzgUXXMDnP/95wE/4tWfPHq655hquueYawE/He+DAAQAeeOABFi9ezOLFi3nwwQdLn9fe3s4nPvEJLrjgAt797ndXbM6Y0F0pWgx01dBFzmLfXw17f1XZ95xxIdzw5RGfvv322/nUpz7FJz/5SQCeeOIJnn76ae655x6am5s5cOAAl19+OTfffPOIv9f58MMPU19fz7Zt29i8eTPLli0rPfelL32JyZMnk8/nufbaa9m8eTP33HMPDzzwAOvXr6etre2Y99q0aRPf/OY3eeGFF3DOcdlll/Gud72L1tbWcZumN4Q99ODCIpVcRKTM0qVL2b9/P3v27OHf/u3faG1tZcaMGfzhH/4hS5Ys4brrrmP37t3s27dvxPf48Y9/XArWJUuWsGTJktJzTzzxBMuWLWPp0qW89NJLbN269YTt+elPf8qtt95KQ0MDjY2N/PZv/zY/+clPgPGbpjd0PXQzIx41nRQVOZudoCc9nm677TbWrFnD3r17uf322/n2t79NZ2cnmzZtIh6PM3/+/GGnzR3NG2+8wVe+8hU2bNhAa2srd9555ym9T9F4TdM7ph66ma0ws1fMbLuZrR7m+Xlmtt7M/tXMNpvZjRVp3Qji0YgCXUSOc/vtt/P444+zZs0abrvtNo4ePcq0adOIx+OsX7+eN99884Svf+c731ma4GvLli1s3rwZgK6uLhoaGmhpaWHfvn3HTPQ10rS9V111FU8++SR9fX309vbyve99j6uuuqqCW3u8UXvoZhYFHgKuBzqADWa21jlXfrzxx8ATzrmHzWwRsA6YPw7tBYqBrpOiInKsCy64gO7ubmbPns3MmTP58Ic/zE033cSFF17I8uXLOf/880/4+rvuuouPfvSjtLe3097ezsUXXwzA29/+dpYuXcr555/P3LlzueKKK0qvWbVqFStWrGDWrFmsX7++tHzZsmXceeedXHrppQB8/OMfZ+nSpeP6K0jm3ImD0czeAXzBOffvgsefA3DO/beydf4a2OGc+9Ng/T9zzv3mid53+fLlbrTxnSO55EvPcP2i6fzJrRee0utFpPK2bdtGe3t7tZtRU4b7NzWzTc655cOtP5aSy2xgV9njjmBZuS8Ad5hZB753/nvDvZGZrTKzjWa2sbOzcwwfPbxENKJx6CIiQ1RqlMuHgL91zs0BbgS+ZWbHvbdz7hHn3HLn3PKpU6ee8ofppKiIyPHGEui7gbllj+cEy8p9DHgCwDn3HJAC2hgnqqGLnJ1GK+HK2J3Kv+VYAn0DsNDMFphZAlgJrB2yzq+BawHMrB0f6KdeUxlFPBrRhUUiZ5lUKsXBgwcV6hXgnOPgwYOkUqmTet2oo1ycczkzuxt4GogCjzrnXjKz+4GNzrm1wGeAr5vZpwEH3OnG8VuNxyK6sEjkLDNnzhw6Ojo4nfNjMiiVSjFnzpyTes2YLixyzq3Dn+wsX3Zf2d9bgSuGvm68JFRDFznrxONxFixYUO1mTGihu/QfdGGRiMhwQhvoGZ0UFRE5RmgDXePQRUSOFcpAT8RUQxcRGSqcga4auojIcUIZ6LqwSETkeOEM9JguLBIRGSqUga6Si4jI8UIZ6PGo6UpREZEhQhro6qGLiAwV4kB3mgRIRKRMKAM9EfPN1kgXEZFBoQz0eNQAVHYRESkT0kAv9tAV6CIiRaEOdI1FFxEZFMpAT0RVQxcRGSqcgV48Kaqx6CIiJaEMdNXQRUSOF9JA96Nc0uqhi4iUhDPQY+qhi4gMFcpA10lREZHjhTLQVUMXETleSAPd19A1Dl1EZFBIA13DFkVEhgploGtyLhGR44Uy0FVDFxE53pgC3cxWmNkrZrbdzFYP8/yfm9mLwe1VMztS+aYOUg1dROR4sdFWMLMo8BBwPdABbDCztc65rcV1nHOfLlv/94Cl49DWkoTGoYuIHGcsPfRLge3OuR3OuQzwOHDLCdb/EPCdSjRuJMVx6PpdURGRQWMJ9NnArrLHHcGy45jZOcAC4EcjPL/KzDaa2cbOzs6TbWuJaugiIser9EnRlcAa51x+uCedc48455Y755ZPnTr1lD8kritFRUSOM5ZA3w3MLXs8J1g2nJWMc7kFyk6KquQiIlIylkDfACw0swVmlsCH9tqhK5nZ+UAr8Fxlm3g8MyMeNZVcRETKjBrozrkccDfwNLANeMI595KZ3W9mN5etuhJ43Dl3Ruog8WhEgS4iUmbUYYsAzrl1wLohy+4b8vgLlWvW6Hygq4YuIlIUyitFwQe6LiwSERkU2kBPRE2Tc4mIlAltoMdjqqGLiJQLbaAnVHIRETlGaAM9Ho2QyemkqIhIUXgDXSUXEZFjhDbQE7qwSETkGKENdF1YJCJyrFAHekYXFomIlIQ60DUOXURkUGgDPRFTDV1EpFxoA101dBGRY4U80FVDFxEpCnWgp1VDFxEpCW2gJ3VhkYjIMUIb6PrFIhGRY4U40NVDFxEpF/JAd5yhX7wTETnrhTbQEzHfdI10ERHxQhvo8agBqOwiIhIIcaAXe+gKdBERqIFA168WiYh4oQ30RFQ1dBGRcqEN9HjM19AzulpURAQIc6Crhi4icowxBbqZrTCzV8xsu5mtHmGdD5rZVjN7ycweq2wzj1csuaiHLiLixUZbwcyiwEPA9UAHsMHM1jrntpatsxD4HHCFc+6wmU0brwYXxWPqoYuIlBtLD/1SYLtzbodzLgM8DtwyZJ1PAA855w4DOOf2V7aZx9NJURGRY40l0GcDu8oedwTLyp0LnGtmPzOz581sRaUaOBLV0EVEjjVqyeUk3mchcDUwB/ixmV3onDtSvpKZrQJWAcybN++0PrB4pajGoYuIeGPpoe8G5pY9nhMsK9cBrHXOZZ1zbwCv4gP+GM65R5xzy51zy6dOnXpqLf7lt+B/XkqCHIB+KFpEJDCWQN8ALDSzBWaWAFYCa4es8yS+d46ZteFLMDsq2M5BmV448ArJQh+gGrqISNGoge6cywF3A08D24AnnHMvmdn9ZnZzsNrTwEEz2wqsB/7AOXdwXFqcbPJ3+V5ANXQRkaIx1dCdc+uAdUOW3Vf2twN+P7iNr1QzAIlcN6Bx6CIiReG7UjRZDHTfQ9dJURERL4SB7ksu8VwPoJKLiEhR+AI91QJATIEuInKM8AV60EOPZX0NXaNcRES8EAa6r6FHM76HrpOiIiJe+AI9loRIHEt3EY+aSi4iIoHwBbqZH7qY7iYejSjQRUQC4Qt08HX0dFcQ6Kqhi4hAaAO9GQZ8oGscuoiIF95AT3eTiJpOioqIBMIZ6KlmX3KJqYYuIlIUzkBPNpfV0BXoIiIQ2kBvGqyh53RSVEQEwhrowbDFRESX/ouIFIUz0JNN4PI0RbMKdBGRQEgD3V/+3xzpV6CLiATCHejWT0YXFomIAGEN9OBXi5psQD8SLSISCGegB1PoNtGrkouISCCkge576I306dJ/EZFAOAM9KLk00K+Si4hIIJyBHpRcGlyfToqKiARCGuhBD931qYYuIhIIZ6BHohBvoM7ppKiISFE4Ax0g1UxdQT10EZGi8AZ6som6Qi/ZvMM51dFFRMYU6Ga2wsxeMbPtZrZ6mOfvNLNOM3sxuH288k0dItlMqtALoJ+hExEBYqOtYGZR4CHgeqAD2GBma51zW4es+vfOubvHoY3DSzaR7O4E/IyLiVh4DzZERCphLCl4KbDdObfDOZcBHgduGd9mjUGqmWS+D9AUuiIiMLZAnw3sKnvcESwb6v1mttnM1pjZ3Iq07kSSTSRyPQD6XVERESp3UvQfgfnOuSXAD4C/G24lM1tlZhvNbGNnZ+fpfWKyhUSuG4C+TP703ktEpAaMJdB3A+U97jnBshLn3EHnXDp4+A3g4uHeyDn3iHNuuXNu+dSpU0+lvYNSzcTy/UQocLA3Pfr6IiI1biyBvgFYaGYLzCwBrATWlq9gZjPLHt4MbKtcE0cQXP7fSB+d3Zlx/zgRkbPdqKNcnHM5M7sbeBqIAo86514ys/uBjc65tcA9ZnYzkAMOAXeOY5u94PL/Jvrp7FEPXURk1EAHcM6tA9YNWXZf2d+fAz5X2aaNIuihN0f66exWoIuIhHfwdjCF7qxUVoEuIkKYAz0oucyuy3JAJRcRkfAH+vSkeugiIhDqQPc19GmJtAJdRIQwB3pQQ58ST3OgJ60ZF0VkwgtvoMfrwaK0RgZI5wp0p3PVbpGISFWFN9DNINlES6QfQGUXEZnwwhvoAKlmGvEzLirQRWSiC3egJ5upcz7QNXRRRCa60Ad6Ku9/tUg9dBGZ6EIe6E3Est3EIqZAF5EJL9yBnmrG0t20NSYV6CIy4YU70JNNkO6irSmhGrqITHghD/RmSHcztTGpKXRFZMILeaA3QT7DzAadFBURCXegp1qA4oyLGQoFXf4vIhNXuAO9yf/y3bzoIfIFx5H+bJUbJCJSPeEO9GntAMzNvQmo7CIiE1u4A711PsRSTB/YASjQRWRiC3egR6Iw9Txael4HoLNnoMoNEhGpnnAHOsDUdlKHXwHgQHemyo0REame8Af6tHYi3W/RFuvXWHQRmdBqINAXAXBJ/T7V0EVkQquBQD8fgCXJPQp0EZnQwh/oLXMh0ci5tlvzuYjIhBb+QDeDqeczv/CmeugiMqGNKdDNbIWZvWJm281s9QnWe7+ZOTNbXrkmjsG0dmam3+BQX4ZcvnBGP1pE5GwxaqCbWRR4CLgBWAR8yMwWDbNeE3Av8EKlGzmqaYuozx5msjvKoV4NXRSRiWksPfRLge3OuR3OuQzwOHDLMOv9V+BPgTN/dU9wYvTcSAe7Dvef8Y8XETkbjCXQZwO7yh53BMtKzGwZMNc5988neiMzW2VmG81sY2dn50k3dkTB0MVzrYNNbx6q3PuKiITIaZ8UNbMI8ADwmdHWdc494pxb7pxbPnXq1NP96EGN06GulYvr9vLCDgW6iExMYwn03cDcssdzgmVFTcBi4Fkz2wlcDqw9oydGzWBqO0sSe/jFTj+VrojIRDOWQN8ALDSzBWaWAFYCa4tPOueOOufanHPznXPzgeeBm51zG8elxSOZ1s6szE66B7K8vLfrjH60iMjZYNRAd87lgLuBp4FtwBPOuZfM7H4zu3m8Gzhm09pJ5LqZwSF+8YbKLiIy8cTGspJzbh2wbsiy+0ZY9+rTb9YpmHc5AB9s2swLOy7go1csqEozRCTkcmno2g1Hd0NuABqn+V9Hi8TgyJtw6A3o7QSLQDQB0Xhwn/BTemf6INMD2T5wQfnXFSDTC+kuf1uyEhZcVfGmjynQQ2HGhTBjCbcfXs9Nb7wb5xxmVu1WiUilOOeDMtPnwzKX9kGJ8/f9h33Q9h6A7reg6y1/7wo+bGNJ/x6FLOSzPogTjf6W6YGjHXB0F/TsG79tSDT5H7efX/kwh1oKdIBlH2H2us8yK/0K2/e/g4XTm6rdIpGJre8QHNzuQzaf9kGaG4Bsvw/l/sO+J9y1x4dxth9y/T6EUy1Q1wqxOh+y3W/514xFJOZ71U0zIBKH7BHIZcDwj6NxSHfDkV9DugfiKT8v1MLr/X3LXGiZXfbZe337W+dD6wL/3i7vtyefCe7TUMhBvAGSjRCvA4v69phBvN734MdRbQX6hbdRePqPuT36LC+8cbMCXeRUOOeDc6AL+g5C3wEfzLmBwfAaOAoDR/x9Ie8DCxsM6b5DPiz7RzmfFU1A8yxong0zFvvQiyV9OWPgqH+vbD/MXALnrvDlj2Rj2XrFwIxA3SSob4OGNn8fCf9UVSertgK9bhJ2wc3cuvmfuO/1Pdxx+TnVbpHIyAoFH4TF0mAhPxhimV4fjtm+oDfb7wM1EvOH7MlmH2L5tC89FPL+cTFYi6WITJ+vB3ft9j3cvkO+tzxw1K9TXK/UprwvPxRyo7c/Vud70dH44HvF66BuMjRMhZlvh7aFMGUhNE2HaHKw9JFo8OvGUoPbL6ettgIdsKUfoXHzEzTv+Gecu1x1dKmcQgG6OnwgxushUe8DtngSrO8AHHgNOl/xJ89ymaBHmw7W6YVsb7C8WP/FlwAiMV9qGC/JFl9+aGiDqef5II7EBncApf9PzO8wUs1+p1E/xb+mbnIQwEEoJxp9mULOKjUX6My/kq76edzQ8wN2HvwcC9oaqt0iOdsVCr580LPPlwkObve3voOQz/mTaD37fVhne0d/v7pWmPwbvgebaIBoqw//RMNgqSCa9D3bQt6/fyHnQzLVAqlJgzXYeNCTLfZmCzk/SmKgy+8QYin/fpGoL5UUe9wWAYK6bfNMH9JS82ov0M1wF93BZT//Ex5+5hnuWjncPGJSs5zzPeQ3/h/8+jl/4ssVfHDmM748kUsPliqy/T7Mh5YYUi1+SonisLT6ybDsI7532zRjsBSSzwYjJep9ELed63u0OjKUKqi9QAdarvgYPS88xG9t+yM6Oq9kztQp1W6SVFL/Yd9b3r8N9m/1fw8c9eHdd8D3rAFa5kHDFH/iLBL14Vzf4HvH8ZTv3UYTvkfdOM3fmufAlLf5AFcoS8jUZKDT0Eb6poc578nf4fnH7mXOvf+72i2Sk9V3CPZuhs5Xfd26a89gOaQY2OBLEm0LfQC3zPY969nL4Tfe5YeYiUwgtRnowJSL3sPPnv/3XLH3W+z7+beZ/psfrnaTpFy6Bw69Dod3+ivvunb7OnXvAb+sq2Nw3dLQtjlw/nt9D3rK22BaO0w6Z0IOTxMZTs0GOsB5H/oyv3zgBRb94DNwTjvMXlbtJk0chQL07PVhfXSXvwqvazcc2uFLJF27j10/2TJY9jjnHaUrf5m2yA+BU2iLjKqmA72tpZF/WP4Vpm/8KDP/5t1E3v1FuOw/qDZaSb0HYdcL0LHBl0SKV9Ud3eXHTZerm+zLIAveOdjLnrzAL0u1VKP1IjWlpgMdYOX1v8kd2/6cT/f+Bdf8y3+GnT+BG/67r7fKyNI9PpSP7PK96XSXX5buht79QWh3+PHW4Mc0t8yBxhkwfRGct2LwMulJ5/iSSaK+qpskUuvMuer8GMTy5cvdxo1nZsr0t472s/Kvn+PG3if5g+hjRFwB2t8Ll66Cc66orR67c37ER29nMGQvGJucGxgcvzxwxJ907D/kR4wUgzrdNbh8aO+6KNEYlEZm+OF7M5fA3Mtg1lI/VlpExpWZbXLODfsDQhMi0AH2HOln5SPPU9fXwdfPf5F5O9f4YGuaBW+7Ft52nQ+mphlnPuDLx0iXJvsJ5sxIdw3OjdHb6XvHvQf8GGicD+zicL3eg36dfHoMH2p+uF7dJH9FYDKYBa5uMtS3+isEyycpSk0KJhdSLVukmhTogd1H+vndR3/B9v09vPf8Fu5fuJ3Ju38Erz8L6aN+pfopMH0xTJoXXLXXEgReow+8SMz3XnOZ4D4d3A8MzreRDS7zLt6K6xRDupDz96WLU8YSwIFI3PeQ43WULtlONA5OSNTQ5p9vmOYv37ZoMG9zPNieZh/OqZZxn/lNRCpPgV4mkyvwjZ/u4C9/uB2HY+Ul87ht2QwuKGyHt16Evb+CfVuge5/vwY91uk4IJh6q8xetJBoHL/Uuv4glGh+cuyNRH1zSHcyRUZwno3SLD04hmprkL5JJTaqtEpGInBQF+jB2H+nnf/zLy6z71V4y+QKLZjZz44UzuHLhVC6c3UI0EoRmLuNLGpluX2su5HwIF2eNi6WOnU9DRGQcKdBP4Ehfhqde3MN3f9nB5g5fdmlOxbhk/mQumjuJi+ZNon1mM1MaEpq5UUSqToE+Rgd60vxs+wF+tv0Am948zOudgzPrNSSinDOlgXOm1DNvSj3nTG5g7uQ6pjenmN6cojkVU+CLyLhToJ+iroEsm3cdZfv+bnYe7OPNg728eaiPjkP9ZPKFY9ZNxCJMaUjQWp+gtSHOpPoEk+riTKqP01IXZ1Jdgua6OI3JGA3JaHAfoyHhH8eiGj0iIqM7UaDX/IVFp6M5FefKhW1cubDtmOX5gmNv1wAdh/rY351mX9cAnd1pDvVmONyX4WBvhreOdnG0L8uR/iz5wug7zVQ8QmMyTlMqRjIWIRWPkoxFqEtEqU9EqYvHqEtESMWi1CWipedT8Sh18WCdhP87VbpF/ONgeVw7DZGapkA/BdGIMXtSHbMnjX4hjXOO3kyeI30ZjvRl6U3n6M3k6Enn6Uvn6Enn6E3n6c3k6B7I0ZvO0Z/NM5DNk84WONiToSObpz+TLy3vz+Y5lQOrWMSoi0dJxiPEoxFiUSMRjdCQjFGfiFKf8DuTRCxS2lkUb82pGM0pv8Mp33EUdyT1Cf8eyVhEpSeRKlGgjzMzozEZozEZY05rZd7TOUcmX2AgW/ABn8nTl8nTn82Vlg1kC6UdQHGdgVye/kyBgVyeXL5ALu9I5wr0ZnL0pfPs6xogkyuQyRdIZ/16xfc6GXXB0cExRxHBTqApFWNysTRVn6ClLk5zXYymVLx0VJGKR0lE/U4nGYtQn/SPtaMQOTEFegiZGclYlGQsSktdfNw/r1Bw9GRydPVn6R4IjiBKO5E8fZkcfZlgJ5IpHmEUSOfygzudrF//wIFeNr15hMN9mTGVoopiEaMu4ctGsYiRjEdKO4XW+jiNqcFzEsngCCMZHEHUJ2I0JKLUJ/19QzJWOsJIxiJEItpRSG1QoMuoIhGjORWnOVW5nYdzjp50jqP9Wbr6c3QPZBnIFejP5Enn8mRyBbJ5V9oZ9Kb9TiNX8EcWA9k8R/qzHO7NsONAD73pPD3pHJncyR1NAMSD0lO8rNTkz18EO4LgxHXxXEaxtFQqXUWMSMSIRyKl8xXJ2OD5CjNKO5Ziiaoh4Xcq2plIJY0p0M1sBfAXQBT4hnPuy0Oe/4/AJ4E80AOscs5trXBbpYaYGU2pOE2pOFSoFAWQzRfI5Aqkc2VHBsE5ir7g3EVvOlcqJQ1k82SC1xRvxVJTf7ZAXzrH4b7+0lFI8VzGyRxdnEg86o+2ErEIg9luOOfIFRyFgiMWtdIRRTwawQwiZlgw84NhRMzveKMW7FyiRiwS8TurmN/xJKKDO6tkPELUDDMjGvG3iBnRCKXXxaN+vVTMf3ZDUDpsTMaIRIJ53xwk48F5GO2gqm7UQDezKPAQcD3QAWwws7VDAvsx59zXgvVvBh4AVoxDe0VOKB7U3huS4/s5ubzfaWRyBfLOkS+4YEfiz1Okc3nAB27BEZzn8CfA+7L+hHhfJl86X5HJ+xPdDh+S0QilcM7lHf3BzimfdxScvw2u7yg4Ssv9EUyBXD5HNu/8Ti7YaRV3ZJl8ofQelRQtC/R41AaPSspKXMUT8hEb3JHEgp1KLBrcR/yOKBH1J/GLpbKGROyYHVr5fWMyVjofU3Au+HctYEAsOJIqvnckYrjg36y4cy5/r2iwc4wFO7ZEzL8+7/xONlfwr8vmCzhH6TxRKhap6hDksfTQLwW2O+d2AJjZ48AtQCnQnXNdZes34P87E6lZsaj/H3e8dxzjzQWBVnB+OG6uUAiCyv9dPFgw0bkAAAWRSURBVDlePPHePeBHZhWcw/BHWumcP+rpSecplB25ZPODJ9wHys6nZPMF0jn/uX5n6M/TZAuFUlhm877kVtwJ5Sp0RHQmxKMW7Lz8VCDOORyUdlLJWIRPXXcuN719VsU/eyyBPhvYVfa4A7hs6Epm9kng94EE8FvDvZGZrQJWAcybN+9k2yoiFWZBL3TQ2Tkfkd9p+KOcYs+6eIRSCHrNPekcXQP+fEzUgh5+LIILdlbZfKFsJ+J3EMWeOAy+l9/B+R1NLl8IdkD+tcXyVPEWD6aTTuf8EVRxFFnxSMj3+P02ZHOudKQ0qX58BjNU7KSoc+4h4CEz+x3gj4HfHWadR4BHwF8pWqnPFpHaVhzVNbkhUe2mnNXGUuzZDcwtezwnWDaSx4H3nU6jRETk5I0l0DcAC81sgZklgJXA2vIVzGxh2cP3AK9VrokiIjIWo5ZcnHM5M7sbeBpfYHvUOfeSmd0PbHTOrQXuNrPrgCxwmGHKLSIiMr7GVEN3zq0D1g1Zdl/Z3/dWuF0iInKSNP2eiEiNUKCLiNQIBbqISI1QoIuI1Iiq/QSdmXUCb57iy9uAAxVsTlhMxO2eiNsME3O7J+I2w8lv9znOuanDPVG1QD8dZrZxpN/Uq2UTcbsn4jbDxNzuibjNUNntVslFRKRGKNBFRGpEWAP9kWo3oEom4nZPxG2GibndE3GboYLbHcoauoiIHC+sPXQRERlCgS4iUiNCF+hmtsLMXjGz7Wa2utrtGQ9mNtfM1pvZVjN7yczuDZZPNrMfmNlrwX0Ff1757GBmUTP7VzP7p+DxAjN7Ifi+/z6YwrmmmNkkM1tjZi+b2TYze8cE+a4/Hfz3vcXMvmNmqVr7vs3sUTPbb2ZbypYN+92a99Vg2zeb2bKT/bxQBXrZD1bfACwCPmRmi6rbqnGRAz7jnFsEXA58MtjO1cAPnXMLgR8Gj2vNvcC2ssd/Cvy5c+5t+KmZP1aVVo2vvwD+xTl3PvB2/PbX9HdtZrOBe4DlzrnF+Km5V1J73/ffAiuGLBvpu70BWBjcVgEPn+yHhSrQKfvBaudcBv/rSLdUuU0V55x7yzn3y+Dvbvz/4LPx2/p3wWp/R439MpSZzcH/QMo3gseG/33aNcEqtbjNLcA7gb8BcM5lnHNHqPHvOhAD6swsBtQDb1Fj37dz7sfAoSGLR/pubwH+l/OeByaZ2cyT+bywBfpwP1g9u0ptOSPMbD6wFHgBmO6ceyt4ai8wvUrNGi8PAv8JKASPpwBHnHO54HEtft8LgE7gm0Gp6Rtm1kCNf9fOud3AV4Bf44P8KLCJ2v++YeTv9rTzLWyBPqGYWSPwXeBTzrmu8uecH29aM2NOzey9wH7n3KZqt+UMiwHLgIedc0uBXoaUV2rtuwYI6sa34Hdos4AGji9N1LxKf7dhC/ST/cHq0DKzOD7Mv+2c+4dg8b7iIVhwv79a7RsHVwA3m9lOfCntt/C15UnBITnU5vfdAXQ4514IHq/BB3wtf9cA1wFvOOc6nXNZ4B/w/w3U+vcNI3+3p51vYQv0UX+wuhYEteO/AbY55x4oe2otg7/X+rvAU2e6bePFOfc559wc59x8/Pf6I+fch4H1wAeC1WpqmwGcc3uBXWZ2XrDoWmArNfxdB34NXG5m9cF/78XtrunvOzDSd7sW+Egw2uVy4GhZaWZsnHOhugE3Aq8CrwN/VO32jNM2Xok/DNsMvBjcbsTXlH8IvAY8A0yudlvHafuvBv4p+Ps3gF8A24H/AySr3b5x2N6LgI3B9/0k0DoRvmvgvwAvA1uAbwHJWvu+ge/gzxFk8UdjHxvpuwUMP4rvdeBX+BFAJ/V5uvRfRKRGhK3kIiIiI1Cgi4jUCAW6iEiNUKCLiNQIBbqISI1QoIuI1AgFuohIjfj/J4We0JjLiIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  99.94092965126038\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.8644 - acc: 0.7648 - val_loss: 0.5999 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59993, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4960 - acc: 0.8654 - val_loss: 0.4426 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59993 to 0.44263, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4018 - acc: 0.8709 - val_loss: 0.3903 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44263 to 0.39027, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3656 - acc: 0.8724 - val_loss: 0.3680 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.39027 to 0.36798, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3488 - acc: 0.8730 - val_loss: 0.3570 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36798 to 0.35695, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3398 - acc: 0.8737 - val_loss: 0.3510 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35695 to 0.35097, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3345 - acc: 0.8737 - val_loss: 0.3473 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.35097 to 0.34731, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3312 - acc: 0.8741 - val_loss: 0.3450 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34731 to 0.34499, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3288 - acc: 0.8744 - val_loss: 0.3434 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34499 to 0.34341, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3270 - acc: 0.8747 - val_loss: 0.3425 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34341 to 0.34253, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3259 - acc: 0.8747 - val_loss: 0.3419 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34253 to 0.34192, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8749 - val_loss: 0.3415 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34192 to 0.34149, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8753 - val_loss: 0.3415 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34149 to 0.34146, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3232 - acc: 0.8754 - val_loss: 0.3413 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34146 to 0.34131, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8756 - val_loss: 0.3417 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34131\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8758 - val_loss: 0.3420 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34131\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8758 - val_loss: 0.3425 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34131\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8759 - val_loss: 0.3430 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34131\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8758 - val_loss: 0.3436 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34131\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8761 - val_loss: 0.3441 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34131\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8762 - val_loss: 0.3447 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34131\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8767 - val_loss: 0.3452 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34131\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8770 - val_loss: 0.3457 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34131\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8772 - val_loss: 0.3465 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34131\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8776 - val_loss: 0.3470 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34131\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8777 - val_loss: 0.3478 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34131\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8780 - val_loss: 0.3488 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34131\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8779 - val_loss: 0.3498 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34131\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8782 - val_loss: 0.3505 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34131\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8787 - val_loss: 0.3515 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34131\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8791 - val_loss: 0.3526 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34131\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8792 - val_loss: 0.3537 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34131\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8796 - val_loss: 0.3544 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34131\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8797 - val_loss: 0.3550 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34131\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8799 - val_loss: 0.3565 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34131\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8802 - val_loss: 0.3572 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34131\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8804 - val_loss: 0.3588 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34131\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8806 - val_loss: 0.3605 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34131\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8806 - val_loss: 0.3611 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34131\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8809 - val_loss: 0.3626 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34131\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8813 - val_loss: 0.3633 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34131\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8814 - val_loss: 0.3643 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34131\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8813 - val_loss: 0.3649 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34131\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8814 - val_loss: 0.3649 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34131\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8815 - val_loss: 0.3660 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34131\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8820 - val_loss: 0.3664 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34131\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8822 - val_loss: 0.3665 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34131\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8825 - val_loss: 0.3670 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34131\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8828 - val_loss: 0.3684 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34131\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8829 - val_loss: 0.3692 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34131\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8828 - val_loss: 0.3702 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34131\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8827 - val_loss: 0.3707 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34131\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8829 - val_loss: 0.3710 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34131\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8831 - val_loss: 0.3720 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34131\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8836 - val_loss: 0.3722 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34131\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3085 - acc: 0.8840 - val_loss: 0.3727 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34131\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8840 - val_loss: 0.3737 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34131\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8838 - val_loss: 0.3739 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34131\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8840 - val_loss: 0.3752 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34131\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8841 - val_loss: 0.3749 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34131\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8843 - val_loss: 0.3756 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34131\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8842 - val_loss: 0.3764 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34131\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8845 - val_loss: 0.3776 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34131\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8846 - val_loss: 0.3787 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34131\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8848 - val_loss: 0.3790 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34131\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8850 - val_loss: 0.3799 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34131\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8850 - val_loss: 0.3806 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34131\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8853 - val_loss: 0.3810 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34131\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8855 - val_loss: 0.3810 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34131\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8856 - val_loss: 0.3818 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34131\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8860 - val_loss: 0.3820 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34131\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8859 - val_loss: 0.3827 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34131\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3055 - acc: 0.8862 - val_loss: 0.3824 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34131\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8861 - val_loss: 0.3825 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34131\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8864 - val_loss: 0.3827 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34131\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8866 - val_loss: 0.3829 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34131\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8869 - val_loss: 0.3831 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34131\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8868 - val_loss: 0.3833 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34131\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8863 - val_loss: 0.3836 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34131\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8863 - val_loss: 0.3836 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34131\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8865 - val_loss: 0.3835 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34131\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8864 - val_loss: 0.3838 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34131\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8865 - val_loss: 0.3838 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34131\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8866 - val_loss: 0.3837 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34131\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8871 - val_loss: 0.3849 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34131\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8864 - val_loss: 0.3850 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34131\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8868 - val_loss: 0.3856 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34131\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8865 - val_loss: 0.3855 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34131\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8866 - val_loss: 0.3861 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34131\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8869 - val_loss: 0.3871 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34131\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8873 - val_loss: 0.3871 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34131\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3029 - acc: 0.8876 - val_loss: 0.3876 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34131\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3027 - acc: 0.8875 - val_loss: 0.3877 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34131\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3026 - acc: 0.8876 - val_loss: 0.3877 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34131\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3022 - acc: 0.8878 - val_loss: 0.3884 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34131\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8874 - val_loss: 0.3888 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34131\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3013 - acc: 0.8873 - val_loss: 0.3891 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34131\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8872 - val_loss: 0.3910 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34131\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3015 - acc: 0.8873 - val_loss: 0.3904 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34131\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8875 - val_loss: 0.3908 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34131\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 1024\n",
      "Fold: 2\n",
      "best val loss: 0.34130778909426684\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  102.30775237083435\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.8653 - acc: 0.7652 - val_loss: 0.5899 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58994, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4953 - acc: 0.8646 - val_loss: 0.4362 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58994 to 0.43622, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4016 - acc: 0.8704 - val_loss: 0.3836 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43622 to 0.38356, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3657 - acc: 0.8718 - val_loss: 0.3610 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38356 to 0.36097, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3490 - acc: 0.8723 - val_loss: 0.3499 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36097 to 0.34990, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3403 - acc: 0.8725 - val_loss: 0.3441 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34990 to 0.34410, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3350 - acc: 0.8727 - val_loss: 0.3409 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34410 to 0.34091, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3317 - acc: 0.8729 - val_loss: 0.3383 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34091 to 0.33830, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3294 - acc: 0.8730 - val_loss: 0.3376 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33830 to 0.33759, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3276 - acc: 0.8735 - val_loss: 0.3366 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33759 to 0.33660, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8736 - val_loss: 0.3364 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33660 to 0.33639, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8741 - val_loss: 0.3360 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33639 to 0.33598, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8740 - val_loss: 0.3364 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33598\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3235 - acc: 0.8744 - val_loss: 0.3365 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33598\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8745 - val_loss: 0.3365 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33598\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8748 - val_loss: 0.3368 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33598\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8752 - val_loss: 0.3375 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33598\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8754 - val_loss: 0.3379 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33598\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8757 - val_loss: 0.3384 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33598\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8757 - val_loss: 0.3390 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33598\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8761 - val_loss: 0.3393 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33598\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8761 - val_loss: 0.3402 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33598\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8765 - val_loss: 0.3410 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33598\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8764 - val_loss: 0.3418 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33598\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8765 - val_loss: 0.3423 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33598\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8769 - val_loss: 0.3433 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33598\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8770 - val_loss: 0.3437 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33598\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8772 - val_loss: 0.3448 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33598\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8776 - val_loss: 0.3448 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33598\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8778 - val_loss: 0.3457 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33598\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8780 - val_loss: 0.3466 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33598\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8783 - val_loss: 0.3469 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33598\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8789 - val_loss: 0.3484 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33598\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8789 - val_loss: 0.3504 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33598\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8791 - val_loss: 0.3498 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33598\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8794 - val_loss: 0.3510 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33598\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8798 - val_loss: 0.3519 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33598\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8795 - val_loss: 0.3522 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33598\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8797 - val_loss: 0.3535 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33598\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8802 - val_loss: 0.3546 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33598\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8802 - val_loss: 0.3545 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33598\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8805 - val_loss: 0.3557 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33598\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8806 - val_loss: 0.3563 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33598\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8805 - val_loss: 0.3571 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33598\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8809 - val_loss: 0.3579 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33598\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8814 - val_loss: 0.3585 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33598\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8818 - val_loss: 0.3602 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33598\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8820 - val_loss: 0.3605 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33598\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8824 - val_loss: 0.3600 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33598\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8824 - val_loss: 0.3610 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33598\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8828 - val_loss: 0.3624 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33598\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8826 - val_loss: 0.3636 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33598\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8829 - val_loss: 0.3638 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33598\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8830 - val_loss: 0.3656 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33598\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8832 - val_loss: 0.3668 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33598\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8835 - val_loss: 0.3677 - val_acc: 0.8614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33598\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8838 - val_loss: 0.3683 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33598\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8840 - val_loss: 0.3698 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33598\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8841 - val_loss: 0.3698 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33598\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8843 - val_loss: 0.3708 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33598\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8845 - val_loss: 0.3714 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33598\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8847 - val_loss: 0.3713 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33598\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8851 - val_loss: 0.3720 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33598\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8855 - val_loss: 0.3728 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33598\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8859 - val_loss: 0.3728 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33598\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8857 - val_loss: 0.3734 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33598\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3030 - acc: 0.8859 - val_loss: 0.3740 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33598\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3029 - acc: 0.8860 - val_loss: 0.3740 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33598\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3025 - acc: 0.8864 - val_loss: 0.3750 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33598\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3025 - acc: 0.8863 - val_loss: 0.3757 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33598\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8862 - val_loss: 0.3760 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33598\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8865 - val_loss: 0.3774 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33598\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8862 - val_loss: 0.3779 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33598\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8864 - val_loss: 0.3784 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33598\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3019 - acc: 0.8868 - val_loss: 0.3780 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33598\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3016 - acc: 0.8871 - val_loss: 0.3789 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33598\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3015 - acc: 0.8870 - val_loss: 0.3798 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33598\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8871 - val_loss: 0.3789 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33598\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3011 - acc: 0.8872 - val_loss: 0.3796 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33598\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3015 - acc: 0.8870 - val_loss: 0.3791 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33598\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3008 - acc: 0.8871 - val_loss: 0.3803 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33598\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3008 - acc: 0.8877 - val_loss: 0.3803 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33598\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3006 - acc: 0.8875 - val_loss: 0.3818 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33598\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3002 - acc: 0.8884 - val_loss: 0.3817 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33598\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8881 - val_loss: 0.3831 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33598\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2998 - acc: 0.8880 - val_loss: 0.3834 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33598\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8882 - val_loss: 0.3828 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33598\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2993 - acc: 0.8885 - val_loss: 0.3835 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33598\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2992 - acc: 0.8886 - val_loss: 0.3848 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33598\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2990 - acc: 0.8889 - val_loss: 0.3837 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33598\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2988 - acc: 0.8890 - val_loss: 0.3842 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33598\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2988 - acc: 0.8890 - val_loss: 0.3871 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33598\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2989 - acc: 0.8887 - val_loss: 0.3854 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33598\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2987 - acc: 0.8889 - val_loss: 0.3864 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33598\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2986 - acc: 0.8888 - val_loss: 0.3861 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33598\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2985 - acc: 0.8889 - val_loss: 0.3866 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33598\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2985 - acc: 0.8888 - val_loss: 0.3870 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33598\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2985 - acc: 0.8888 - val_loss: 0.3885 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33598\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2986 - acc: 0.8889 - val_loss: 0.3887 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33598\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2981 - acc: 0.8894 - val_loss: 0.3895 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33598\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 1024\n",
      "Fold: 3\n",
      "best val loss: 0.33597521700357136\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  101.13243103027344\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.8703 - acc: 0.7615 - val_loss: 0.6045 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60445, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4963 - acc: 0.8644 - val_loss: 0.4448 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60445 to 0.44476, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4017 - acc: 0.8707 - val_loss: 0.3911 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44476 to 0.39112, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3655 - acc: 0.8725 - val_loss: 0.3683 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.39112 to 0.36832, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3487 - acc: 0.8731 - val_loss: 0.3572 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36832 to 0.35725, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3398 - acc: 0.8735 - val_loss: 0.3509 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35725 to 0.35093, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3344 - acc: 0.8737 - val_loss: 0.3471 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.35093 to 0.34712, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3313 - acc: 0.8738 - val_loss: 0.3451 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34712 to 0.34507, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3288 - acc: 0.8743 - val_loss: 0.3435 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34507 to 0.34349, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3271 - acc: 0.8743 - val_loss: 0.3428 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34349 to 0.34276, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3257 - acc: 0.8746 - val_loss: 0.3422 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34276 to 0.34219, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8746 - val_loss: 0.3419 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34219 to 0.34185, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8746 - val_loss: 0.3415 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34185 to 0.34154, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8750 - val_loss: 0.3413 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34154 to 0.34133, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8752 - val_loss: 0.3411 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34133 to 0.34110, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8756 - val_loss: 0.3412 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34110\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8757 - val_loss: 0.3416 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34110\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8759 - val_loss: 0.3417 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34110\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8764 - val_loss: 0.3423 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34110\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8764 - val_loss: 0.3428 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34110\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8765 - val_loss: 0.3431 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34110\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8770 - val_loss: 0.3434 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34110\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8774 - val_loss: 0.3441 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34110\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8774 - val_loss: 0.3444 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34110\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8775 - val_loss: 0.3452 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34110\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8778 - val_loss: 0.3457 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34110\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8782 - val_loss: 0.3464 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34110\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8783 - val_loss: 0.3470 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34110\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8787 - val_loss: 0.3473 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34110\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8785 - val_loss: 0.3480 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34110\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8784 - val_loss: 0.3483 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34110\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8786 - val_loss: 0.3490 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34110\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8790 - val_loss: 0.3492 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34110\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8790 - val_loss: 0.3501 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34110\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8795 - val_loss: 0.3503 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34110\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8796 - val_loss: 0.3511 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34110\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8799 - val_loss: 0.3523 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34110\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8800 - val_loss: 0.3531 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34110\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8803 - val_loss: 0.3542 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34110\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8805 - val_loss: 0.3547 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34110\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8804 - val_loss: 0.3556 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34110\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8810 - val_loss: 0.3561 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34110\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8813 - val_loss: 0.3566 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34110\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3116 - acc: 0.8813 - val_loss: 0.3566 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34110\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8814 - val_loss: 0.3566 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34110\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8813 - val_loss: 0.3571 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34110\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8818 - val_loss: 0.3578 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34110\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8815 - val_loss: 0.3585 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34110\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8817 - val_loss: 0.3596 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34110\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8819 - val_loss: 0.3599 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34110\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8820 - val_loss: 0.3605 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34110\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8823 - val_loss: 0.3616 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34110\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8825 - val_loss: 0.3623 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34110\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8829 - val_loss: 0.3628 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34110\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8825 - val_loss: 0.3634 - val_acc: 0.8599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34110\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8827 - val_loss: 0.3640 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34110\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8829 - val_loss: 0.3644 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34110\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8832 - val_loss: 0.3644 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34110\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8832 - val_loss: 0.3653 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34110\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8836 - val_loss: 0.3659 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34110\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8840 - val_loss: 0.3666 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34110\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8840 - val_loss: 0.3672 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34110\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8845 - val_loss: 0.3666 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34110\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8845 - val_loss: 0.3671 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34110\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8848 - val_loss: 0.3672 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34110\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8851 - val_loss: 0.3665 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34110\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8851 - val_loss: 0.3678 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34110\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8850 - val_loss: 0.3669 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34110\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8854 - val_loss: 0.3680 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34110\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3055 - acc: 0.8850 - val_loss: 0.3675 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34110\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8850 - val_loss: 0.3680 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34110\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8850 - val_loss: 0.3674 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34110\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3055 - acc: 0.8851 - val_loss: 0.3686 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34110\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8852 - val_loss: 0.3680 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34110\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8852 - val_loss: 0.3692 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34110\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8848 - val_loss: 0.3694 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34110\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8853 - val_loss: 0.3699 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34110\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8856 - val_loss: 0.3713 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34110\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8862 - val_loss: 0.3706 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34110\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8863 - val_loss: 0.3720 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34110\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8866 - val_loss: 0.3724 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34110\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3040 - acc: 0.8869 - val_loss: 0.3728 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34110\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8871 - val_loss: 0.3736 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34110\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8874 - val_loss: 0.3734 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34110\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3032 - acc: 0.8873 - val_loss: 0.3743 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34110\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3027 - acc: 0.8876 - val_loss: 0.3738 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34110\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3027 - acc: 0.8874 - val_loss: 0.3742 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34110\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3025 - acc: 0.8875 - val_loss: 0.3751 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34110\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3023 - acc: 0.8877 - val_loss: 0.3764 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34110\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3019 - acc: 0.8879 - val_loss: 0.3770 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34110\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8877 - val_loss: 0.3780 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34110\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8878 - val_loss: 0.3778 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34110\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8877 - val_loss: 0.3798 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34110\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8878 - val_loss: 0.3801 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34110\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8875 - val_loss: 0.3800 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34110\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8875 - val_loss: 0.3803 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34110\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3015 - acc: 0.8876 - val_loss: 0.3813 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34110\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3011 - acc: 0.8879 - val_loss: 0.3810 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34110\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3011 - acc: 0.8880 - val_loss: 0.3819 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34110\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3007 - acc: 0.8882 - val_loss: 0.3813 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34110\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 1024\n",
      "Fold: 4\n",
      "best val loss: 0.3410962222751818\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686], [16, 8192, 0, 0.3300208747317219], [16, 8192, 1, 0.330462209139651], [16, 8192, 2, 0.3360145849094056], [16, 8192, 3, 0.32807612699374816], [16, 8192, 4, 0.33612065163969296], [32, 512, 0, 0.33564156908040854], [32, 512, 1, 0.3362385708755917], [32, 512, 2, 0.34011004318270766], [32, 512, 3, 0.33541222581389357], [32, 512, 4, 0.3429361226684169], [32, 1024, 0, 0.3381186140141292], [32, 1024, 1, 0.3369432279519867], [32, 1024, 2, 0.34130778909426684], [32, 1024, 3, 0.33597521700357136], [32, 1024, 4, 0.3410962222751818]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  101.99078917503357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f6754d46278>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.0274 - acc: 0.7004 - val_loss: 0.8006 - val_acc: 0.7991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80061, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6694 - acc: 0.8345 - val_loss: 0.5716 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80061 to 0.57162, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5086 - acc: 0.8637 - val_loss: 0.4674 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57162 to 0.46744, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4338 - acc: 0.8688 - val_loss: 0.4153 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46744 to 0.41526, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3938 - acc: 0.8716 - val_loss: 0.3858 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41526 to 0.38582, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3707 - acc: 0.8722 - val_loss: 0.3683 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38582 to 0.36830, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3567 - acc: 0.8726 - val_loss: 0.3573 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36830 to 0.35730, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3476 - acc: 0.8729 - val_loss: 0.3500 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35730 to 0.35000, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3414 - acc: 0.8731 - val_loss: 0.3451 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35000 to 0.34509, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3368 - acc: 0.8735 - val_loss: 0.3416 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34509 to 0.34160, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3335 - acc: 0.8734 - val_loss: 0.3390 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34160 to 0.33904, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3308 - acc: 0.8736 - val_loss: 0.3372 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33904 to 0.33722, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3287 - acc: 0.8739 - val_loss: 0.3359 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33722 to 0.33593, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3269 - acc: 0.8742 - val_loss: 0.3350 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33593 to 0.33496, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8744 - val_loss: 0.3344 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33496 to 0.33440, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3241 - acc: 0.8747 - val_loss: 0.3341 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33440 to 0.33405, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8750 - val_loss: 0.3340 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33405 to 0.33396, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8753 - val_loss: 0.3339 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33396 to 0.33388, saving model to Post_val_weights1.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8756 - val_loss: 0.3341 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33388\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8758 - val_loss: 0.3344 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33388\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8761 - val_loss: 0.3348 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33388\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8764 - val_loss: 0.3352 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33388\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8767 - val_loss: 0.3357 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33388\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8770 - val_loss: 0.3362 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33388\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8773 - val_loss: 0.3367 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33388\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8777 - val_loss: 0.3374 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33388\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8780 - val_loss: 0.3379 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33388\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8780 - val_loss: 0.3387 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33388\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8782 - val_loss: 0.3393 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33388\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8784 - val_loss: 0.3403 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33388\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8786 - val_loss: 0.3407 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33388\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8791 - val_loss: 0.3416 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33388\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8788 - val_loss: 0.3421 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33388\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8789 - val_loss: 0.3427 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33388\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3122 - acc: 0.8793 - val_loss: 0.3433 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33388\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8793 - val_loss: 0.3439 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33388\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8797 - val_loss: 0.3448 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33388\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8798 - val_loss: 0.3454 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33388\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8802 - val_loss: 0.3460 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33388\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8801 - val_loss: 0.3466 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33388\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8803 - val_loss: 0.3471 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33388\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8803 - val_loss: 0.3480 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33388\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8804 - val_loss: 0.3486 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33388\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8806 - val_loss: 0.3491 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33388\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3088 - acc: 0.8808 - val_loss: 0.3504 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33388\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8814 - val_loss: 0.3507 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33388\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8817 - val_loss: 0.3524 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33388\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8818 - val_loss: 0.3528 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33388\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8822 - val_loss: 0.3539 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33388\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8823 - val_loss: 0.3541 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33388\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8824 - val_loss: 0.3551 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33388\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8824 - val_loss: 0.3554 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33388\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8827 - val_loss: 0.3558 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33388\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8828 - val_loss: 0.3560 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33388\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3042 - acc: 0.8829 - val_loss: 0.3565 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33388\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8828 - val_loss: 0.3569 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33388\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8830 - val_loss: 0.3574 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33388\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3028 - acc: 0.8831 - val_loss: 0.3580 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33388\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8834 - val_loss: 0.3592 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33388\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3020 - acc: 0.8835 - val_loss: 0.3600 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33388\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3013 - acc: 0.8838 - val_loss: 0.3603 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33388\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3009 - acc: 0.8838 - val_loss: 0.3615 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33388\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3005 - acc: 0.8841 - val_loss: 0.3624 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33388\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3002 - acc: 0.8845 - val_loss: 0.3636 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33388\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8848 - val_loss: 0.3629 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33388\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8848 - val_loss: 0.3649 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33388\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2994 - acc: 0.8848 - val_loss: 0.3649 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33388\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2988 - acc: 0.8850 - val_loss: 0.3652 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33388\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2984 - acc: 0.8851 - val_loss: 0.3659 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33388\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2979 - acc: 0.8853 - val_loss: 0.3666 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33388\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8855 - val_loss: 0.3676 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33388\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8863 - val_loss: 0.3682 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33388\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2973 - acc: 0.8865 - val_loss: 0.3689 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33388\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2972 - acc: 0.8866 - val_loss: 0.3693 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33388\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2970 - acc: 0.8870 - val_loss: 0.3701 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33388\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2964 - acc: 0.8871 - val_loss: 0.3704 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33388\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2961 - acc: 0.8873 - val_loss: 0.3710 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33388\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2958 - acc: 0.8876 - val_loss: 0.3711 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33388\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2956 - acc: 0.8879 - val_loss: 0.3727 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33388\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2952 - acc: 0.8879 - val_loss: 0.3721 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33388\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2950 - acc: 0.8883 - val_loss: 0.3733 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33388\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2948 - acc: 0.8885 - val_loss: 0.3739 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33388\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2946 - acc: 0.8887 - val_loss: 0.3748 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33388\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2942 - acc: 0.8888 - val_loss: 0.3760 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33388\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2943 - acc: 0.8890 - val_loss: 0.3762 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33388\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2937 - acc: 0.8898 - val_loss: 0.3772 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33388\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2935 - acc: 0.8897 - val_loss: 0.3792 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33388\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8900 - val_loss: 0.3791 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33388\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2929 - acc: 0.8903 - val_loss: 0.3793 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33388\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2926 - acc: 0.8906 - val_loss: 0.3806 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33388\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2925 - acc: 0.8910 - val_loss: 0.3827 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33388\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8907 - val_loss: 0.3821 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33388\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8905 - val_loss: 0.3817 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33388\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2922 - acc: 0.8905 - val_loss: 0.3830 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33388\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2919 - acc: 0.8909 - val_loss: 0.3827 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33388\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2915 - acc: 0.8912 - val_loss: 0.3823 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33388\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2914 - acc: 0.8913 - val_loss: 0.3834 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33388\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2911 - acc: 0.8911 - val_loss: 0.3825 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33388\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2910 - acc: 0.8912 - val_loss: 0.3825 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33388\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2910 - acc: 0.8910 - val_loss: 0.3832 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33388\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 2048\n",
      "Fold: 0\n",
      "best val loss: 0.333883015684217\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  85.54248547554016\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.0252 - acc: 0.7028 - val_loss: 0.7901 - val_acc: 0.8009\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79006, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6664 - acc: 0.8365 - val_loss: 0.5661 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79006 to 0.56610, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5069 - acc: 0.8640 - val_loss: 0.4658 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56610 to 0.46579, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4330 - acc: 0.8691 - val_loss: 0.4151 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46579 to 0.41512, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3932 - acc: 0.8714 - val_loss: 0.3867 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41512 to 0.38669, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3702 - acc: 0.8724 - val_loss: 0.3698 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38669 to 0.36975, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3562 - acc: 0.8726 - val_loss: 0.3589 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36975 to 0.35893, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3472 - acc: 0.8729 - val_loss: 0.3517 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35893 to 0.35171, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3410 - acc: 0.8733 - val_loss: 0.3467 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35171 to 0.34670, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3366 - acc: 0.8735 - val_loss: 0.3431 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34670 to 0.34314, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3332 - acc: 0.8736 - val_loss: 0.3405 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34314 to 0.34054, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3307 - acc: 0.8737 - val_loss: 0.3387 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34054 to 0.33869, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8739 - val_loss: 0.3373 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33869 to 0.33727, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3270 - acc: 0.8742 - val_loss: 0.3363 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33727 to 0.33635, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8744 - val_loss: 0.3357 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33635 to 0.33567, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8744 - val_loss: 0.3353 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33567 to 0.33526, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8747 - val_loss: 0.3350 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33526 to 0.33498, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8748 - val_loss: 0.3353 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33498\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8751 - val_loss: 0.3353 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33498\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8757 - val_loss: 0.3358 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33498\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8760 - val_loss: 0.3361 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33498\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8763 - val_loss: 0.3369 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33498\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8765 - val_loss: 0.3373 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33498\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8767 - val_loss: 0.3380 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33498\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8772 - val_loss: 0.3386 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33498\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8777 - val_loss: 0.3392 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33498\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8778 - val_loss: 0.3398 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33498\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8779 - val_loss: 0.3410 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33498\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8780 - val_loss: 0.3413 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33498\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8783 - val_loss: 0.3420 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33498\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8784 - val_loss: 0.3428 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33498\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8786 - val_loss: 0.3439 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33498\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8787 - val_loss: 0.3444 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33498\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8790 - val_loss: 0.3455 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33498\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8792 - val_loss: 0.3462 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33498\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8793 - val_loss: 0.3477 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33498\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8796 - val_loss: 0.3485 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33498\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8801 - val_loss: 0.3502 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33498\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8806 - val_loss: 0.3505 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33498\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8808 - val_loss: 0.3519 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33498\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3100 - acc: 0.8809 - val_loss: 0.3526 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33498\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8814 - val_loss: 0.3536 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33498\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8818 - val_loss: 0.3543 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33498\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8817 - val_loss: 0.3561 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33498\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8820 - val_loss: 0.3560 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33498\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8822 - val_loss: 0.3572 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33498\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8824 - val_loss: 0.3585 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33498\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8827 - val_loss: 0.3595 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33498\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8829 - val_loss: 0.3605 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33498\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3050 - acc: 0.8831 - val_loss: 0.3615 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33498\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8832 - val_loss: 0.3626 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33498\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8835 - val_loss: 0.3637 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33498\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3040 - acc: 0.8837 - val_loss: 0.3650 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33498\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8844 - val_loss: 0.3659 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33498\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3033 - acc: 0.8844 - val_loss: 0.3670 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33498\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3030 - acc: 0.8844 - val_loss: 0.3671 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33498\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3027 - acc: 0.8846 - val_loss: 0.3686 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33498\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3023 - acc: 0.8851 - val_loss: 0.3691 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33498\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3019 - acc: 0.8855 - val_loss: 0.3707 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33498\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8857 - val_loss: 0.3709 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33498\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8860 - val_loss: 0.3718 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33498\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8863 - val_loss: 0.3725 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33498\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3009 - acc: 0.8867 - val_loss: 0.3739 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33498\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3005 - acc: 0.8867 - val_loss: 0.3747 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33498\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8870 - val_loss: 0.3753 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33498\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8870 - val_loss: 0.3756 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33498\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2992 - acc: 0.8874 - val_loss: 0.3771 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33498\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2990 - acc: 0.8872 - val_loss: 0.3780 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33498\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2989 - acc: 0.8877 - val_loss: 0.3779 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33498\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2986 - acc: 0.8876 - val_loss: 0.3792 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33498\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2982 - acc: 0.8877 - val_loss: 0.3794 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33498\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2980 - acc: 0.8878 - val_loss: 0.3802 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33498\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2979 - acc: 0.8879 - val_loss: 0.3800 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33498\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2978 - acc: 0.8880 - val_loss: 0.3803 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33498\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8881 - val_loss: 0.3802 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33498\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8880 - val_loss: 0.3812 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33498\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2975 - acc: 0.8878 - val_loss: 0.3804 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33498\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8875 - val_loss: 0.3815 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33498\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2973 - acc: 0.8877 - val_loss: 0.3811 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33498\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2972 - acc: 0.8880 - val_loss: 0.3817 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33498\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2968 - acc: 0.8884 - val_loss: 0.3817 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33498\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2964 - acc: 0.8884 - val_loss: 0.3829 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33498\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2960 - acc: 0.8886 - val_loss: 0.3834 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33498\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2957 - acc: 0.8888 - val_loss: 0.3836 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33498\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2954 - acc: 0.8889 - val_loss: 0.3853 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33498\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2954 - acc: 0.8890 - val_loss: 0.3867 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33498\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2952 - acc: 0.8892 - val_loss: 0.3868 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33498\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8895 - val_loss: 0.3880 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33498\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2943 - acc: 0.8897 - val_loss: 0.3880 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33498\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2939 - acc: 0.8900 - val_loss: 0.3890 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33498\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2936 - acc: 0.8904 - val_loss: 0.3901 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33498\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2933 - acc: 0.8906 - val_loss: 0.3897 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33498\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2930 - acc: 0.8907 - val_loss: 0.3903 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33498\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2929 - acc: 0.8901 - val_loss: 0.3905 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33498\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2925 - acc: 0.8904 - val_loss: 0.3914 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33498\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2922 - acc: 0.8903 - val_loss: 0.3921 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33498\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2918 - acc: 0.8903 - val_loss: 0.3931 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33498\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2916 - acc: 0.8902 - val_loss: 0.3920 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33498\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2916 - acc: 0.8902 - val_loss: 0.3922 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33498\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2913 - acc: 0.8904 - val_loss: 0.3916 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33498\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 2048\n",
      "Fold: 1\n",
      "best val loss: 0.334981138929289\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5hcdZ3n8fe37t1d3Z1Op3PtQKJGCIRLQhvYQRTEcQMoiIqAuoqr5hkeGXRGd5/ozCLD6q7zrIOOO6iLDo7OKsjGUeJsHGbUsOAFJskAMeGWcEs610463Unf6vrbP36nuqs73elOqE6lqj6v56mn61yq6lcp+Jzf+Z7fOcecc4iISOULlbsBIiJSGgp0EZEqoUAXEakSCnQRkSqhQBcRqRKRcn3wrFmz3KJFi8r18SIiFWnz5s0HnXNt4y0rW6AvWrSITZs2levjRUQqkpm9OtEylVxERKqEAl1EpEoo0EVEqkTZaugiUl0ymQydnZ0MDQ2VuylVIZFI0N7eTjQanfJrFOgiUhKdnZ00NjayaNEizKzczalozjkOHTpEZ2cnixcvnvLrVHIRkZIYGhqitbVVYV4CZkZra+sJ7+0o0EWkZBTmpXMy/5YVF+gbX+nmKw8/TzaXL3dTREROKxUX6E/uPMzfbNjBUFaBLiIjenp6+MY3vnHCr7v66qvp6emZhhadehUX6IloGIBUJlfmlojI6WSiQM9ms8d93fr165kxY8Z0NeuUqrhRLvGI3wal1EMXkSJr1qzhxRdf5MILLyQajZJIJGhpaeG5557jhRde4N3vfje7du1iaGiIT33qU6xevRoYuQxJX18fV111FW9+85v57W9/y4IFC3jooYeoq6sr8zebugoM9KCHrkAXOW39xc+28cyeIyV9z3PmN/GFd5074fIvf/nLbN26laeeeopHHnmEa665hq1btw4P+7vvvvuYOXMmg4ODvOlNb+K9730vra2to95j+/bt3H///Xz729/m/e9/Pz/+8Y/50Ic+VNLvMZ0mLbmY2X1mdsDMtk6w3Mzs62a2w8y2mNmK0jdzRKGHPqSSi4gcx8qVK0eN4f7617/OBRdcwCWXXMKuXbvYvn37Ma9ZvHgxF154IQAXXXQRr7zyyqlqbklMpYf+d8DfAN+fYPlVwJLgcTHwzeDvtIhHVXIROd0dryd9qjQ0NAw/f+SRR/jFL37B7373O+rr67n88svHHeMdj8eHn4fDYQYHB09JW0tl0h66c+5RoPs4q1wHfN95jwMzzGxeqRo41nDJRT10ESnS2NjI0aNHx13W29tLS0sL9fX1PPfcczz++OOnuHWnRilq6AuAXUXTncG8vWNXNLPVwGqAM84446Q+TAdFRWQ8ra2tXHrppSxbtoy6ujrmzJkzvGzVqlV861vfYunSpZx11llccsklZWzp9DmlB0Wdc/cC9wJ0dHS4k3mP4WGLCnQRGeOHP/zhuPPj8Tg///nPx11WqJPPmjWLrVtHDhV+9rOfLXn7plspxqHvBhYWTbcH86bFSA9dJRcRkWKlCPR1wIeD0S6XAL3OuWPKLaUyUkNXD11EpNikJRczux+4HJhlZp3AF4AogHPuW8B64GpgBzAAfHS6Ggsjo1yG1EMXERll0kB3zt08yXIHfLJkLZrEcMlFPXQRkVEq7louOlNURGR8FRjoOigqIjKeigv0UMiIhUPqoYvIa5JMJgHYs2cP73vf+8Zd5/LLL2fTpk3HfZ+vfe1rDAwMDE+X83K8FRfo4HvpqqGLSCnMnz+ftWvXnvTrxwZ6OS/HW5mBHg2p5CIio6xZs4Z77rlnePrOO+/ki1/8IldeeSUrVqzgvPPO46GHHjrmda+88grLli0DYHBwkJtuuomlS5dy/fXXj7qWy6233kpHRwfnnnsuX/jCFwB/wa89e/ZwxRVXcMUVVwD+crwHDx4E4O6772bZsmUsW7aMr33ta8Oft3TpUj7xiU9w7rnn8o53vKNk14ypuMvngj8wOqQeusjp6+drYN/vS/uec8+Dq7484eIbb7yRT3/603zyk37Q3YMPPsjDDz/M7bffTlNTEwcPHuSSSy7h2muvnfB+nd/85jepr6/n2WefZcuWLaxYMXLx2C996UvMnDmTXC7HlVdeyZYtW7j99tu5++672bBhA7NmzRr1Xps3b+a73/0uTzzxBM45Lr74Yt761rfS0tIybZfprcweekQ9dBEZbfny5Rw4cIA9e/bw9NNP09LSwty5c/n85z/P+eefz9vf/nZ2797N/v37J3yPRx99dDhYzz//fM4///zhZQ8++CArVqxg+fLlbNu2jWeeeea47fn1r3/N9ddfT0NDA8lkkve85z089thjwPRdprcie+ixiA6KipzWjtOTnk433HADa9euZd++fdx444384Ac/oKuri82bNxONRlm0aNG4l82dzMsvv8xXvvIVNm7cSEtLC7fccstJvU/BdF2mtzJ76NGwAl1EjnHjjTfywAMPsHbtWm644QZ6e3uZPXs20WiUDRs28Oqrrx739W95y1uGL/C1detWtmzZAsCRI0doaGigubmZ/fv3j7rQ10SX7b3sssv46U9/ysDAAP39/fzkJz/hsssuK+G3PVZF9tD9KBeVXERktHPPPZejR4+yYMEC5s2bxwc/+EHe9a53cd5559HR0cHZZ5993NffeuutfPSjH2Xp0qUsXbqUiy66CIALLriA5cuXc/bZZ7Nw4UIuvfTS4desXr2aVatWMX/+fDZs2DA8f8WKFdxyyy2sXLkSgI9//OMsX758Wu+CZP7M/VOvo6PDTTa+cyIfvu9fOTKY4aefvHTylUXklHj22WdZunRpuZtRVcb7NzWzzc65jvHWr8ySi2roIiLHqNxAV8lFRGSUCg10HRQVOR2Vq4RbjU7m37IyA11nioqcdhKJBIcOHVKol4BzjkOHDpFIJE7odRU8ykU9dJHTSXt7O52dnXR1dZW7KVUhkUjQ3t5+Qq+p0EBXyUXkdBONRlm8eHG5m1HTKrLkkoiGSOfy5PPatRMRKZhSoJvZKjN73sx2mNmacZafaWa/NLMtZvaImZ3YfsIJKty1KJ1TL11EpGDSQDezMHAPcBVwDnCzmZ0zZrWvAN93zp0P3AX891I3tFjhrkVDGrooIjJsKj30lcAO59xLzrk08ABw3Zh1zgF+FTzfMM7ykopHC7ehUw9dRKRgKoG+ANhVNN0ZzCv2NPCe4Pn1QKOZtY59IzNbbWabzGzTazkSPnyjaI10EREZVqqDop8F3mpmTwJvBXYDx9RDnHP3Ouc6nHMdbW1tJ/1hulG0iMixpjJscTewsGi6PZg3zDm3h6CHbmZJ4L3OuWm7S+pIoKuHLiJSMJUe+kZgiZktNrMYcBOwrngFM5tlZoX3+hxwX2mbOVoiGpRc1EMXERk2aaA757LAbcDDwLPAg865bWZ2l5ldG6x2OfC8mb0AzAG+NE3tBYp66Kqhi4gMm9KZos659cD6MfPuKHq+Flhb2qZNLB700IfUQxcRGVaRZ4qqhy4icqzKDnQdFBURGVaZga6DoiIix6jMQFcPXUTkGBUZ6MPDFlVDFxEZVpGBrjNFRUSOVZGBHgkZIYMh9dBFRIZVZKCbWXDXIvXQRUQKKjLQoXCjaPXQRUQKKjfQdaNoEZFRKjjQVXIRESlWsYGeUMlFRGSUig1030NXoIuIFFRwoId0k2gRkSKVG+gquYiIjFK5ga6DoiIio1RwoGvYoohIscoOdJVcRESGTSnQzWyVmT1vZjvMbM04y88wsw1m9qSZbTGzq0vf1NESUZVcRESKTRroZhYG7gGuAs4Bbjazc8as9uf4m0cvB24CvlHqho6lHrqIyGhT6aGvBHY4515yzqWBB4DrxqzjgKbgeTOwp3RNHF88GtawRRGRIlMJ9AXArqLpzmBesTuBD5lZJ7Ae+OPx3sjMVpvZJjPb1NXVdRLNHVHooTvnXtP7iIhUi1IdFL0Z+DvnXDtwNfD3ZnbMezvn7nXOdTjnOtra2k7ukwa6Yd/viYcN5yCTU6CLiMDUAn03sLBouj2YV+xjwIMAzrnfAQlgVikaeIx/+x58683UhzKA7lokIlIwlUDfCCwxs8VmFsMf9Fw3Zp2dwJUAZrYUH+ivraYykVgSgKQNAbpRtIhIwaSB7pzLArcBDwPP4kezbDOzu8zs2mC1zwCfMLOngfuBW9x0FbfjjQAkUaCLiBSLTGUl59x6/MHO4nl3FD1/Bri0tE2bQNBDr2cAgJRGuoiIAJV4pmjcB3qdGwR0o2gRkYLKC/SYL7kUAl0HRUVEvMoL9KCGnsj1A6qhi4gUVGCg+5JL3AU1dAW6iAhQiYEeHBSN5YKSiw6KiogAFRzocZVcRERGqbxAD4Ug2kA0p5KLiEixygt0gHiSSNb30HXFRRERrzIDPZYknFHJRUSkWGUGejxJOFsIdPXQRUSgUgM91kgo3QegG0WLiAQqM9DjSSzdRyys29CJiBRUZqDHkpDuC+5apJKLiAhUaqDHk5DqIx4Nq4cuIhKozEAv6qFr2KKIiFeZgR5vhMwAdRGnHrqISKAyAz04/b85ktEoFxGRQGUGenDFxRmhlA6KiogEphToZrbKzJ43sx1mtmac5V81s6eCxwtm1lP6phYp9NBDQyq5iIgEJr2nqJmFgXuAPwQ6gY1mti64jygAzrk/KVr/j4Hl09DWEcFNLprCKQW6iEhgKj30lcAO59xLzrk08ABw3XHWvxm4vxSNm1Chh26Duh66iEhgKoG+ANhVNN0ZzDuGmZ0JLAZ+NcHy1Wa2ycw2dXV1nWhbRwQ19GRIPXQRkYJSHxS9CVjrnBu32+ycu9c51+Gc62hrazv5Twl66En10EVEhk0l0HcDC4um24N547mJ6S63wHANvYFB9dBFRAJTCfSNwBIzW2xmMXxorxu7kpmdDbQAvyttE8cxHOga5SIiUjBpoDvnssBtwMPAs8CDzrltZnaXmV1btOpNwAPOOTc9TS0SSYCFqXODGocuIhKYdNgigHNuPbB+zLw7xkzfWbpmTcIM4knq3CCZnCOXd4RDdso+XkTkdFSZZ4oCxBqpc/5G0WmVXUREKjjQ40kS+UFAN4oWEYFKDvRYknje99CHVEcXEangQI+PBHp/KlvmxoiIlF/lBnosSTznA/3wQKbMjRERKb/KDfR4I9Eg0HsU6CIiFRzosSThbD8APQPpMjdGRKT8KjfQ40lC6T5APXQREajkQI8lsXyGulCWnkH10EVEKjfQg+u5zE9k1UMXEaGSAz24hO6cOgW6iAhUcqAHN7mYG0ur5CIiQiUHetBDb4tn1EMXEaGSAz2oobdG0wp0EREqOdCDHvrMSFrj0EVEqORAD2roLZEU/emcLqErIjWvcgM96KE3hVIAOjAqIjWvcgM9qKE3hoYA6FUdXURq3JQC3cxWmdnzZrbDzNZMsM77zewZM9tmZj8sbTPHEY5COE4DPtB7BhXoIlLbJr2nqJmFgXuAPwQ6gY1mts4590zROkuAzwGXOucOm9ns6WrwKPEk9c7ftehwv0ouIlLbptJDXwnscM695JxLAw8A141Z5xPAPc65wwDOuQOlbeYE4o0kgvuKqocuIrVuKoG+ANhVNN0ZzCv2RuCNZvYbM3vczFaN90ZmttrMNpnZpq6urpNrcbFYI7HgmuiqoYtIrSvVQdEIsAS4HLgZ+LaZzRi7knPuXudch3Ouo62t7bV/ajxJJNtPOGQc1lh0EalxUwn03cDCoun2YF6xTmCdcy7jnHsZeAEf8NMrlsTSfcyoi6rkIiI1byqBvhFYYmaLzSwG3ASsG7POT/G9c8xsFr4E81IJ2zm+eBJSfcyoj6rkIiI1b9JAd85lgduAh4FngQedc9vM7C4zuzZY7WHgkJk9A2wA/pNz7tB0NXpYLAnpPmbUx3RikYjUvEmHLQI459YD68fMu6PouQP+NHicOvFG30NvjbK3d+iUfrSIyOmmcs8UhZEeel2UXtXQRaTGVXagx5OAoy2R1RUXRaTmVXagBxfomh1N64qLIlLzKjvQG/xY9tmRI4CuuCgita2yA73Zn7A6O38Q0NmiIlLbKjvQm9oBmJn1l445rEAXkRpW2YHe0AahKM0ZH+g6MCoitayyAz0Ugqb51A/uA3TFRRGpbZUd6ADN7cQH9gLqoYtIbav8QG9aQPjobiIho0c1dBGpYZUf6M0LsKN7mVkXUslFRGpa5Qd60wLIZ1mU6FfJRURqWuUHerMfuvi6eK9KLiJS06om0M+MHFagi0hNq/xAb/Jni863bpVcRKSmVX6g17VAtJ45HNRBURGpaZUf6GbQtIBZuQMMpHOksrlyt0hEpCwqP9ABmhcwIzj9XxfoEpFaNaVAN7NVZva8me0wszXjLL/FzLrM7Kng8fHSN/U4mtpJpvYDukCXiNSuSQPdzMLAPcBVwDnAzWZ2zjir/sg5d2Hw+E6J23l8zQuIDx0kSpZd3QOn9KNFRE4XU+mhrwR2OOdecs6lgQeA66a3WSeoaQGGY44d5sWuvnK3RkSkLKYS6AuAXUXTncG8sd5rZlvMbK2ZLRzvjcxstZltMrNNXV1dJ9HcCQQ3uji7vpeXuvpL974iIhWkVAdFfwYscs6dD/wL8L3xVnLO3euc63DOdbS1tZXooxm+0cV5yX710EWkZk0l0HcDxT3u9mDeMOfcIedcKpj8DnBRaZo3RUEP/Y11vbx0UD10EalNUwn0jcASM1tsZjHgJmBd8QpmNq9o8lrg2dI1cQrijZBo5oxwN939aQ7364xREak9kwa6cy4L3AY8jA/qB51z28zsLjO7NljtdjPbZmZPA7cDt0xXgyfU1M5s528W/dJBlV1EpPZEprKSc249sH7MvDuKnn8O+Fxpm3aCmhfQdNhXgl480M9FZ84sa3NERE616jhTFKBpAbH+vcTCIV5UD11EalD1BHrzAmywm7Naw7x4QAdGRaT2VE+gB0MXVzT3q4YuIjWpegJ99tkAXJToZOehATK5fJkbJCJyalVPoM9ZBtF6zsk+Rzbv2KlruohIjameQA9HYf4K5h39PQAvHlDZRURqS/UEOsDCldR3byNBSmeMikjNqbJAvxjLZ3lLwy710EWk5lRXoLe/CYC31r+iHrqI1JzqCvSGVmh9A8vtBXYc6MM5V+4WiYicMtUV6ADtK1k8uI3ewTTdukiXiNSQ6gv0hSupyxzmTNvPdtXRRaSGVGGgXwxAR+gFfrvjYJkbIyJy6lRfoLedDfEm3tG0kw3Pl/A2dyIip7nqC/RQCNo7uCi0nd/v7qXraGry14iIVIHqC3SAhRfT2r+DJAM8+oJ66SJSG6o00FdiOP59ww42PH+g3K0RETklphToZrbKzJ43sx1mtuY4673XzJyZdZSuiSdh0WXQMJv/WP8oj20/SFZXXhSRGjBpoJtZGLgHuAo4B7jZzM4ZZ71G4FPAE6Vu5AkLR2H5hzjn6OPUD+7j6c6ecrdIRGTaTaWHvhLY4Zx7yTmXBh4Arhtnvf8K/CUwVML2nbyLPgI4boo+wobnVEcXkeo3lUBfAOwqmu4M5g0zsxXAQufc/y1h216blkXY69/GB6P/j0ef31vu1oiITLvXfFDUzELA3cBnprDuajPbZGaburpOQa+546PMyh+kbd+jHDh6euw4iEiVcQ4GuqHredi1EQ7ugKFeP/8Ui0xhnd3AwqLp9mBeQSOwDHjEzADmAuvM7Frn3KbiN3LO3QvcC9DR0TH93/aNq8jUzeYDuV/xs6f/Ax978+Jp/0gROc3lsjBwCPr2wdH9cHQv5NIQSUC0zgdx+iik+iAz6Jfl0v75wCH/GDwMqSOQOurDO5899nNCUf/X5cDlIVoPsSTEG+GKz8N57yv5V5tKoG8ElpjZYnyQ3wR8oLDQOdcLzCpMm9kjwGfHhnlZhKNEOz7MFY/9Fe9+5Hd88OIzSETD5W6ViLxW2TT07ISeV6F3FxzZA9kU4Hx49h+EI7vhyF7IpQADMx/AA91+vamyMIRjEE1Afat/NM2H+Nk+nBPN0NAGydkQb4LBbug74IPfzL/eQpAZgHSfb0N967T8s0wa6M65rJndBjwMhIH7nHPbzOwuYJNzbt20tKxULvoI/Obr3Jq6jweeuIRb3vy6crdIpDrlc4D5s7ULnIOhHh+2kTiE44Dzvd90H2SLSqHZoaDHvMcHcroP0v2je8npATj8Mhx+1fd8h5kf3Yb58Gxog6Z5MOdc3/PG+bbEG/2yhlmQnAON86Bxjl8nMxi0x/x68aTvVYcqpxNo5bpmeEdHh9u06dR04t1jX8V+eSf/Jfxp/mzNHeqlS21JD/jeYupo0GMM+XA8stf3bvsO+F5sLuPnD/XCYI//awahiH+Ny/vSQj47uj6cOuIDeLDbrxdvgroZ/v36u/x7noxIHcQafKiGo76XHIlDyyJofQO0vh5mnAkzzvDBHJ5KwaHymdlm59y45/rUxL+AXXo7R55+iM90fZuf/ead3HD5m8rdJJETl035gBzo9uE51OtDOnXU92RzGR/Mg4d9D7ZnZ1CKGJz8vUNBYIajvoRQN8MHs5nveefSQekh6nuzFmK419u8AOpn+V5voUc+2OM3BMk23xOOJPx7DPeAkxBr9AHtj735NjTO9eHc0FYzAV1KtfEvFgrTeOO9pO+5lLmPriF16cPEo7Xx1eU0NdTrAzc9APmMD+uhHugPDroN9YwccDu6L+hJ75/8fcMxXy6YcSbMOx/OusoHbd1MPx8A58O5aT40t/vAraCygkysZlLN2t5I54rPctm//Tce+8GdXHbLF8vdJKkGzvng7dvve8Yu7x/ZIejZ5Q/aHdkz0otOHfG954FJrtUfb/KPRJMP3CXvgOaFvt5b3+oDOtHsl8eSvjQRjo30dqUm1UygA7zums/w5Pbfcdkr/5MXH3S8/oYv6n8AGV8+FwxtO+DD+ug+P2qit9M/Hzjo68b9XX70wkQKPeF4E8Tq/d+l74SWxb4WHE+OlDvqZvjSRV2Lyg1yUmrqvxoLR1h624P84u4P8PZn/obun6SYef3/UKjXiuHxx/uDWvQh/7fw6Ovyy/r2+yAfNYoi0NDm67wNbTDz9cH0HEjOhfqZQenCfEDPWAiN8xXOcsrU3H9piXiMZbd+nx99/WPcuOXbpPtfJXbtV30tUSpLPjcyFtm5kTpw34FgDPIe36Pu7fTP+7sYd/xxKFo0lG02zF3mA7oQ3Mk5PrQb5/uxyCKnqZoYtjiep3Ye5h+/fQefCf+IeDRC6Mr/AitX6+BQOTnnDwIW6tGDPf5v/4GREzWGjvh1Bg5C98vBSSMTiCX9hrppgS97NM7zgV04CaShLahHt2gvTSrG8YYt1mygA2x+tZu/+Pt/4rOZ/8Vb7CmY+Tq4+I/gwg8UjQiQ16Rw0HDwsB9q19sJB7fDoRd9jzk75IezDfb4Zemj479PJOEDONEcjHNu8eOQZy3x9ehQODixxUHDbB/giaZT+lVFTgUF+nEcODLErf97M7M6/4XPN/8zZw5u84Gx7L1w9jth8WV+rKyMyKaDs/j6fN356F5/XYzBHj+KY+iIL3H0vOpHdIw3Djo5d+QMvXDMB3Vzu380zvMHCBMt/m9ytu9tqxctokCfTDqb56/++Xnu+83LrAjt4M7Zj3H2kd9gmX5/8sPit8AZF8PCi2HeBf4CPpUumxoZrZFN+Z5yZsiXM4Z6Rp8tWFz2KJxVOJFw3O/dNM3zY6FbFvladF2LfzTO82f5qfcsclIU6FO089AAX/nn51n39B6aoln++Mw9XJt4ktndG7Hul/xKFvJB1XaWD6bCqceFs+XqWyESm75G5nM+ZNP9QQgPjpyAMtQ7cgW41NHgQkB9IxcEKiwbPOzr0ZOJNwVjnZt9Lzk5Z6TsURj7XBj1UQht7c2ITCsF+gnatqeXHzyxk589tYejqSzzmhNc8/oo18zYybmhV4kd3u6vfdz90uiLCxXEGn0PNN7ke6vROv+IJIILFEX9yIp8xpcvRl3rwvmQTvcHFy9K+x5xNh2Ecu/UvkQo6sc4xxt9e+LJkfbUzQguShScYh1N+J51NBEEeHDat4bbiZx2FOgnaTCd45+27eXhrfv59Y6D9KWyhAzOmtvEijNmcEF7M+fNSPO66CHiA/v8iSYD3cGFkI6MXGuj0JMuHADMZfwjHB256BBF9eFoXdADrh+5Ql3hlO66oK4cS45sJOLJkZ50IbTVUxapSgr0Ekhn82x6pZvHX+7myZ2HeXJnD30pf1H7cMhY1FrP4lkNLGpt4MxZDSxsqWPhzHoWzKjT1R1FpGRq/mqLpRCLhPiDN8ziD97g7+WRyzteOdTPc3uP8ty+I7yw/yivHBzgse0HSWXzo147KxljbnOCuU11zG2OM7cpwZymBLMa48xqiNOajDErGScWec13BBSRGqZAP0nhkPH6tiSvb0tyzfnzhufn8479R4fY1T3Iru4BOg8Psu/IIHt7h9jVPcCmV7vpGciM+57NdVFmJWPMbIgxoz5GS32UlvoYLQ3+eVMiSmMiSmMiEjz883gkhGlIn0jNU6CXWChkzGuuY15zHSsXzxx3naFMjgNHUnT1pTjUl+JgX5qDfanhR3d/ml3dA2zpTHN4IEN6TI9/rHDIqI+GScTCNMYjNNZFaa7zYd8QC9MQj9AQi/i/8TANsQh1sbB/RMMk48GyYN36WFgbCJEKpEAvg0Q0zBmt9ZzRWj/pus45BjM5uvvTHB3KBo/M8N8jQ1kG0lkG0jkG0zn6Ull6BzP0DmboPDzAQCpHfzpLfypLfoqHS8ygIRYhEQ1TFwtRFw0Tj4RJREN+XjRMfSxMfTxCIhImHg0Rj4wsq4v6eXXRMIngEYv4daJhI2RGOFT0MCMSDvn3j4QJhbQxETkZUwp0M1sF/DX+nqLfcc59eczyPwI+CeSAPmC1c+6ZEre1JpkZ9bEI9bHXtu11zpHK5ulLZRlI5RjIjN4IDKSz9KVy9Kd8+Pelsgxl8qQyOQYzOYYyueHXdx1NMZDOMZDOkQrmp3PH34s4EbFwiLpYsNGIhWmq86WmpkSE5rooTXW+/FQf7GXUB3sWyWBPJBmPkEz4vZFYWOUoqR2TpiJo0IAAAAgqSURBVISZhYF7gD8EOoGNZrZuTGD/0Dn3rWD9a4G7gVXT0F45SWY23FsmWfr3z+UdqazfQPgNQJ6hYGOQzuZJZXOkMnkyeUc+78gVHs7/zeTypLJ5Upk8g5kcg8FeR3/a75X0DmbY1T3AkWDvIzvF3Q0ziEdCxCPhkfJTEP6FDYH/d/HrFPY+ErEw8XCIUMgIhyASGtkDiUdDxMIhouEQsUhoeM8lHvHT2ohIuUyl27cS2OGcewnAzB4ArgOGA905d6Ro/QbGvUapVLNwqDR7ElPhnGMokx8uNQ0EexnFexf9qSz9wR7EUNZvXAbSueHlA+kcB/tS9KezwxufVKZ0exrRsBGPhIdLUfFIiHiw4YiF/fNYOEQsYkRCISJhC6b9hiIaDhEJmZ8fbCQKG6ZYsOEYLn3FItTHg+fRCImYNiq1air/9y0AdhVNdwIXj13JzD4J/CkQA95WktaJjMPMhg/qtpb4vXN5f8xiIJ0lkxvZm8jk8gwFew9DmRyZXH7UXsVQdmSD4PdI8sN7JkOZ0X9T2Ty9g/5gdyaXJ5vLk8n5zyi8PptzZPJ5XstpIn4vwh+fiATHK0JmhMwfvC9sQEY2NuHh4xzhkH+NP97hN9hm/nhHyAj2TPz6hWMehbY653AOcs4Nfw/DhjduheMoIYNwOEQimF+8p1R8vCYezIsHbdWGamIl60455+4B7jGzDwB/Dnxk7DpmthpYDXDGGWeU6qNFSiYcMl+Dj58e4wWKy1Hp4FhFKpMjHWxgBoI9keK9lcLxjnTwyDtHNu83Es5BPihzFW98hjI5egczpDI5skFZLJPPk88zXBpzzpF3fjqd9RuxyTY4IYNIOASOku39FPZcoqEQFmycCgfai5cV9mTqYyMjueqKDtD7PZ8x08MH7/1eTiQ8siGMhCxYPnogQOFvJNjoldNU/qvdDSwsmm4P5k3kAeCb4y1wzt0L3Av+TNEptlGkZvmRQOHT8mxj5/xGoTjUzcAwzPC9+aIRS/nCRiSXx+X9hiWTD/ZwMqP3ZIYyOYaKnhc2Oqms36PJBhs653w7/LEYhpelc3kywcZqMJ1jT89QcKA/F2wUfTtyUx36NQUhg3gkPLwRiISMwiU9zCAa8ntL0bDx6be/kXddML9kn10wlUDfCCwxs8X4IL8J+EDxCma2xDm3PZi8BtiOiFQ1M3+cYKpCISNxmm2cskVlruFSWVBO8yUxv2eSyzu/ociOlM1SmfFLatn8yPoFrlB+yvmBATPqo9PyfSYNdOdc1sxuAx7GD1u8zzm3zczuAjY559YBt5nZ24EMcJhxyi0iIqebSDhEJByifhqveH0qTalQ6JxbD6wfM++OouefKnG7RETkBOlqUCIiVUKBLiJSJRToIiJVQoEuIlIlFOgiIlVCgS4iUiUU6CIiVaJsN4k2sy7g1ZN8+SzgYAmbUylq8XvX4neG2vzetfid4cS/95nOubbxFpQt0F8LM9s00V2vq1ktfu9a/M5Qm9+7Fr8zlPZ7q+QiIlIlFOgiIlWiUgP93nI3oExq8XvX4neG2vzetfidoYTfuyJr6CIicqxK7aGLiMgYCnQRkSpRcYFuZqvM7Hkz22Fma8rdnulgZgvNbIOZPWNm28zsU8H8mWb2L2a2PfjbUu62lpqZhc3sSTP7x2B6sZk9EfzePzKzKrkVwQgzm2Fma83sOTN71sz+XY381n8S/Pe91czuN7NEtf3eZnafmR0ws61F88b9bc37evDdt5jZihP9vIoKdDMLA/cAVwHnADeb2TnlbdW0yAKfcc6dA1wCfDL4nmuAXzrnlgC/DKarzaeAZ4um/xL4qnPuDfi7YX2sLK2aXn8N/JNz7mzgAvz3r+rf2swWALcDHc65Zfi7od1E9f3efwesGjNvot/2KmBJ8FjNBPdmPp6KCnRgJbDDOfeScy6NvyH1dWVuU8k55/Y65/4teH4U/z/4Avx3/V6w2veAd5enhdPDzNrx96T9TjBtwNuAtcEq1fidm4G3AH8L4JxLO+d6qPLfOhAB6swsAtQDe6my39s59yjQPWb2RL/tdcD3nfc4MMPM5p3I51VaoC8AdhVNdwbzqpaZLQKWA08Ac5xze4NF+4A5ZWrWdPka8J+BfDDdCvQ457LBdDX+3ouBLuC7QanpO2bWQJX/1s653cBXgJ34IO8FNlP9vzdM/Nu+5nyrtECvKWaWBH4MfNo5d6R4mfPjTatmzKmZvRM44JzbXO62nGIRYAXwTefccqCfMeWVavutAYK68XX4Ddp8oIFjSxNVr9S/baUF+m5gYdF0ezCv6phZFB/mP3DO/UMwe39hFyz4e6Bc7ZsGlwLXmtkr+FLa2/C15RnBLjlU5+/dCXQ6554IptfiA76af2uAtwMvO+e6nHMZ4B/w/w1U++8NE/+2rznfKi3QNwJLgiPhMfxBlHVlblPJBbXjvwWedc7dXbRoHfCR4PlHgIdOddumi3Puc865dufcIvzv+ivn3AeBDcD7gtWq6jsDOOf2AbvM7Kxg1pXAM1Txbx3YCVxiZvXBf++F713Vv3dgot92HfDhYLTLJUBvUWlmapxzFfUArgZeAF4E/qzc7Zmm7/hm/G7YFuCp4HE1vqb8S2A78AtgZrnbOk3f/3LgH4PnrwP+FdgB/B8gXu72TcP3vRDYFPzePwVaauG3Bv4CeA7YCvw9EK+23xu4H3+MIIPfG/vYRL8tYPhRfC8Cv8ePADqhz9Op/yIiVaLSSi4iIjIBBbqISJVQoIuIVAkFuohIlVCgi4hUCQW6iEiVUKCLiFSJ/w+UllUtgRpIbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  86.52636194229126\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.0229 - acc: 0.7032 - val_loss: 0.7978 - val_acc: 0.7963\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79784, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6647 - acc: 0.8378 - val_loss: 0.5744 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79784 to 0.57435, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5050 - acc: 0.8653 - val_loss: 0.4722 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57435 to 0.47217, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4316 - acc: 0.8700 - val_loss: 0.4207 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47217 to 0.42072, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3918 - acc: 0.8717 - val_loss: 0.3919 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42072 to 0.39193, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3688 - acc: 0.8726 - val_loss: 0.3750 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39193 to 0.37501, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3547 - acc: 0.8732 - val_loss: 0.3646 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37501 to 0.36458, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3457 - acc: 0.8737 - val_loss: 0.3578 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36458 to 0.35776, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3395 - acc: 0.8741 - val_loss: 0.3531 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35776 to 0.35305, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3351 - acc: 0.8741 - val_loss: 0.3496 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35305 to 0.34962, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3317 - acc: 0.8742 - val_loss: 0.3471 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34962 to 0.34711, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3292 - acc: 0.8746 - val_loss: 0.3452 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34711 to 0.34518, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3272 - acc: 0.8745 - val_loss: 0.3437 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34518 to 0.34372, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3256 - acc: 0.8749 - val_loss: 0.3427 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34372 to 0.34270, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3241 - acc: 0.8751 - val_loss: 0.3419 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34270 to 0.34189, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8752 - val_loss: 0.3415 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34189 to 0.34145, saving model to Post_val_weights3.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8754 - val_loss: 0.3411 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34145 to 0.34110, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8756 - val_loss: 0.3410 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34110 to 0.34100, saving model to Post_val_weights3.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8758 - val_loss: 0.3410 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34100\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8763 - val_loss: 0.3410 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34100\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8763 - val_loss: 0.3411 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34100\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8764 - val_loss: 0.3412 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34100\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8769 - val_loss: 0.3413 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34100\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8771 - val_loss: 0.3417 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34100\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8774 - val_loss: 0.3421 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34100\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8775 - val_loss: 0.3425 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34100\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8779 - val_loss: 0.3433 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34100\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8779 - val_loss: 0.3438 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34100\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8779 - val_loss: 0.3451 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34100\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8782 - val_loss: 0.3453 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34100\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8782 - val_loss: 0.3462 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34100\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8783 - val_loss: 0.3469 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34100\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8787 - val_loss: 0.3479 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34100\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3114 - acc: 0.8790 - val_loss: 0.3490 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34100\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8793 - val_loss: 0.3501 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34100\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8795 - val_loss: 0.3508 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34100\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8797 - val_loss: 0.3524 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34100\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3093 - acc: 0.8800 - val_loss: 0.3533 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34100\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8802 - val_loss: 0.3546 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34100\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8807 - val_loss: 0.3554 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34100\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8805 - val_loss: 0.3570 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34100\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8808 - val_loss: 0.3578 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34100\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3072 - acc: 0.8812 - val_loss: 0.3590 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34100\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8819 - val_loss: 0.3598 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34100\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8822 - val_loss: 0.3607 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34100\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8823 - val_loss: 0.3612 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34100\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8825 - val_loss: 0.3625 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34100\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8828 - val_loss: 0.3631 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34100\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8832 - val_loss: 0.3645 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34100\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8837 - val_loss: 0.3655 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34100\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8841 - val_loss: 0.3676 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34100\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8840 - val_loss: 0.3688 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34100\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3032 - acc: 0.8840 - val_loss: 0.3699 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34100\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3027 - acc: 0.8845 - val_loss: 0.3706 - val_acc: 0.8585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34100\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3023 - acc: 0.8849 - val_loss: 0.3722 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34100\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3020 - acc: 0.8850 - val_loss: 0.3728 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34100\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3015 - acc: 0.8855 - val_loss: 0.3740 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34100\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3015 - acc: 0.8855 - val_loss: 0.3753 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34100\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3010 - acc: 0.8856 - val_loss: 0.3766 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34100\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3007 - acc: 0.8857 - val_loss: 0.3774 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34100\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3004 - acc: 0.8856 - val_loss: 0.3781 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34100\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8858 - val_loss: 0.3784 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34100\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2994 - acc: 0.8862 - val_loss: 0.3801 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34100\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2992 - acc: 0.8867 - val_loss: 0.3806 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34100\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2988 - acc: 0.8868 - val_loss: 0.3808 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34100\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2984 - acc: 0.8870 - val_loss: 0.3823 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34100\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2984 - acc: 0.8872 - val_loss: 0.3827 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34100\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2980 - acc: 0.8877 - val_loss: 0.3829 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34100\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8876 - val_loss: 0.3835 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34100\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2971 - acc: 0.8878 - val_loss: 0.3846 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34100\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2970 - acc: 0.8878 - val_loss: 0.3859 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34100\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2966 - acc: 0.8883 - val_loss: 0.3860 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34100\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2961 - acc: 0.8887 - val_loss: 0.3870 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34100\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2962 - acc: 0.8878 - val_loss: 0.3874 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34100\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2958 - acc: 0.8883 - val_loss: 0.3887 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34100\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2957 - acc: 0.8886 - val_loss: 0.3899 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34100\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2951 - acc: 0.8888 - val_loss: 0.3903 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34100\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2948 - acc: 0.8890 - val_loss: 0.3906 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34100\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2945 - acc: 0.8891 - val_loss: 0.3925 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34100\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2944 - acc: 0.8896 - val_loss: 0.3921 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34100\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2940 - acc: 0.8898 - val_loss: 0.3928 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34100\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2938 - acc: 0.8895 - val_loss: 0.3934 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34100\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2937 - acc: 0.8897 - val_loss: 0.3940 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34100\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2933 - acc: 0.8901 - val_loss: 0.3939 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34100\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2930 - acc: 0.8901 - val_loss: 0.3948 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34100\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2928 - acc: 0.8902 - val_loss: 0.3949 - val_acc: 0.8509\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34100\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8902 - val_loss: 0.3963 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34100\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8899 - val_loss: 0.3961 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34100\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8904 - val_loss: 0.3976 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34100\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2922 - acc: 0.8907 - val_loss: 0.3981 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34100\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8906 - val_loss: 0.3990 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34100\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2925 - acc: 0.8901 - val_loss: 0.3995 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34100\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8903 - val_loss: 0.4009 - val_acc: 0.8462\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34100\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2931 - acc: 0.8900 - val_loss: 0.4024 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34100\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2932 - acc: 0.8896 - val_loss: 0.4031 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34100\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2939 - acc: 0.8893 - val_loss: 0.4044 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34100\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2947 - acc: 0.8889 - val_loss: 0.4044 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34100\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2955 - acc: 0.8887 - val_loss: 0.4040 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34100\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2960 - acc: 0.8884 - val_loss: 0.4027 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34100\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2961 - acc: 0.8884 - val_loss: 0.4013 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34100\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 2048\n",
      "Fold: 2\n",
      "best val loss: 0.3410016691963575\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  87.24475479125977\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.0255 - acc: 0.7008 - val_loss: 0.7987 - val_acc: 0.7950\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79867, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6654 - acc: 0.8376 - val_loss: 0.5642 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79867 to 0.56417, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5056 - acc: 0.8640 - val_loss: 0.4649 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56417 to 0.46492, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4323 - acc: 0.8696 - val_loss: 0.4132 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46492 to 0.41324, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3923 - acc: 0.8711 - val_loss: 0.3838 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41324 to 0.38379, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3691 - acc: 0.8719 - val_loss: 0.3668 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38379 to 0.36680, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3551 - acc: 0.8728 - val_loss: 0.3559 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36680 to 0.35588, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3460 - acc: 0.8732 - val_loss: 0.3493 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35588 to 0.34935, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3399 - acc: 0.8735 - val_loss: 0.3443 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34935 to 0.34427, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3355 - acc: 0.8736 - val_loss: 0.3410 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34427 to 0.34096, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3323 - acc: 0.8737 - val_loss: 0.3390 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34096 to 0.33901, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3298 - acc: 0.8741 - val_loss: 0.3368 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33901 to 0.33677, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3278 - acc: 0.8743 - val_loss: 0.3358 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33677 to 0.33583, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3261 - acc: 0.8743 - val_loss: 0.3347 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33583 to 0.33473, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8746 - val_loss: 0.3343 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33473 to 0.33431, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8750 - val_loss: 0.3339 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33431 to 0.33388, saving model to Post_val_weights4.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8751 - val_loss: 0.3338 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33388 to 0.33379, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8755 - val_loss: 0.3339 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33379\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8758 - val_loss: 0.3343 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33379\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8763 - val_loss: 0.3346 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33379\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8766 - val_loss: 0.3350 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33379\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8768 - val_loss: 0.3357 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33379\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8772 - val_loss: 0.3363 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33379\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8775 - val_loss: 0.3367 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33379\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8778 - val_loss: 0.3375 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33379\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8778 - val_loss: 0.3378 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33379\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8778 - val_loss: 0.3385 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33379\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8783 - val_loss: 0.3393 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33379\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8785 - val_loss: 0.3402 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33379\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8789 - val_loss: 0.3415 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33379\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8790 - val_loss: 0.3420 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33379\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8790 - val_loss: 0.3426 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33379\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8793 - val_loss: 0.3440 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33379\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8791 - val_loss: 0.3453 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33379\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8796 - val_loss: 0.3460 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33379\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8797 - val_loss: 0.3469 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33379\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8803 - val_loss: 0.3491 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33379\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8804 - val_loss: 0.3493 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33379\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8807 - val_loss: 0.3501 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33379\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8808 - val_loss: 0.3511 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33379\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8812 - val_loss: 0.3523 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33379\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8811 - val_loss: 0.3535 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33379\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8814 - val_loss: 0.3540 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33379\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8814 - val_loss: 0.3551 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33379\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8817 - val_loss: 0.3556 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33379\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8820 - val_loss: 0.3569 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33379\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8822 - val_loss: 0.3580 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33379\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8825 - val_loss: 0.3591 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33379\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8827 - val_loss: 0.3594 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33379\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8833 - val_loss: 0.3609 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33379\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8834 - val_loss: 0.3613 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33379\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8836 - val_loss: 0.3627 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33379\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8837 - val_loss: 0.3634 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33379\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3030 - acc: 0.8840 - val_loss: 0.3642 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33379\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3028 - acc: 0.8842 - val_loss: 0.3651 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33379\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3023 - acc: 0.8841 - val_loss: 0.3672 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33379\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3020 - acc: 0.8846 - val_loss: 0.3672 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33379\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8847 - val_loss: 0.3677 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33379\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8848 - val_loss: 0.3683 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33379\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3009 - acc: 0.8851 - val_loss: 0.3697 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33379\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3006 - acc: 0.8851 - val_loss: 0.3693 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33379\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3002 - acc: 0.8850 - val_loss: 0.3717 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33379\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8854 - val_loss: 0.3707 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33379\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8858 - val_loss: 0.3719 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33379\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2993 - acc: 0.8854 - val_loss: 0.3719 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33379\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2990 - acc: 0.8859 - val_loss: 0.3731 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33379\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2989 - acc: 0.8861 - val_loss: 0.3743 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33379\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2986 - acc: 0.8863 - val_loss: 0.3739 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33379\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2983 - acc: 0.8863 - val_loss: 0.3742 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33379\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2980 - acc: 0.8866 - val_loss: 0.3748 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33379\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2978 - acc: 0.8866 - val_loss: 0.3751 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33379\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8868 - val_loss: 0.3767 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33379\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8869 - val_loss: 0.3769 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33379\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8872 - val_loss: 0.3778 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33379\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8873 - val_loss: 0.3801 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33379\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8878 - val_loss: 0.3801 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33379\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8877 - val_loss: 0.3808 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33379\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8879 - val_loss: 0.3808 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33379\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2973 - acc: 0.8879 - val_loss: 0.3810 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33379\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2971 - acc: 0.8881 - val_loss: 0.3807 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33379\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2968 - acc: 0.8879 - val_loss: 0.3811 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33379\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2964 - acc: 0.8882 - val_loss: 0.3809 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33379\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2960 - acc: 0.8886 - val_loss: 0.3815 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33379\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2955 - acc: 0.8887 - val_loss: 0.3814 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33379\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2952 - acc: 0.8891 - val_loss: 0.3822 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33379\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8891 - val_loss: 0.3826 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33379\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2946 - acc: 0.8894 - val_loss: 0.3836 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33379\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2941 - acc: 0.8897 - val_loss: 0.3837 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33379\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2939 - acc: 0.8898 - val_loss: 0.3851 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33379\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8900 - val_loss: 0.3860 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33379\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2931 - acc: 0.8899 - val_loss: 0.3862 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33379\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2929 - acc: 0.8902 - val_loss: 0.3872 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33379\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8901 - val_loss: 0.3873 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33379\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2926 - acc: 0.8905 - val_loss: 0.3895 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33379\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2924 - acc: 0.8903 - val_loss: 0.3893 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33379\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8903 - val_loss: 0.3896 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33379\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2922 - acc: 0.8898 - val_loss: 0.3895 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33379\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2919 - acc: 0.8902 - val_loss: 0.3905 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33379\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2919 - acc: 0.8901 - val_loss: 0.3906 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33379\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2917 - acc: 0.8904 - val_loss: 0.3906 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33379\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 2048\n",
      "Fold: 3\n",
      "best val loss: 0.3337871924408695\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3df5TcdX3v8ed7fu/O/kyyCcluINEGEgiBhCVgEQXRNsCViKiAWsWr5tQDBdt670Fvi5arp7aHQ6kt6kFFa6sgN7aa2liuP0jxFzTJFdJACITwI5uQZPN7f83vz/3j853dyWY3uwmzmczM63HOnJ35zndmPpOB1/fzfX8/38/XnHOIiEj1C1W6ASIiUh4KdBGRGqFAFxGpEQp0EZEaoUAXEakRkUp98IwZM9y8efMq9fEiIlVp48aN+5xzHWM9V7FAnzdvHhs2bKjUx4uIVCUze2W851RyERGpEQp0EZEaoUAXEakRFauhi0htyWaz9PT0kEqlKt2UmpBIJOjq6iIajU76NQp0ESmLnp4empubmTdvHmZW6eZUNecc+/fvp6enh/nz50/6dSq5iEhZpFIppk+frjAvAzNj+vTpJ7y3o0AXkbJRmJfPyfxbVl2gr3/5APc8upVcvlDppoiInFaqLtB/++pB/v6xbaRyCnQRGXHo0CG+/OUvn/DrrrnmGg4dOjQFLTr1qi7QE9EwAOlsvsItEZHTyXiBnsvljvu6tWvX0tbWNlXNOqWqbpRLPOK3QWn10EWkxJ133smLL77IhRdeSDQaJZFI0N7eznPPPcfzzz/Pu971Lnbs2EEqleKOO+5g1apVwMg0JP39/Vx99dW8+c1v5te//jWdnZ388Ic/pKGhocLfbPKqMNCDHroCXeS09Rf/+gzP7jpS1vc8d04Ln33neeM+/8UvfpHNmzfz1FNPsW7dOq699lo2b948POzvwQcfZNq0aQwNDXHxxRdzww03MH369KPe44UXXuChhx7ia1/7Gu973/v4/ve/zwc/+MGyfo+pNGHJxcweNLO9ZrZ5nOfNzL5kZtvMbJOZLSt/M0eM9NBVchGR8S1fvvyoMdxf+tKXuOCCC7j00kvZsWMHL7zwwjGvmT9/PhdeeCEAF110ES+//PKpam5ZTKaH/i3g74Fvj/P81cCC4HYJ8JXg75SIR4NAz6qHLnK6Ol5P+lRJJpPD99etW8dPf/pTfvOb39DY2MgVV1wx5hjveDw+fD8cDjM0NHRK2louE/bQnXOPAweOs8pK4NvOewJoM7PZ5WrgaMWSS0oHRUWkRHNzM319fWM+d/jwYdrb22lsbOS5557jiSeeOMWtOzXKUUPvBHaUPO4Jlr02ekUzWwWsAjjzzDNP6sN0UFRExjJ9+nQuu+wyFi9eTENDA7NmzRp+bsWKFXz1q19l0aJFnHPOOVx66aUVbOnUOaUHRZ1zDwAPAHR3d7uTeQ8dFBWR8Xz3u98dc3k8HufHP/7xmM8V6+QzZsxg8+aRQ4Wf+tSnyt6+qVaOceg7gbklj7uCZVNiuIaug6IiIkcpR6CvAT4UjHa5FDjsnDum3FIuiWIPXQdFRUSOMmHJxcweAq4AZphZD/BZIArgnPsqsBa4BtgGDAIfmarGQmkPXYEuIlJqwkB3zt08wfMOuLVsLZqAxqGLiIyt6uZy0UFREZGxVV2gx4Ieusahi4gcreoCPRwyomFTD11EXpempiYAdu3axXve854x17niiivYsGHDcd/nvvvuY3BwcPhxJafjrbpAB1920SgXESmHOXPmsHr16pN+/ehAr+R0vFUa6CEdFBWRo9x5553cf//9w48/97nP8fnPf56rrrqKZcuWcf755/PDH/7wmNe9/PLLLF68GIChoSFuuukmFi1axPXXX3/UXC6f+MQn6O7u5rzzzuOzn/0s4Cf82rVrF1deeSVXXnkl4Kfj3bdvHwD33nsvixcvZvHixdx3333Dn7do0SI+/vGPc9555/F7v/d7ZZszpuqmz4VioKuHLnLa+vGdsPu/yvueZ5wPV39x3KdvvPFGPvnJT3LrrX7Q3SOPPMKjjz7K7bffTktLC/v27ePSSy/luuuuG/d6nV/5yldobGxky5YtbNq0iWXLRiaP/cIXvsC0adPI5/NcddVVbNq0idtvv517772Xxx57jBkzZhz1Xhs3buSb3/wmTz75JM45LrnkEt761rfS3t4+ZdP0VmcPPRpWoIvIUZYuXcrevXvZtWsXTz/9NO3t7Zxxxhl85jOfYcmSJbz97W9n586d7NmzZ9z3ePzxx4eDdcmSJSxZsmT4uUceeYRly5axdOlSnnnmGZ599tnjtueXv/wl119/PclkkqamJt797nfzi1/8Api6aXqrt4euUS4ip6/j9KSn0nvf+15Wr17N7t27ufHGG/nOd75Db28vGzduJBqNMm/evDGnzZ3ISy+9xD333MP69etpb2/nlltuOan3KZqqaXrVQxeRmnHjjTfy8MMPs3r1at773vdy+PBhZs6cSTQa5bHHHuOVV1457uvf8pa3DE/wtXnzZjZt2gTAkSNHSCaTtLa2smfPnqMm+hpv2t7LL7+cH/zgBwwODjIwMMC//Mu/cPnll5fx2x6renvoOigqIqOcd9559PX10dnZyezZs/nABz7AO9/5Ts4//3y6u7tZuHDhcV//iU98go985CMsWrSIRYsWcdFFFwFwwQUXsHTpUhYuXMjcuXO57LLLhl+zatUqVqxYwZw5c3jssceGly9btoxbbrmF5cuXA/Cxj32MpUuXTulVkMyfuX/qdXd3u4nGd47nD77xJH2pHD+49bKJVxaRU2LLli0sWrSo0s2oKWP9m5rZRudc91jrV2fJJaKSi4jIaNUZ6FGVXERERqvOQI+EdKaoyGmoUiXcWnQy/5ZVGugquYicbhKJBPv371eol4Fzjv3795NIJE7odRrlIiJl0dXVRU9PD729vZVuSk1IJBJ0dXWd0GuqMtATGocuctqJRqPMnz+/0s2oa1VacgmRyRW0ayciUmJSgW5mK8xsq5ltM7M7x3j+LDP7mZltMrN1ZnZi+wknSNcVFRE51oSBbmZh4H7gauBc4GYzO3fUavcA33bOLQHuBv6y3A0tNXwZOo10EREZNpke+nJgm3Nuu3MuAzwMrBy1zrnAz4P7j43xfFnpQtEiIseaTKB3AjtKHvcEy0o9Dbw7uH890Gxm00e/kZmtMrMNZrbh9RwJHwl09dBFRIrKdVD0U8Bbzey3wFuBncAx3Wfn3APOuW7nXHdHR8dJf1g8GpRc1EMXERk2mWGLO4G5JY+7gmXDnHO7CHroZtYE3OCcm7KrpBZ76CnV0EVEhk2mh74eWGBm880sBtwErCldwcxmmFnxvT4NPFjeZh5NJRcRkWNNGOjOuRxwG/AosAV4xDn3jJndbWbXBatdAWw1s+eBWcAXpqi9gD+xCFRyEREpNakzRZ1za4G1o5bdVXJ/NbC6vE0bn3roIiLHqtIzRTUOXURktOoM9KjGoYuIjFadgV4suaiHLiIyrEoDXQdFRURGq85A1+RcIiLHqM5A1ygXEZFjVGWgx8IhzCCdVclFRKSoKgPdzILL0KmHLiJSVJWBDrpQtIjIaFUc6LpQtIhIqeoN9GhIsy2KiJSo3kCPhNVDFxEpUcWBHtKZoiIiJao70HVQVERkWBUHukouIiKlqjfQo+qhi4iUqtpAT0TCqqGLiJSo2kD3PXSVXEREiiYV6Ga2wsy2mtk2M7tzjOfPNLPHzOy3ZrbJzK4pf1OPpoOiIiJHmzDQzSwM3A9cDZwL3Gxm545a7c/wF49eCtwEfLncDR0tHgmT0uRcIiLDJtNDXw5sc85td85lgIeBlaPWcUBLcL8V2FW+Jo6yezOs/wbxsKbPFREpNZlA7wR2lDzuCZaV+hzwQTPrAdYCfzTWG5nZKjPbYGYbent7T6K5wIs/h3/7E5rCGQW6iEiJch0UvRn4lnOuC7gG+EczO+a9nXMPOOe6nXPdHR0dJ/dJsSQATZYmX3Dk8gp1ERGYXKDvBOaWPO4KlpX6KPAIgHPuN0ACmFGOBh4j3gxAkhSgsouISNFkAn09sMDM5ptZDH/Qc82odV4FrgIws0X4QD/JmsoEgh56kiFAgS4iUjRhoDvncsBtwKPAFvxolmfM7G4zuy5Y7U+Bj5vZ08BDwC3OOTclLY41AZC0Yg9dI11ERAAik1nJObcWf7CzdNldJfefBS4rb9PGEQR6gxsC4jpbVEQkUH1nisaLga4auohIqeoL9KCGnigMAujkIhGRQBUGuu+hx9VDFxE5StUGeqwwAOigqIhIUfUFejgCkQSxfDBsUQdFRUSAagx0gFiSaM7X0FVyERHxqjTQm4jmi4GukouICFRxoEdyxRq6eugiIlC1gZ4kXCy5aNiiiAhQrYEebyKkHrqIyFGqM9BjSUKZfgBSGuUiIgJUbaA3Y5lBIiHTQVERkUCVBnoSMn26ULSISInqDPR4E2QGiEfD6qGLiASqM9BjSchnSIbzOlNURCRQpYHuL0PXFtGFokVEiqo00P0Uuu2RjEouIiKB6gz04CIXLaG0eugiIoFJBbqZrTCzrWa2zczuHOP5vzGzp4Lb82Z2qPxNLRFModsaSusCFyIigQmvKWpmYeB+4B1AD7DezNYE1xEFwDn3xyXr/xGwdAraOiII9OaweugiIkWT6aEvB7Y557Y75zLAw8DK46x/M/BQORo3rqCG3mwpjXIREQlMJtA7gR0lj3uCZccws7OA+cDPx3l+lZltMLMNvb29J9rWEUGgN1laB0VFRALlPih6E7DaOTdmyjrnHnDOdTvnujs6Ok7+U+J+2GKSIZVcREQCkwn0ncDcksddwbKx3MRUl1tguIeetJQCXUQkMJlAXw8sMLP5ZhbDh/aa0SuZ2UKgHfhNeZs4hmgjYDSS0nzoIiKBCQPdOZcDbgMeBbYAjzjnnjGzu83supJVbwIeds65qWlqCTOINdGAeugiIkUTDlsEcM6tBdaOWnbXqMefK1+zJiHeREPB19Cdc5jZKf14EZHTTXWeKQoQS5JwQ4CuWiQiAlUd6E3ECwp0EZGiKg/04ELRGosuIlLFgR5vIhb00AfTCnQRkeoN9FiSWN730A8PZSvcGBGRyqviQG8iGgT6IQW6iEh1B3okNwDAocFMhRsjIlJ51Rvo8SYsO4hR4NCgeugiItUb6LEkhqOBjAJdRIQqD3SAmfEcB1VyERGp5kD3U+iekchqlIuICFUd6EEPPZHTQVEREao50OP+uqIzY1kNWxQRoZoDPbhQ9LRoVgdFRUSoiUDPqOQiIkJVB7qvobdHMhweylIoTP11NURETmfVG+hBDb0llKbgoC+Vq3CDREQqq3oDPSi5NIfSABwaUtlFROrbpALdzFaY2VYz22Zmd46zzvvM7Fkze8bMvlveZo4hHIVwnCZSADowKiJ1b8JrippZGLgfeAfQA6w3szXOuWdL1lkAfBq4zDl30MxmTlWDjxJL0mh+TnQNXRSRejeZHvpyYJtzbrtzLgM8DKwctc7HgfudcwcBnHN7y9vMccSbSLhiD10lFxGpb5MJ9E5gR8njnmBZqbOBs83sV2b2hJmtGOuNzGyVmW0wsw29vb0n1+JSJZehU8lFROpduQ6KRoAFwBXAzcDXzKxt9ErOuQecc93Oue6Ojo7X/6mxJNF8UHJRoItInZtMoO8E5pY87gqWleoB1jjnss65l4Dn8QE/tWJNhDL9NMcjmnFRROreZAJ9PbDAzOabWQy4CVgzap0f4HvnmNkMfAlmexnbObZYEjIDtDZGNeOiiNS9CQPdOZcDbgMeBbYAjzjnnjGzu83sumC1R4H9ZvYs8BjwP5xz+6eq0cPizZDup70xpoOiIlL3Jhy2COCcWwusHbXsrpL7DviT4HbqxJKQ6aetJaphiyJS96r3TFHwZ4tm+mltiOqgqIjUveoP9HyG6QmNQxcRqe5AL17kIp7TjIsiUveqPND9dUWnR4MZF9OacVFE6ld1B3rzGQDM4gCgsouI1LfqDvRWf75TR8FPI6ADoyJSz6o70Fv8lDJtWT8XmIYuikg9q+5AjzdBopWm9G5AJRcRqW/VHegArXNpGCoGunroIlK/qj/QWzqJ9fu5whToIlLPqj/QW7uwIztpjkd0XVERqWs1EOidMHSQWQ159dBFpK5Vf6C3dAGwIHFYB0VFpK5Vf6C3+kCfFz2oYYsiUtdqIND9WPSu0H6VXESkrlV/oDfPAYzZ7FfJRUTqWvUHeiQGTbPocPs046KI1LXqD3SA1k6m5fZqxkURqWuTCnQzW2FmW81sm5ndOcbzt5hZr5k9Fdw+Vv6mHkdrF83pYD4XlV1EpE5NGOhmFgbuB64GzgVuNrNzx1j1e865C4Pb18vczuNr6SKZeg1w7O1Ln9KPFhE5XUymh74c2Oac2+6cywAPAyuntlknqLWLcD5FG/1s7+2vdGtERCpiMoHeCewoedwTLBvtBjPbZGarzWzuWG9kZqvMbIOZbejt7T2J5o4jGLp4VuQAL/YOlO99RUSqSLkOiv4rMM85twT4CfAPY63knHvAOdftnOvu6Ogo00czfHLR0tYBXtyrHrqI1KfJBPpOoLTH3RUsG+ac2++cKxavvw5cVJ7mTVJw+v+ixiO8qJKLiNSpyQT6emCBmc03sxhwE7CmdAUzm13y8DpgS/maOAnJDghFmR89yI6DQ6Rz+VP68SIip4PIRCs453JmdhvwKBAGHnTOPWNmdwMbnHNrgNvN7DogBxwAbpnCNh8rFILWTmbbAfIFx6v7B1kwq/mUNkFEpNImDHQA59xaYO2oZXeV3P808OnyNu0EtXQxLbUHgBd7+xXoIlJ3auNMUYDWruFL0Wmki4jUoxoK9E5Cfa/R2RLVSBcRqUu1E+gtneDyXDQto5EuIlKXaifQp80HYFmyl+29AzinWRdFpL7UTqDPWQbABfYCfekcvZrTRUTqTO0EekMbdCzkrMFnAdimsouI1JnaCXSArm7aDjwNOI10EZG6U2OBvpxQ6gCLYns10kVE6k6NBfrFALyj5VWNdBGRulNbgd6xEOItLI+8yHaVXESkztRWoIdC0LmMc7LPsfPQEEMZTdIlIvWjtgIdoGs5Mwa20UhKZRcRqSu1F+hzl2MUWBLazoaXD1S6NSIip0ztBXqnv7bGVU2vsO75Ml7mTkTkNFd7gd44DaYv4C0NL/GbF/eTyqqOLiL1ofYCHaDrYuanniWdy/PE9v2Vbo2IyClRm4E+92Ji6QP8TqSXdVtVdhGR+lCbgT7vcgA+2rGF/1AdXUTqxKQC3cxWmNlWM9tmZnceZ70bzMyZWXf5mngSZiyAzm6uzvyEl/b188p+nWQkIrVvwkA3szBwP3A1cC5ws5mdO8Z6zcAdwJPlbuRJWfYh2ga2s8xeUNlFROrCZHroy4FtzrntzrkM8DCwcoz1/jfwV0CqjO07eYvfDdEkH03+knVb91a6NSIiU24ygd4J7Ch53BMsG2Zmy4C5zrl/O94bmdkqM9tgZht6e6e41xxvhvOu5+2FX/P09p0avigiNS/yet/AzELAvcAtE63rnHsAeACgu7t76q8Rt+wPiD/1T1xV+DW/2va7XLVo1pR/pIjUoKFD0PcahCL+ZiHIZyA7BPksmPllLg+DB2BgHwzuh0LOL3MF/z4WAgx+5yqYfUHZmzmZQN8JzC153BUsK2oGFgPrzAzgDGCNmV3nnNtQroaelLmXUJi+gD848B98/j/ezdsWziRoo4jUG+cgMwCD+3zgZgd94BbykD4C/b0wsNev4wr+1r8HXtsEh14pb1sSrRUL9PXAAjObjw/ym4D3F590zh0GZhQfm9k64FMVD3MAM0LLPsSSn/w5h155mie2n82b3ji90q0SkclyzocuQQ8YB6nDkDrk/2aHRm6D+0ZCOZf2PeNCHvr3wuEef8tOMOLNwhBr8jO3WsgH75ylcNGHoX2+D/l8xv+NJCASh3DMt9MVfE+9cQYkZ/iz1sOxkV65/0J+vVB0Sv65Jgx051zOzG4DHgXCwIPOuWfM7G5gg3NuzZS0rFwufD/u8b/mL+3b3PPT83nTGy+rdItEqlsuA3ufhV2/hdeegnQwq6kZZAZ92A4dgkK2JMycD8J8zt8Px3wYYpAbGildhKP+hkG6z98K2RNrX7wVogkfzqGwD9eOs+GNb4PmMyDZ4ZfFkkH5JAzxJkjOhIZ2H+ZValI1dOfcWmDtqGV3jbPuFa+/WWWUnIH9/l9y0ZrbOPvV7/Hk9oVc8gb10qUO5NI+bCNxiDb4cCvkR2q/mf4gNPv9skLWB/LBl+HAdl9myKX9awo5GDroe8FDh4DgEFiiDRqn+8fOQbTRX7C9fR5EYkHpIlg3HPM3gHw66EU737Zogw/yfDaoOxf8wIZ4s39PGKlDx1t88CZaR14bSfiQTnYEG4r69LoPilaFpR8k/8wP+PSLD/GZ//tWLvnDGyrdIpHjcw4O74DXnvb3m2b6sMql4cguOLLT13rNAPPh3PfayHNHdsHA6JFkQU95MhKtvsQQbfQbgkgMWuYEpYTp0HEOzFnmg1vHpU4b9RHoZoRX/h25L13Mzbu+yG9euJw3LZhZ6VZJrcoOwcFXRnqUruAPwGUGglv/SDnhyE44tMP/dS6oyUZh/zY/SuJENLRD8xxomQ2zL4SWTt9bzqUgm/I98HAsKGvER3rAsSYf2MUySNtZvv4rVac+Ah187+Lqv+Lif72Vhx76Y954x9eZ2dpQ6VZJtXDOB3DxgNzQwaAEcQCGDvj7R3bB7s2w/4WRMJ9IohXazoTWub4nnEv5XvjZV0PnUpi91AfwwF5/wC8S80Hd0unrvsVyRiQBscap+/5SFeon0IH4sg9w4KWN3Lz5QR79yke44k//kXh0ao42y2muUBip4/bv8T3qQ6/4gM4N+R7t4D449Kq/9e85fkhHGnxZZNZ5cO5KmHF2cHAPX5KIJv1BuFij7xHHm4PHyVPzfaUu1FWgY8a0G+7lxWyY39/6NTb+/QdYdvt3sLBCvSYUxxn37YYjPXB4p68r9+/xf/v2+Pv9e31ojycU9QfaGtp8+eGNV0HzLH8AsKHN96obpvkSR0O7L09EtbcnlVdfgQ5gxhtvvodfPhjmza9+ldfufTOz3nsfoXlvqnTLpFSh4EsZR3YFB/t2+pNBMgO+Hp3uD8J5jz/4l+73y8c66JdohaYz/JC1uZf4nnS8eWTURdNMf3Cv7Sx/0C8UPtXfVqQs6i/QA797yxf57jdnceWrf0foWyvILLqe2DvugmlvqHTTalNm0I9dHugdGZqWGfAH/oYO+L8D+/zz/Xt9L3us8cfhmO8Nx5p8ELfOhc5lfihbtNGXMJrPCOrMc/xNvWepE+bc1E+pMpbu7m63YUNlTyZ1zvHwr55j36N/zarwj4iRxRZeC2+6Fc58k4ZjTUYuA327/Fl4gwf8KdSpw/7+4H5fh973Aux7fvwadDjmh8IlO0ZuLbOhebYP5+LIjeRMf1BQpI6Z2Ubn3JjXnKjrQC9a//IB/vyffsa1qR/x32M/J1k4AtPeCGf/Pix4hw/3eunl5dK+vNG324/qyPT7csbwcLsjvjZ9uMePk+7bzZhlDgv72nLDNL/XM3sJnLEEWjt9jToU8f+mjdN9r1obT5FJUaBPwpFUlq89vp1/+sVzXOMe54Otmzhn6ClChYw/fbl9PsxcBLMW+0l1Zl/gd+dPtyAq5EeG1hXPAMyl/djo4vwXR90OjcwM17/X96iPJ5LwPee2udB6JrR2BbdOP4dFotXf4i1VfQq1yOlKgX4CevvSfHndNlZv7CGbGmBl64us7NjNonAPbX3bsIPbR0oHsWZITg8m4+nwIyGaZvnHsUYfftFGP69EpGFkfgkLJv4pzujm8r50kRvy4Vu85dMjEw/lUiXjoA+PnJiS6fe3bGrkdO7JnA0Yio6M2BieTGi6D+eWTl/iiLf6sc6xpK9Zx5IjQ/FEpCIU6CdhKJPn3595je+t38F/vnSAgoOWRIS3zGvkbe29LI28TKd7jVjqwMgsb/17Ju7hvh6RxEjvN9FSMp65KZjTotEHcHE4XSzpzwiMxPwGpdh7TgQHEE+3vQsRmZAC/XU6NJjhV9v2s27rXta/fICX9w8OPzd3WgPnzGrh7FlNzJ+R5A3TYpzVmGF6PI/l0n4oXTY1crLKcK+8MNJTt5A/5bo4HWfptJzFiYeKkxeJSF07XqDX7bDFE9HWGOPaJbO5dslsAA4MZHh6xyE27zzMc3v62Lq7j3Vb95IrjGwc45EQc9oa6GxrYE5bI3PapjOnrYGZzXFmtSSY2RynvTFGKKResoiUhwL9JExLxrhy4UyuXDgywVc2X6Dn4BAv7xvglf0D7Dw0xK5DKXoODbFuay97+9LHvE8kZMxoijOzJc6MpjgzmmJ0NMeZlowzLRllWjJOe2OU9sYY7ckYyVhYV1wSkXEp0MskGg4xf0aS+TPGnpsjncuz+3CKvX1p9h5Js7fP3+/tS7O3L83uwyk27zzM/oEM+cLYZbBwyGhORGhORGhJRGltiNKSiNLSEKEpHqU5EaEpHiEZj5CMh0nGIjQW/8bCNMYjNEbDNMTCxCMhbRxEaowC/RSJR8KcNT3JWdOPPxlToeA4kspyYCDDgYEMBwezHBzMcHAgw5FUlr5UjiNDWY6kchweyrKtt5/+VI7+tL9NViRkPvhjYRKxMI2xMA3RMImo/9sQC9MY8883xsI0BBuFhtjRGwq/bohE8Nri68MqJYmccgr000woZLQ1xmhrjPGGjhN7bb7gGMzkGEjn6U/nGEjnGMzk/bJMnqFM8XGegeD5/nSeVC5PKljen87R25dmKOsfD6ZzDGbznOix82jYSETCxKN+g5CMR2iK+8CPR0LEI/5+ca+iMR4mFg4RD54v7lUkomFikRDxSIhYJOTfKxbRXobIGCYV6Ga2Avhb/DVFv+6c++Ko5/8QuBXIA/3AKufcs2Vuq0zAl2SiNCfKOxrGOUcqW2CwdIOQyTGYzjOUzZPK+r/p4O9QpkAql2cokyedK25A8sEGJMeBgQLpXIGhTJ6+VJb+dI5xqkwTikVCJDXHLfsAAAf8SURBVCKhklJThFgkRDRsRMMhEpHw8J6F34MobkyCvYqI30NJRELDG5toJEQsHBpetyHmNyrRUIhwyIiGTRsSOS1NGOhmFgbuB94B9ADrzWzNqMD+rnPuq8H61wH3AiumoL1SAWZGQxCKU3E1Vucc6VwhuOVJZwvDexZDmTzZgiMTPFfcuxjM5I9av394jyNHNl/wy1K54T2NoYzf8KRyhXGPUZyIYlkqUbIBKO5BJIK9klgkTDRsfu8i2PuIhUP+3zJYJxr2r4+G/AbIb4xCQcnLr1fcO4kFezYqZ8l4JtNDXw5sc85tBzCzh4GVwHCgO+eOlKyfZNIXLhTxG4xi/R2mfqx9Nl/w4Z71f9O5kfuZXIFMvhBsQIrr+Y1HruDIBc+lgj2MoWyebMn6Q5k8R1I59h5JH/U+mVyeTN7ff72nfkRCNrwnEQkZ4ZARCYWIR0c2LGZG2Aj2KELDt1jEiAX348EeSCzYoETCISJhI2xGyIxQyHDO4RwUnMMMQub3TiZ7/krxteGQDW/I4pEwkbBvR/HvyF6R34AV96YSUb/Rk8mZTKB3AjtKHvcAl4xeycxuBf4EiAFvG+uNzGwVsArgzDPPPNG2ipRFMdyaE6f+s4t7I6lgzyGbL5DN+z2QXMFvAPwGw5euBjO5YIPgNzTpbGF4A5Qr+I1MobgHE2xAsvkCBec/K5d3ZPMFBjJ+Y5XL++eL71ncy8nmT98+WDhkIwfsY6Hg2Iz/Gw2X7iHZ8AateHC+eEzGb/RseO+p+H7FPZ9oeOQ9IkFpLRQKNm4hCJtfHgpBJBTCDDL5Atlcgbxz/n2jYSIV3viU7aCoc+5+4H4zez/wZ8CHx1jnAeAB8GeKluuzRapF6d5I22l0CVDnHPmC8xuI4H4hOJk5ZEaxyFNwfjnmZ44oLf64o96PkR49kCs4f6wlKJVl84XhjVk2f/TGKp0rkC7ZgxoK7vvjM7nh8lwq2DsaHMoPb8iKe0ulrzuVouGRjUokHKK0OlbcUETCxifffjbXXTCn7J8/mUDfCcwtedwVLBvPw8BXXk+jROTUMvNBE5nCizW1Npz6qSsKBUe2UCCX93srxeMwg8EB++KeT3FDkMn7slp+eMMGeef3gop7Q3nnnystb6WLx2qyR29cipUp5/xGLRe0pb1xav4tJhPo64EFZjYfH+Q3Ae8vXcHMFjjnXggeXgu8gIhIhYVCRjwUJj6cdLU9H9KEge6cy5nZbcCj+GGLDzrnnjGzu4ENzrk1wG1m9nYgCxxkjHKLiIhMrUnV0J1za4G1o5bdVXL/jjK3S0RETpDGA4mI1AgFuohIjVCgi4jUCAW6iEiNUKCLiNQIBbqISI2o2EWizawXeOUkXz4D2FfG5lSLevze9fidoT6/dz1+Zzjx732Wc27MqyVULNBfDzPbMN5Vr2tZPX7vevzOUJ/fux6/M5T3e6vkIiJSIxToIiI1oloD/YFKN6BC6vF71+N3hvr83vX4naGM37sqa+giInKsau2hi4jIKAp0EZEaUXWBbmYrzGyrmW0zszsr3Z6pYGZzzewxM3vWzJ4xszuC5dPM7Cdm9kLwt73SbS03Mwub2W/N7EfB4/lm9mTwe3/PzGKVbmO5mVmbma02s+fMbIuZvalOfus/Dv773mxmD5lZotZ+bzN70Mz2mtnmkmVj/rbmfSn47pvMbNmJfl5VBbqZhYH7gauBc4GbzezcyrZqSuSAP3XOnQtcCtwafM87gZ855xYAPwse15o7gC0lj/8K+Bvn3O/gL57y0Yq0amr9LfDvzrmFwAX471/Tv7WZdQK3A93OucX4i+fcRO393t8CVoxaNt5vezWwILit4iQu5VlVgQ4sB7Y557Y75zL465eurHCbys4595pz7v8F9/vw/4N34r/rPwSr/QPwrsq0cGqYWRf+EoZfDx4b8DZgdbBKLX7nVuAtwDcAnHMZ59whavy3DkSABjOLAI3Aa9TY7+2cexw4MGrxeL/tSuDbznsCaDOz2SfyedUW6J3AjpLHPcGymmVm84ClwJPALOfca8FTu4FZFWrWVLkP+J9A8VLt04FDzrlc8LgWf+/5QC/wzaDU9HUzS1Ljv7VzbidwD/AqPsgPAxup/d8bxv9tX3e+VVug1xUzawK+D3zSOXek9Dnnx5vWzJhTM/tvwF7n3MZKt+UUiwDLgK8455YCA4wqr9Tabw0Q1I1X4jdoc4Akx5Ymal65f9tqC/SdwNySx13BsppjZlF8mH/HOffPweI9xV2w4O/eSrVvClwGXGdmL+NLaW/D15bbgl1yqM3fuwfocc49GTxejQ/4Wv6tAd4OvOSc63XOZYF/xv83UOu/N4z/277ufKu2QF8PLAiOhMfwB1HWVLhNZRfUjr8BbHHO3Vvy1Brgw8H9DwM/PNVtmyrOuU8757qcc/Pwv+vPnXMfAB4D3hOsVlPfGcA5txvYYWbnBIuuAp6lhn/rwKvApWbWGPz3XvzeNf17B8b7bdcAHwpGu1wKHC4pzUyOc66qbsA1wPPAi8D/qnR7pug7vhm/G7YJeCq4XYOvKf8MeAH4KTCt0m2dou9/BfCj4P4bgP8EtgH/B4hXun1T8H0vBDYEv/cPgPZ6+K2BvwCeAzYD/wjEa+33Bh7CHyPI4vfGPjrebwsYfhTfi8B/4UcAndDn6dR/EZEaUW0lFxERGYcCXUSkRijQRURqhAJdRKRGKNBFRGqEAl1EpEYo0EVEasT/B3WyM/l3jrM8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  73.45234084129333\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.0293 - acc: 0.6987 - val_loss: 0.8072 - val_acc: 0.7944\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80717, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6675 - acc: 0.8379 - val_loss: 0.5771 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80717 to 0.57709, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5063 - acc: 0.8644 - val_loss: 0.4756 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57709 to 0.47564, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4323 - acc: 0.8699 - val_loss: 0.4229 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47564 to 0.42291, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3919 - acc: 0.8722 - val_loss: 0.3929 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42291 to 0.39292, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3685 - acc: 0.8730 - val_loss: 0.3757 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39292 to 0.37575, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3542 - acc: 0.8736 - val_loss: 0.3646 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37575 to 0.36455, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3450 - acc: 0.8737 - val_loss: 0.3575 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36455 to 0.35752, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3388 - acc: 0.8740 - val_loss: 0.3525 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35752 to 0.35249, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3345 - acc: 0.8741 - val_loss: 0.3489 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35249 to 0.34891, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3312 - acc: 0.8744 - val_loss: 0.3462 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34891 to 0.34622, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3287 - acc: 0.8744 - val_loss: 0.3444 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34622 to 0.34442, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8748 - val_loss: 0.3431 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34442 to 0.34315, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8748 - val_loss: 0.3421 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34315 to 0.34212, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8748 - val_loss: 0.3416 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34212 to 0.34163, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8751 - val_loss: 0.3410 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34163 to 0.34103, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8752 - val_loss: 0.3407 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34103 to 0.34075, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3207 - acc: 0.8759 - val_loss: 0.3405 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34075 to 0.34055, saving model to Post_val_weights5.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8762 - val_loss: 0.3407 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34055\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8763 - val_loss: 0.3403 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34055 to 0.34033, saving model to Post_val_weights5.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8765 - val_loss: 0.3404 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34033\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8770 - val_loss: 0.3407 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34033\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8773 - val_loss: 0.3406 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34033\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8774 - val_loss: 0.3409 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34033\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8776 - val_loss: 0.3411 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34033\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8775 - val_loss: 0.3416 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34033\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8781 - val_loss: 0.3417 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34033\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8783 - val_loss: 0.3423 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34033\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8784 - val_loss: 0.3429 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34033\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8785 - val_loss: 0.3437 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34033\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8787 - val_loss: 0.3445 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34033\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8785 - val_loss: 0.3452 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34033\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8788 - val_loss: 0.3462 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34033\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8792 - val_loss: 0.3466 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34033\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8796 - val_loss: 0.3475 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34033\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8797 - val_loss: 0.3478 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34033\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8799 - val_loss: 0.3484 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34033\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8801 - val_loss: 0.3493 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34033\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8806 - val_loss: 0.3499 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34033\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8805 - val_loss: 0.3508 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34033\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3082 - acc: 0.8808 - val_loss: 0.3522 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34033\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8812 - val_loss: 0.3530 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34033\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8813 - val_loss: 0.3541 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34033\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8817 - val_loss: 0.3554 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34033\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8820 - val_loss: 0.3563 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34033\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8822 - val_loss: 0.3572 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34033\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8824 - val_loss: 0.3582 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34033\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3054 - acc: 0.8826 - val_loss: 0.3594 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34033\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3051 - acc: 0.8825 - val_loss: 0.3599 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34033\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8827 - val_loss: 0.3611 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34033\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8827 - val_loss: 0.3613 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34033\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8826 - val_loss: 0.3626 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34033\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8828 - val_loss: 0.3631 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34033\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8832 - val_loss: 0.3641 - val_acc: 0.8588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34033\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8834 - val_loss: 0.3648 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34033\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3028 - acc: 0.8833 - val_loss: 0.3659 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34033\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3025 - acc: 0.8838 - val_loss: 0.3672 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34033\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8839 - val_loss: 0.3687 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34033\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3022 - acc: 0.8841 - val_loss: 0.3694 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34033\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8841 - val_loss: 0.3704 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34033\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3019 - acc: 0.8841 - val_loss: 0.3712 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34033\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8844 - val_loss: 0.3727 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34033\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3016 - acc: 0.8846 - val_loss: 0.3730 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34033\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8848 - val_loss: 0.3731 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34033\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3008 - acc: 0.8857 - val_loss: 0.3736 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34033\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8858 - val_loss: 0.3735 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34033\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2991 - acc: 0.8860 - val_loss: 0.3742 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34033\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2987 - acc: 0.8860 - val_loss: 0.3749 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34033\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2981 - acc: 0.8864 - val_loss: 0.3747 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34033\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2975 - acc: 0.8867 - val_loss: 0.3759 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34033\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2970 - acc: 0.8871 - val_loss: 0.3758 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34033\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2965 - acc: 0.8878 - val_loss: 0.3766 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34033\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2962 - acc: 0.8877 - val_loss: 0.3767 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34033\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2957 - acc: 0.8879 - val_loss: 0.3781 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34033\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2954 - acc: 0.8880 - val_loss: 0.3784 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34033\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8884 - val_loss: 0.3796 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34033\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2945 - acc: 0.8884 - val_loss: 0.3800 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34033\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2941 - acc: 0.8889 - val_loss: 0.3809 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34033\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2938 - acc: 0.8889 - val_loss: 0.3814 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34033\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2936 - acc: 0.8888 - val_loss: 0.3821 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34033\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8889 - val_loss: 0.3827 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34033\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2933 - acc: 0.8892 - val_loss: 0.3839 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34033\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2930 - acc: 0.8890 - val_loss: 0.3842 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34033\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2928 - acc: 0.8892 - val_loss: 0.3852 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34033\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2924 - acc: 0.8896 - val_loss: 0.3851 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34033\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2925 - acc: 0.8896 - val_loss: 0.3867 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34033\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8894 - val_loss: 0.3879 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34033\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2920 - acc: 0.8896 - val_loss: 0.3882 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34033\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2916 - acc: 0.8900 - val_loss: 0.3885 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34033\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2916 - acc: 0.8898 - val_loss: 0.3895 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34033\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2914 - acc: 0.8899 - val_loss: 0.3886 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34033\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2913 - acc: 0.8898 - val_loss: 0.3902 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34033\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2908 - acc: 0.8903 - val_loss: 0.3903 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34033\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2908 - acc: 0.8897 - val_loss: 0.3916 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34033\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2905 - acc: 0.8903 - val_loss: 0.3919 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34033\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2904 - acc: 0.8903 - val_loss: 0.3929 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34033\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2902 - acc: 0.8903 - val_loss: 0.3926 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34033\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2902 - acc: 0.8904 - val_loss: 0.3938 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34033\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2898 - acc: 0.8904 - val_loss: 0.3941 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34033\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2893 - acc: 0.8907 - val_loss: 0.3947 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34033\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 2048\n",
      "Fold: 4\n",
      "best val loss: 0.3403301309214698\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686], [16, 8192, 0, 0.3300208747317219], [16, 8192, 1, 0.330462209139651], [16, 8192, 2, 0.3360145849094056], [16, 8192, 3, 0.32807612699374816], [16, 8192, 4, 0.33612065163969296], [32, 512, 0, 0.33564156908040854], [32, 512, 1, 0.3362385708755917], [32, 512, 2, 0.34011004318270766], [32, 512, 3, 0.33541222581389357], [32, 512, 4, 0.3429361226684169], [32, 1024, 0, 0.3381186140141292], [32, 1024, 1, 0.3369432279519867], [32, 1024, 2, 0.34130778909426684], [32, 1024, 3, 0.33597521700357136], [32, 1024, 4, 0.3410962222751818], [32, 2048, 0, 0.333883015684217], [32, 2048, 1, 0.334981138929289], [32, 2048, 2, 0.3410016691963575], [32, 2048, 3, 0.3337871924408695], [32, 2048, 4, 0.3403301309214698]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  85.16732835769653\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.1555 - acc: 0.6387 - val_loss: 0.9829 - val_acc: 0.7298\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98295, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8771 - acc: 0.7707 - val_loss: 0.7850 - val_acc: 0.8048\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.98295 to 0.78501, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.7072 - acc: 0.8267 - val_loss: 0.6461 - val_acc: 0.8426\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.78501 to 0.64614, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5885 - acc: 0.8533 - val_loss: 0.5514 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64614 to 0.55135, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5121 - acc: 0.8640 - val_loss: 0.4907 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55135 to 0.49068, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4622 - acc: 0.8684 - val_loss: 0.4503 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49068 to 0.45033, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4274 - acc: 0.8701 - val_loss: 0.4217 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45033 to 0.42170, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4024 - acc: 0.8715 - val_loss: 0.4008 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42170 to 0.40078, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3840 - acc: 0.8725 - val_loss: 0.3853 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40078 to 0.38530, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3704 - acc: 0.8735 - val_loss: 0.3737 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38530 to 0.37374, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3602 - acc: 0.8736 - val_loss: 0.3651 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37374 to 0.36511, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3526 - acc: 0.8743 - val_loss: 0.3583 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36511 to 0.35834, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3465 - acc: 0.8744 - val_loss: 0.3532 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35834 to 0.35319, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3419 - acc: 0.8743 - val_loss: 0.3491 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35319 to 0.34908, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3381 - acc: 0.8745 - val_loss: 0.3458 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34908 to 0.34580, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3350 - acc: 0.8745 - val_loss: 0.3433 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34580 to 0.34327, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3323 - acc: 0.8747 - val_loss: 0.3412 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34327 to 0.34118, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3302 - acc: 0.8749 - val_loss: 0.3395 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34118 to 0.33953, saving model to Post_val_weights1.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3284 - acc: 0.8750 - val_loss: 0.3382 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33953 to 0.33823, saving model to Post_val_weights1.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3267 - acc: 0.8752 - val_loss: 0.3371 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33823 to 0.33706, saving model to Post_val_weights1.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8755 - val_loss: 0.3363 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33706 to 0.33629, saving model to Post_val_weights1.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8756 - val_loss: 0.3357 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33629 to 0.33574, saving model to Post_val_weights1.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3227 - acc: 0.8759 - val_loss: 0.3352 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33574 to 0.33521, saving model to Post_val_weights1.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8760 - val_loss: 0.3347 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33521 to 0.33471, saving model to Post_val_weights1.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8764 - val_loss: 0.3345 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33471 to 0.33446, saving model to Post_val_weights1.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8768 - val_loss: 0.3342 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33446 to 0.33422, saving model to Post_val_weights1.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8772 - val_loss: 0.3340 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33422 to 0.33402, saving model to Post_val_weights1.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8775 - val_loss: 0.3340 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33402 to 0.33401, saving model to Post_val_weights1.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8778 - val_loss: 0.3338 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33401 to 0.33383, saving model to Post_val_weights1.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8779 - val_loss: 0.3339 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33383\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8781 - val_loss: 0.3341 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33383\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8784 - val_loss: 0.3344 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33383\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8787 - val_loss: 0.3346 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33383\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8791 - val_loss: 0.3350 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33383\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8796 - val_loss: 0.3354 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33383\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8796 - val_loss: 0.3359 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33383\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8800 - val_loss: 0.3363 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33383\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8803 - val_loss: 0.3367 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33383\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8805 - val_loss: 0.3373 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33383\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8805 - val_loss: 0.3379 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33383\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8808 - val_loss: 0.3384 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33383\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8809 - val_loss: 0.3391 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33383\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8813 - val_loss: 0.3396 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33383\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3070 - acc: 0.8815 - val_loss: 0.3402 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33383\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8817 - val_loss: 0.3409 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33383\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3060 - acc: 0.8821 - val_loss: 0.3414 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33383\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3056 - acc: 0.8821 - val_loss: 0.3422 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33383\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3051 - acc: 0.8824 - val_loss: 0.3429 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33383\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8825 - val_loss: 0.3434 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33383\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3044 - acc: 0.8827 - val_loss: 0.3440 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33383\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3040 - acc: 0.8829 - val_loss: 0.3446 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33383\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8830 - val_loss: 0.3452 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33383\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8831 - val_loss: 0.3457 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33383\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3026 - acc: 0.8831 - val_loss: 0.3464 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33383\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3023 - acc: 0.8833 - val_loss: 0.3467 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33383\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8833 - val_loss: 0.3477 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33383\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3016 - acc: 0.8834 - val_loss: 0.3480 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33383\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8836 - val_loss: 0.3489 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33383\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3009 - acc: 0.8837 - val_loss: 0.3492 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33383\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3005 - acc: 0.8839 - val_loss: 0.3500 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33383\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8843 - val_loss: 0.3503 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33383\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.2997 - acc: 0.8844 - val_loss: 0.3510 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33383\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2992 - acc: 0.8846 - val_loss: 0.3510 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33383\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2989 - acc: 0.8847 - val_loss: 0.3514 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33383\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2984 - acc: 0.8853 - val_loss: 0.3514 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33383\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2979 - acc: 0.8853 - val_loss: 0.3515 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33383\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2975 - acc: 0.8852 - val_loss: 0.3520 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33383\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2973 - acc: 0.8856 - val_loss: 0.3527 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33383\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2969 - acc: 0.8856 - val_loss: 0.3535 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33383\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2966 - acc: 0.8858 - val_loss: 0.3541 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33383\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2962 - acc: 0.8863 - val_loss: 0.3548 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33383\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2959 - acc: 0.8864 - val_loss: 0.3557 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33383\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2955 - acc: 0.8868 - val_loss: 0.3564 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33383\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2953 - acc: 0.8868 - val_loss: 0.3573 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33383\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8868 - val_loss: 0.3584 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33383\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2947 - acc: 0.8871 - val_loss: 0.3583 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33383\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2943 - acc: 0.8873 - val_loss: 0.3595 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33383\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2940 - acc: 0.8874 - val_loss: 0.3598 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33383\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2936 - acc: 0.8875 - val_loss: 0.3606 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33383\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8876 - val_loss: 0.3608 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33383\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2929 - acc: 0.8877 - val_loss: 0.3617 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33383\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2928 - acc: 0.8875 - val_loss: 0.3617 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33383\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2925 - acc: 0.8877 - val_loss: 0.3621 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33383\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8878 - val_loss: 0.3613 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33383\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2920 - acc: 0.8878 - val_loss: 0.3613 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33383\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2918 - acc: 0.8883 - val_loss: 0.3613 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33383\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2913 - acc: 0.8881 - val_loss: 0.3617 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33383\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2913 - acc: 0.8883 - val_loss: 0.3619 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33383\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2907 - acc: 0.8885 - val_loss: 0.3623 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33383\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2905 - acc: 0.8887 - val_loss: 0.3624 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33383\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2899 - acc: 0.8886 - val_loss: 0.3626 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33383\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2897 - acc: 0.8889 - val_loss: 0.3626 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33383\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2894 - acc: 0.8887 - val_loss: 0.3631 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33383\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2891 - acc: 0.8887 - val_loss: 0.3632 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33383\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2887 - acc: 0.8890 - val_loss: 0.3644 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33383\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2884 - acc: 0.8890 - val_loss: 0.3651 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33383\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2880 - acc: 0.8889 - val_loss: 0.3656 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33383\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2878 - acc: 0.8893 - val_loss: 0.3659 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33383\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2875 - acc: 0.8894 - val_loss: 0.3675 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33383\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2872 - acc: 0.8895 - val_loss: 0.3675 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33383\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 4096\n",
      "Fold: 0\n",
      "best val loss: 0.333830724745466\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  80.45899295806885\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.1542 - acc: 0.6397 - val_loss: 0.9748 - val_acc: 0.7244\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97477, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8753 - acc: 0.7726 - val_loss: 0.7744 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97477 to 0.77443, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.7044 - acc: 0.8286 - val_loss: 0.6360 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77443 to 0.63600, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5854 - acc: 0.8538 - val_loss: 0.5457 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63600 to 0.54574, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5099 - acc: 0.8637 - val_loss: 0.4878 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54574 to 0.48781, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4606 - acc: 0.8686 - val_loss: 0.4483 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48781 to 0.44833, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4260 - acc: 0.8704 - val_loss: 0.4201 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44833 to 0.42014, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4011 - acc: 0.8718 - val_loss: 0.3996 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42014 to 0.39958, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3829 - acc: 0.8730 - val_loss: 0.3846 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39958 to 0.38458, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3694 - acc: 0.8737 - val_loss: 0.3733 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38458 to 0.37333, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3594 - acc: 0.8741 - val_loss: 0.3649 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37333 to 0.36485, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3517 - acc: 0.8743 - val_loss: 0.3584 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36485 to 0.35841, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3459 - acc: 0.8744 - val_loss: 0.3532 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35841 to 0.35319, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3413 - acc: 0.8745 - val_loss: 0.3491 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35319 to 0.34914, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3376 - acc: 0.8745 - val_loss: 0.3459 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34914 to 0.34590, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3346 - acc: 0.8746 - val_loss: 0.3433 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34590 to 0.34331, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3321 - acc: 0.8749 - val_loss: 0.3412 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34331 to 0.34123, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3300 - acc: 0.8750 - val_loss: 0.3396 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34123 to 0.33959, saving model to Post_val_weights2.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8751 - val_loss: 0.3382 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33959 to 0.33819, saving model to Post_val_weights2.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3265 - acc: 0.8755 - val_loss: 0.3372 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33819 to 0.33720, saving model to Post_val_weights2.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3251 - acc: 0.8759 - val_loss: 0.3363 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33720 to 0.33632, saving model to Post_val_weights2.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8763 - val_loss: 0.3356 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33632 to 0.33560, saving model to Post_val_weights2.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8766 - val_loss: 0.3351 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33560 to 0.33512, saving model to Post_val_weights2.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8769 - val_loss: 0.3347 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33512 to 0.33474, saving model to Post_val_weights2.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8770 - val_loss: 0.3342 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33474 to 0.33425, saving model to Post_val_weights2.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8772 - val_loss: 0.3343 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33425\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8774 - val_loss: 0.3342 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33425 to 0.33418, saving model to Post_val_weights2.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8777 - val_loss: 0.3341 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33418 to 0.33405, saving model to Post_val_weights2.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8781 - val_loss: 0.3342 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33405\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8783 - val_loss: 0.3343 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33405\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8786 - val_loss: 0.3345 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33405\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8790 - val_loss: 0.3351 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33405\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8791 - val_loss: 0.3350 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33405\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8792 - val_loss: 0.3354 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33405\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3124 - acc: 0.8793 - val_loss: 0.3361 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33405\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8795 - val_loss: 0.3364 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33405\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8798 - val_loss: 0.3367 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33405\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8801 - val_loss: 0.3380 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33405\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8803 - val_loss: 0.3383 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33405\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8803 - val_loss: 0.3388 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33405\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8805 - val_loss: 0.3399 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33405\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8808 - val_loss: 0.3406 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33405\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8808 - val_loss: 0.3414 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33405\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3065 - acc: 0.8813 - val_loss: 0.3421 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33405\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8815 - val_loss: 0.3429 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33405\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8816 - val_loss: 0.3439 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33405\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8817 - val_loss: 0.3452 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33405\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8819 - val_loss: 0.3462 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33405\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3036 - acc: 0.8822 - val_loss: 0.3475 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33405\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8826 - val_loss: 0.3480 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33405\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3026 - acc: 0.8825 - val_loss: 0.3488 - val_acc: 0.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33405\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3020 - acc: 0.8830 - val_loss: 0.3503 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33405\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8832 - val_loss: 0.3519 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33405\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3010 - acc: 0.8832 - val_loss: 0.3520 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33405\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3005 - acc: 0.8835 - val_loss: 0.3533 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33405\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8838 - val_loss: 0.3542 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33405\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.2994 - acc: 0.8841 - val_loss: 0.3552 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33405\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.2990 - acc: 0.8844 - val_loss: 0.3567 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33405\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.2985 - acc: 0.8846 - val_loss: 0.3575 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33405\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.2981 - acc: 0.8847 - val_loss: 0.3580 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33405\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8847 - val_loss: 0.3589 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33405\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8850 - val_loss: 0.3604 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33405\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2971 - acc: 0.8851 - val_loss: 0.3609 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33405\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2967 - acc: 0.8855 - val_loss: 0.3615 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33405\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2965 - acc: 0.8858 - val_loss: 0.3622 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33405\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2965 - acc: 0.8859 - val_loss: 0.3629 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33405\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2967 - acc: 0.8859 - val_loss: 0.3632 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33405\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2969 - acc: 0.8860 - val_loss: 0.3651 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33405\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2970 - acc: 0.8860 - val_loss: 0.3653 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33405\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2967 - acc: 0.8860 - val_loss: 0.3664 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33405\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2960 - acc: 0.8863 - val_loss: 0.3660 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33405\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8870 - val_loss: 0.3666 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33405\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2940 - acc: 0.8874 - val_loss: 0.3664 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33405\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2931 - acc: 0.8881 - val_loss: 0.3673 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33405\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2926 - acc: 0.8882 - val_loss: 0.3688 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33405\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2921 - acc: 0.8887 - val_loss: 0.3691 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33405\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2919 - acc: 0.8888 - val_loss: 0.3686 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33405\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2915 - acc: 0.8890 - val_loss: 0.3700 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33405\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2912 - acc: 0.8891 - val_loss: 0.3703 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33405\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2909 - acc: 0.8892 - val_loss: 0.3711 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33405\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2906 - acc: 0.8898 - val_loss: 0.3726 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33405\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2906 - acc: 0.8895 - val_loss: 0.3731 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33405\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2905 - acc: 0.8896 - val_loss: 0.3736 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33405\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2902 - acc: 0.8897 - val_loss: 0.3753 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33405\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2902 - acc: 0.8900 - val_loss: 0.3755 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33405\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2900 - acc: 0.8899 - val_loss: 0.3770 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33405\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2898 - acc: 0.8904 - val_loss: 0.3786 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33405\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2896 - acc: 0.8904 - val_loss: 0.3790 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33405\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2894 - acc: 0.8901 - val_loss: 0.3805 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33405\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2891 - acc: 0.8906 - val_loss: 0.3812 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33405\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2887 - acc: 0.8909 - val_loss: 0.3808 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33405\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2882 - acc: 0.8908 - val_loss: 0.3820 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33405\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2880 - acc: 0.8908 - val_loss: 0.3827 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33405\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2876 - acc: 0.8905 - val_loss: 0.3829 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33405\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2873 - acc: 0.8909 - val_loss: 0.3831 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33405\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2868 - acc: 0.8909 - val_loss: 0.3836 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33405\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2863 - acc: 0.8913 - val_loss: 0.3836 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33405\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2858 - acc: 0.8914 - val_loss: 0.3835 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33405\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2852 - acc: 0.8915 - val_loss: 0.3844 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33405\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2849 - acc: 0.8919 - val_loss: 0.3843 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33405\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 4096\n",
      "Fold: 1\n",
      "best val loss: 0.3340547772597151\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  81.18636274337769\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.1532 - acc: 0.6395 - val_loss: 0.9796 - val_acc: 0.7277\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97959, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8747 - acc: 0.7725 - val_loss: 0.7836 - val_acc: 0.7989\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97959 to 0.78365, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.7036 - acc: 0.8291 - val_loss: 0.6460 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.78365 to 0.64600, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5846 - acc: 0.8549 - val_loss: 0.5545 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64600 to 0.55452, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5091 - acc: 0.8644 - val_loss: 0.4941 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55452 to 0.49406, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4599 - acc: 0.8691 - val_loss: 0.4537 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49406 to 0.45369, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4255 - acc: 0.8710 - val_loss: 0.4251 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45369 to 0.42507, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4006 - acc: 0.8720 - val_loss: 0.4043 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42507 to 0.40432, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3823 - acc: 0.8729 - val_loss: 0.3891 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40432 to 0.38908, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3688 - acc: 0.8738 - val_loss: 0.3778 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38908 to 0.37776, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3588 - acc: 0.8743 - val_loss: 0.3693 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37776 to 0.36933, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3510 - acc: 0.8745 - val_loss: 0.3629 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36933 to 0.36292, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3452 - acc: 0.8745 - val_loss: 0.3580 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36292 to 0.35800, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3405 - acc: 0.8746 - val_loss: 0.3542 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35800 to 0.35420, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3368 - acc: 0.8747 - val_loss: 0.3513 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.35420 to 0.35125, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3338 - acc: 0.8748 - val_loss: 0.3489 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.35125 to 0.34889, saving model to Post_val_weights3.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3312 - acc: 0.8750 - val_loss: 0.3471 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34889 to 0.34706, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3291 - acc: 0.8752 - val_loss: 0.3456 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34706 to 0.34557, saving model to Post_val_weights3.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3272 - acc: 0.8754 - val_loss: 0.3445 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34557 to 0.34447, saving model to Post_val_weights3.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3256 - acc: 0.8755 - val_loss: 0.3434 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34447 to 0.34341, saving model to Post_val_weights3.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8759 - val_loss: 0.3426 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34341 to 0.34264, saving model to Post_val_weights3.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8761 - val_loss: 0.3420 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.34264 to 0.34200, saving model to Post_val_weights3.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8762 - val_loss: 0.3415 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34200 to 0.34150, saving model to Post_val_weights3.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8763 - val_loss: 0.3411 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34150 to 0.34112, saving model to Post_val_weights3.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8769 - val_loss: 0.3408 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34112 to 0.34085, saving model to Post_val_weights3.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8772 - val_loss: 0.3406 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34085 to 0.34063, saving model to Post_val_weights3.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8774 - val_loss: 0.3406 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34063 to 0.34057, saving model to Post_val_weights3.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8777 - val_loss: 0.3406 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34057\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8779 - val_loss: 0.3406 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34057\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8780 - val_loss: 0.3407 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34057\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8785 - val_loss: 0.3410 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34057\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8788 - val_loss: 0.3412 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34057\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8789 - val_loss: 0.3416 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34057\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8790 - val_loss: 0.3420 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34057\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8792 - val_loss: 0.3425 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34057\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8796 - val_loss: 0.3428 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34057\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8795 - val_loss: 0.3435 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34057\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3095 - acc: 0.8798 - val_loss: 0.3439 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34057\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3089 - acc: 0.8802 - val_loss: 0.3445 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34057\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3083 - acc: 0.8804 - val_loss: 0.3451 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34057\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8805 - val_loss: 0.3458 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34057\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8807 - val_loss: 0.3464 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34057\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8811 - val_loss: 0.3470 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34057\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8813 - val_loss: 0.3477 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34057\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8816 - val_loss: 0.3487 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34057\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8818 - val_loss: 0.3496 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34057\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8821 - val_loss: 0.3503 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34057\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3036 - acc: 0.8824 - val_loss: 0.3513 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34057\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3030 - acc: 0.8826 - val_loss: 0.3522 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34057\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8827 - val_loss: 0.3532 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34057\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3018 - acc: 0.8832 - val_loss: 0.3543 - val_acc: 0.8637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34057\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8832 - val_loss: 0.3554 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34057\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3009 - acc: 0.8834 - val_loss: 0.3562 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34057\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3005 - acc: 0.8838 - val_loss: 0.3572 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34057\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8840 - val_loss: 0.3576 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34057\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.2994 - acc: 0.8840 - val_loss: 0.3589 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34057\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.2988 - acc: 0.8843 - val_loss: 0.3592 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34057\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.2984 - acc: 0.8845 - val_loss: 0.3596 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34057\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.2978 - acc: 0.8850 - val_loss: 0.3603 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34057\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.2973 - acc: 0.8854 - val_loss: 0.3614 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34057\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.2970 - acc: 0.8858 - val_loss: 0.3621 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34057\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.2966 - acc: 0.8860 - val_loss: 0.3633 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34057\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2960 - acc: 0.8861 - val_loss: 0.3632 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34057\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2957 - acc: 0.8861 - val_loss: 0.3639 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34057\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2952 - acc: 0.8862 - val_loss: 0.3650 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34057\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8867 - val_loss: 0.3654 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34057\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2947 - acc: 0.8869 - val_loss: 0.3660 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34057\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2942 - acc: 0.8868 - val_loss: 0.3674 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34057\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2937 - acc: 0.8871 - val_loss: 0.3680 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34057\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2933 - acc: 0.8871 - val_loss: 0.3688 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34057\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2928 - acc: 0.8876 - val_loss: 0.3698 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34057\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2924 - acc: 0.8875 - val_loss: 0.3703 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34057\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2921 - acc: 0.8878 - val_loss: 0.3710 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34057\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2916 - acc: 0.8877 - val_loss: 0.3718 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34057\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2908 - acc: 0.8885 - val_loss: 0.3724 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34057\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2904 - acc: 0.8884 - val_loss: 0.3735 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34057\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2899 - acc: 0.8885 - val_loss: 0.3736 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34057\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2897 - acc: 0.8887 - val_loss: 0.3751 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34057\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2894 - acc: 0.8886 - val_loss: 0.3757 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34057\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2890 - acc: 0.8889 - val_loss: 0.3766 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34057\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2889 - acc: 0.8890 - val_loss: 0.3776 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34057\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2886 - acc: 0.8892 - val_loss: 0.3776 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34057\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2884 - acc: 0.8892 - val_loss: 0.3789 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34057\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2882 - acc: 0.8893 - val_loss: 0.3803 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34057\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2880 - acc: 0.8891 - val_loss: 0.3807 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34057\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2877 - acc: 0.8894 - val_loss: 0.3820 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34057\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2875 - acc: 0.8895 - val_loss: 0.3822 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34057\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2872 - acc: 0.8898 - val_loss: 0.3835 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34057\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2874 - acc: 0.8901 - val_loss: 0.3838 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34057\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2869 - acc: 0.8901 - val_loss: 0.3846 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34057\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2866 - acc: 0.8905 - val_loss: 0.3856 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34057\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2864 - acc: 0.8906 - val_loss: 0.3872 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34057\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2862 - acc: 0.8907 - val_loss: 0.3872 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34057\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2864 - acc: 0.8912 - val_loss: 0.3872 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34057\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2866 - acc: 0.8911 - val_loss: 0.3878 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34057\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2864 - acc: 0.8915 - val_loss: 0.3873 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34057\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2860 - acc: 0.8912 - val_loss: 0.3879 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34057\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2853 - acc: 0.8915 - val_loss: 0.3896 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34057\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2846 - acc: 0.8918 - val_loss: 0.3898 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34057\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2838 - acc: 0.8920 - val_loss: 0.3907 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34057\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 4096\n",
      "Fold: 2\n",
      "best val loss: 0.34056920306027283\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  84.6982831954956\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.1557 - acc: 0.6362 - val_loss: 0.9851 - val_acc: 0.7239\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98505, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8766 - acc: 0.7706 - val_loss: 0.7839 - val_acc: 0.8006\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.98505 to 0.78389, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.7052 - acc: 0.8285 - val_loss: 0.6388 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.78389 to 0.63882, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5863 - acc: 0.8543 - val_loss: 0.5461 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63882 to 0.54613, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5107 - acc: 0.8641 - val_loss: 0.4887 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54613 to 0.48869, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4615 - acc: 0.8685 - val_loss: 0.4489 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48869 to 0.44893, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4269 - acc: 0.8709 - val_loss: 0.4205 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44893 to 0.42047, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4018 - acc: 0.8719 - val_loss: 0.3995 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42047 to 0.39948, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3834 - acc: 0.8726 - val_loss: 0.3840 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39948 to 0.38402, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3698 - acc: 0.8733 - val_loss: 0.3725 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38402 to 0.37251, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3595 - acc: 0.8738 - val_loss: 0.3641 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37251 to 0.36408, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3517 - acc: 0.8740 - val_loss: 0.3577 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36408 to 0.35768, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3457 - acc: 0.8743 - val_loss: 0.3529 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35768 to 0.35288, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3410 - acc: 0.8745 - val_loss: 0.3491 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35288 to 0.34905, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3373 - acc: 0.8744 - val_loss: 0.3460 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34905 to 0.34601, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3342 - acc: 0.8745 - val_loss: 0.3437 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34601 to 0.34373, saving model to Post_val_weights4.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3318 - acc: 0.8747 - val_loss: 0.3418 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34373 to 0.34182, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8749 - val_loss: 0.3400 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34182 to 0.33998, saving model to Post_val_weights4.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3277 - acc: 0.8752 - val_loss: 0.3389 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33998 to 0.33894, saving model to Post_val_weights4.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3261 - acc: 0.8755 - val_loss: 0.3377 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33894 to 0.33771, saving model to Post_val_weights4.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8756 - val_loss: 0.3370 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33771 to 0.33699, saving model to Post_val_weights4.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8761 - val_loss: 0.3364 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33699 to 0.33645, saving model to Post_val_weights4.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8766 - val_loss: 0.3358 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33645 to 0.33578, saving model to Post_val_weights4.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3211 - acc: 0.8768 - val_loss: 0.3353 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33578 to 0.33533, saving model to Post_val_weights4.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8771 - val_loss: 0.3353 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33533 to 0.33529, saving model to Post_val_weights4.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8773 - val_loss: 0.3347 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33529 to 0.33472, saving model to Post_val_weights4.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8774 - val_loss: 0.3349 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33472\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8775 - val_loss: 0.3346 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33472 to 0.33456, saving model to Post_val_weights4.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8776 - val_loss: 0.3347 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33456\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8779 - val_loss: 0.3348 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33456\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8782 - val_loss: 0.3350 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33456\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8785 - val_loss: 0.3355 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33456\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8788 - val_loss: 0.3355 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33456\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8788 - val_loss: 0.3360 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33456\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8794 - val_loss: 0.3363 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33456\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8798 - val_loss: 0.3368 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33456\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3104 - acc: 0.8803 - val_loss: 0.3373 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33456\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8805 - val_loss: 0.3377 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33456\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8806 - val_loss: 0.3382 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33456\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3086 - acc: 0.8810 - val_loss: 0.3386 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33456\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8809 - val_loss: 0.3393 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33456\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3075 - acc: 0.8812 - val_loss: 0.3397 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33456\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3069 - acc: 0.8814 - val_loss: 0.3406 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33456\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8817 - val_loss: 0.3411 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33456\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3059 - acc: 0.8817 - val_loss: 0.3419 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33456\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8819 - val_loss: 0.3428 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33456\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8821 - val_loss: 0.3435 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33456\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8823 - val_loss: 0.3443 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33456\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8822 - val_loss: 0.3454 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33456\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8824 - val_loss: 0.3460 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33456\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3029 - acc: 0.8828 - val_loss: 0.3471 - val_acc: 0.8677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33456\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3025 - acc: 0.8830 - val_loss: 0.3475 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33456\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8833 - val_loss: 0.3490 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33456\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8834 - val_loss: 0.3491 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33456\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8835 - val_loss: 0.3506 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33456\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3011 - acc: 0.8834 - val_loss: 0.3514 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33456\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3008 - acc: 0.8842 - val_loss: 0.3521 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33456\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3003 - acc: 0.8841 - val_loss: 0.3524 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33456\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3001 - acc: 0.8845 - val_loss: 0.3531 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33456\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.2997 - acc: 0.8847 - val_loss: 0.3535 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33456\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8845 - val_loss: 0.3542 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33456\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.2992 - acc: 0.8847 - val_loss: 0.3540 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33456\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2986 - acc: 0.8850 - val_loss: 0.3553 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33456\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2981 - acc: 0.8854 - val_loss: 0.3559 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33456\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2975 - acc: 0.8857 - val_loss: 0.3564 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33456\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2971 - acc: 0.8858 - val_loss: 0.3574 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33456\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2967 - acc: 0.8858 - val_loss: 0.3573 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33456\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2963 - acc: 0.8858 - val_loss: 0.3577 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33456\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2959 - acc: 0.8861 - val_loss: 0.3580 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33456\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2958 - acc: 0.8861 - val_loss: 0.3583 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33456\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2955 - acc: 0.8865 - val_loss: 0.3586 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33456\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2952 - acc: 0.8866 - val_loss: 0.3588 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33456\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2951 - acc: 0.8867 - val_loss: 0.3591 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33456\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2944 - acc: 0.8871 - val_loss: 0.3589 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33456\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2942 - acc: 0.8870 - val_loss: 0.3597 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33456\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2941 - acc: 0.8870 - val_loss: 0.3594 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33456\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2936 - acc: 0.8870 - val_loss: 0.3604 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33456\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2931 - acc: 0.8874 - val_loss: 0.3615 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33456\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2928 - acc: 0.8874 - val_loss: 0.3629 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33456\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2922 - acc: 0.8879 - val_loss: 0.3637 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33456\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2919 - acc: 0.8881 - val_loss: 0.3647 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33456\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2914 - acc: 0.8881 - val_loss: 0.3650 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33456\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2909 - acc: 0.8886 - val_loss: 0.3659 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33456\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2904 - acc: 0.8887 - val_loss: 0.3653 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33456\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2900 - acc: 0.8890 - val_loss: 0.3667 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33456\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2897 - acc: 0.8887 - val_loss: 0.3664 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33456\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2893 - acc: 0.8893 - val_loss: 0.3677 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33456\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2890 - acc: 0.8895 - val_loss: 0.3687 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33456\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2886 - acc: 0.8894 - val_loss: 0.3699 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33456\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2881 - acc: 0.8896 - val_loss: 0.3707 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33456\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2879 - acc: 0.8899 - val_loss: 0.3723 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33456\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2875 - acc: 0.8900 - val_loss: 0.3739 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33456\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2873 - acc: 0.8903 - val_loss: 0.3747 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33456\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2870 - acc: 0.8901 - val_loss: 0.3749 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33456\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2869 - acc: 0.8904 - val_loss: 0.3757 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33456\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2869 - acc: 0.8901 - val_loss: 0.3758 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33456\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2867 - acc: 0.8905 - val_loss: 0.3767 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33456\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2865 - acc: 0.8907 - val_loss: 0.3754 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33456\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2859 - acc: 0.8909 - val_loss: 0.3765 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33456\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2855 - acc: 0.8910 - val_loss: 0.3758 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33456\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 4096\n",
      "Fold: 3\n",
      "best val loss: 0.3345642007721795\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  81.25735020637512\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.1574 - acc: 0.6359 - val_loss: 0.9919 - val_acc: 0.7184\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99188, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8775 - acc: 0.7710 - val_loss: 0.7910 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.99188 to 0.79098, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.7055 - acc: 0.8290 - val_loss: 0.6498 - val_acc: 0.8387\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.79098 to 0.64982, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5865 - acc: 0.8550 - val_loss: 0.5574 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64982 to 0.55744, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5108 - acc: 0.8644 - val_loss: 0.4984 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55744 to 0.49837, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4614 - acc: 0.8690 - val_loss: 0.4579 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49837 to 0.45791, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4266 - acc: 0.8712 - val_loss: 0.4289 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45791 to 0.42887, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4014 - acc: 0.8724 - val_loss: 0.4077 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42887 to 0.40775, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3828 - acc: 0.8734 - val_loss: 0.3922 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40775 to 0.39219, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3691 - acc: 0.8741 - val_loss: 0.3807 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.39219 to 0.38073, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3588 - acc: 0.8743 - val_loss: 0.3721 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.38073 to 0.37213, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3510 - acc: 0.8748 - val_loss: 0.3659 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.37213 to 0.36591, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3450 - acc: 0.8747 - val_loss: 0.3608 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36591 to 0.36076, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3402 - acc: 0.8748 - val_loss: 0.3569 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.36076 to 0.35688, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3364 - acc: 0.8747 - val_loss: 0.3539 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.35688 to 0.35390, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3333 - acc: 0.8749 - val_loss: 0.3513 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.35390 to 0.35132, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3308 - acc: 0.8752 - val_loss: 0.3494 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.35132 to 0.34939, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8756 - val_loss: 0.3476 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34939 to 0.34760, saving model to Post_val_weights5.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8758 - val_loss: 0.3464 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34760 to 0.34644, saving model to Post_val_weights5.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8760 - val_loss: 0.3453 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34644 to 0.34530, saving model to Post_val_weights5.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8762 - val_loss: 0.3445 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34530 to 0.34455, saving model to Post_val_weights5.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3225 - acc: 0.8765 - val_loss: 0.3438 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.34455 to 0.34377, saving model to Post_val_weights5.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8767 - val_loss: 0.3433 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34377 to 0.34333, saving model to Post_val_weights5.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8770 - val_loss: 0.3428 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34333 to 0.34278, saving model to Post_val_weights5.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8772 - val_loss: 0.3424 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34278 to 0.34239, saving model to Post_val_weights5.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8772 - val_loss: 0.3422 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34239 to 0.34218, saving model to Post_val_weights5.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8770 - val_loss: 0.3419 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34218 to 0.34186, saving model to Post_val_weights5.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8775 - val_loss: 0.3420 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34186\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8779 - val_loss: 0.3415 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34186 to 0.34149, saving model to Post_val_weights5.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8785 - val_loss: 0.3418 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34149\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8788 - val_loss: 0.3417 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34149\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8789 - val_loss: 0.3419 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34149\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8791 - val_loss: 0.3420 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34149\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8792 - val_loss: 0.3423 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34149\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8795 - val_loss: 0.3426 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34149\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3112 - acc: 0.8796 - val_loss: 0.3430 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34149\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3106 - acc: 0.8796 - val_loss: 0.3438 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34149\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3099 - acc: 0.8797 - val_loss: 0.3438 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34149\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3094 - acc: 0.8799 - val_loss: 0.3444 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34149\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8803 - val_loss: 0.3450 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34149\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3080 - acc: 0.8805 - val_loss: 0.3460 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34149\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8806 - val_loss: 0.3465 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34149\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8808 - val_loss: 0.3475 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34149\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3061 - acc: 0.8810 - val_loss: 0.3479 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34149\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3055 - acc: 0.8813 - val_loss: 0.3491 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34149\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8817 - val_loss: 0.3498 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34149\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8816 - val_loss: 0.3511 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34149\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8820 - val_loss: 0.3518 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34149\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3032 - acc: 0.8823 - val_loss: 0.3535 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34149\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3028 - acc: 0.8825 - val_loss: 0.3546 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34149\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3022 - acc: 0.8830 - val_loss: 0.3558 - val_acc: 0.8612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34149\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3017 - acc: 0.8831 - val_loss: 0.3571 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34149\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3011 - acc: 0.8832 - val_loss: 0.3583 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34149\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3007 - acc: 0.8832 - val_loss: 0.3601 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34149\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3003 - acc: 0.8835 - val_loss: 0.3613 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34149\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8837 - val_loss: 0.3622 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34149\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8839 - val_loss: 0.3635 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34149\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.2990 - acc: 0.8836 - val_loss: 0.3644 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34149\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.2986 - acc: 0.8841 - val_loss: 0.3653 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34149\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.2982 - acc: 0.8842 - val_loss: 0.3658 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34149\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.2977 - acc: 0.8848 - val_loss: 0.3667 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34149\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8851 - val_loss: 0.3670 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34149\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2972 - acc: 0.8851 - val_loss: 0.3676 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34149\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2969 - acc: 0.8852 - val_loss: 0.3687 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34149\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2964 - acc: 0.8855 - val_loss: 0.3695 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34149\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2959 - acc: 0.8858 - val_loss: 0.3707 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34149\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2954 - acc: 0.8865 - val_loss: 0.3712 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34149\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2948 - acc: 0.8868 - val_loss: 0.3724 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34149\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2944 - acc: 0.8871 - val_loss: 0.3725 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34149\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2939 - acc: 0.8872 - val_loss: 0.3727 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34149\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2935 - acc: 0.8875 - val_loss: 0.3739 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34149\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2931 - acc: 0.8878 - val_loss: 0.3741 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34149\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8879 - val_loss: 0.3750 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34149\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8882 - val_loss: 0.3756 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34149\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2919 - acc: 0.8881 - val_loss: 0.3757 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34149\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2916 - acc: 0.8885 - val_loss: 0.3767 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34149\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2914 - acc: 0.8884 - val_loss: 0.3771 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34149\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2911 - acc: 0.8886 - val_loss: 0.3779 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34149\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2907 - acc: 0.8889 - val_loss: 0.3788 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34149\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2904 - acc: 0.8891 - val_loss: 0.3786 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34149\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2901 - acc: 0.8893 - val_loss: 0.3794 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34149\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2898 - acc: 0.8895 - val_loss: 0.3797 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34149\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2895 - acc: 0.8894 - val_loss: 0.3807 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34149\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2894 - acc: 0.8895 - val_loss: 0.3809 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34149\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2891 - acc: 0.8899 - val_loss: 0.3823 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34149\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2888 - acc: 0.8896 - val_loss: 0.3826 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34149\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2886 - acc: 0.8899 - val_loss: 0.3831 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34149\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2884 - acc: 0.8898 - val_loss: 0.3838 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34149\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2884 - acc: 0.8899 - val_loss: 0.3844 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34149\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2883 - acc: 0.8897 - val_loss: 0.3843 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34149\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2881 - acc: 0.8897 - val_loss: 0.3853 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34149\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2880 - acc: 0.8899 - val_loss: 0.3861 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34149\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2878 - acc: 0.8899 - val_loss: 0.3864 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34149\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2875 - acc: 0.8905 - val_loss: 0.3863 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34149\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2873 - acc: 0.8904 - val_loss: 0.3884 - val_acc: 0.8511\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34149\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2869 - acc: 0.8908 - val_loss: 0.3883 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34149\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2865 - acc: 0.8910 - val_loss: 0.3892 - val_acc: 0.8511\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34149\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2861 - acc: 0.8913 - val_loss: 0.3898 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34149\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2857 - acc: 0.8915 - val_loss: 0.3911 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34149\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2854 - acc: 0.8916 - val_loss: 0.3909 - val_acc: 0.8503\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34149\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 4096\n",
      "Fold: 4\n",
      "best val loss: 0.34149437257420945\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686], [16, 8192, 0, 0.3300208747317219], [16, 8192, 1, 0.330462209139651], [16, 8192, 2, 0.3360145849094056], [16, 8192, 3, 0.32807612699374816], [16, 8192, 4, 0.33612065163969296], [32, 512, 0, 0.33564156908040854], [32, 512, 1, 0.3362385708755917], [32, 512, 2, 0.34011004318270766], [32, 512, 3, 0.33541222581389357], [32, 512, 4, 0.3429361226684169], [32, 1024, 0, 0.3381186140141292], [32, 1024, 1, 0.3369432279519867], [32, 1024, 2, 0.34130778909426684], [32, 1024, 3, 0.33597521700357136], [32, 1024, 4, 0.3410962222751818], [32, 2048, 0, 0.333883015684217], [32, 2048, 1, 0.334981138929289], [32, 2048, 2, 0.3410016691963575], [32, 2048, 3, 0.3337871924408695], [32, 2048, 4, 0.3403301309214698], [32, 4096, 0, 0.333830724745466], [32, 4096, 1, 0.3340547772597151], [32, 4096, 2, 0.34056920306027283], [32, 4096, 3, 0.3345642007721795], [32, 4096, 4, 0.34149437257420945]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  81.4754364490509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f661d489710>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.2493 - acc: 0.5888 - val_loss: 1.1192 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11919, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.0432 - acc: 0.6972 - val_loss: 0.9635 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.11919 to 0.96347, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.9074 - acc: 0.7589 - val_loss: 0.8494 - val_acc: 0.7794\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.96347 to 0.84940, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.8020 - acc: 0.7976 - val_loss: 0.7578 - val_acc: 0.8122\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.84940 to 0.75781, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7144 - acc: 0.8253 - val_loss: 0.6802 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75781 to 0.68018, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6410 - acc: 0.8437 - val_loss: 0.6153 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68018 to 0.61531, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5822 - acc: 0.8550 - val_loss: 0.5641 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61531 to 0.56410, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5366 - acc: 0.8614 - val_loss: 0.5242 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56410 to 0.52421, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.5011 - acc: 0.8651 - val_loss: 0.4932 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52421 to 0.49323, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4729 - acc: 0.8674 - val_loss: 0.4683 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49323 to 0.46832, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4498 - acc: 0.8693 - val_loss: 0.4480 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.46832 to 0.44803, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4307 - acc: 0.8707 - val_loss: 0.4312 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44803 to 0.43119, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4148 - acc: 0.8717 - val_loss: 0.4171 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43119 to 0.41710, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.4015 - acc: 0.8725 - val_loss: 0.4052 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.41710 to 0.40524, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3902 - acc: 0.8732 - val_loss: 0.3952 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40524 to 0.39522, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3807 - acc: 0.8733 - val_loss: 0.3867 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39522 to 0.38673, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3726 - acc: 0.8740 - val_loss: 0.3795 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.38673 to 0.37954, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3657 - acc: 0.8742 - val_loss: 0.3734 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37954 to 0.37344, saving model to Post_val_weights1.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3599 - acc: 0.8745 - val_loss: 0.3683 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37344 to 0.36828, saving model to Post_val_weights1.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3549 - acc: 0.8746 - val_loss: 0.3639 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36828 to 0.36387, saving model to Post_val_weights1.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3506 - acc: 0.8746 - val_loss: 0.3602 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36387 to 0.36017, saving model to Post_val_weights1.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3468 - acc: 0.8747 - val_loss: 0.3570 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36017 to 0.35697, saving model to Post_val_weights1.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3437 - acc: 0.8747 - val_loss: 0.3544 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35697 to 0.35436, saving model to Post_val_weights1.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3408 - acc: 0.8750 - val_loss: 0.3520 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35436 to 0.35198, saving model to Post_val_weights1.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3383 - acc: 0.8752 - val_loss: 0.3500 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35198 to 0.35004, saving model to Post_val_weights1.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3361 - acc: 0.8752 - val_loss: 0.3483 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35004 to 0.34834, saving model to Post_val_weights1.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3342 - acc: 0.8753 - val_loss: 0.3469 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34834 to 0.34693, saving model to Post_val_weights1.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3324 - acc: 0.8756 - val_loss: 0.3457 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34693 to 0.34570, saving model to Post_val_weights1.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3309 - acc: 0.8756 - val_loss: 0.3447 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34570 to 0.34472, saving model to Post_val_weights1.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8758 - val_loss: 0.3438 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34472 to 0.34380, saving model to Post_val_weights1.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3283 - acc: 0.8759 - val_loss: 0.3430 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34380 to 0.34302, saving model to Post_val_weights1.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3270 - acc: 0.8759 - val_loss: 0.3423 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.34302 to 0.34227, saving model to Post_val_weights1.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3259 - acc: 0.8761 - val_loss: 0.3417 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.34227 to 0.34173, saving model to Post_val_weights1.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3249 - acc: 0.8764 - val_loss: 0.3413 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.34173 to 0.34126, saving model to Post_val_weights1.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3239 - acc: 0.8766 - val_loss: 0.3409 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34126 to 0.34089, saving model to Post_val_weights1.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8768 - val_loss: 0.3406 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.34089 to 0.34060, saving model to Post_val_weights1.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8768 - val_loss: 0.3403 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.34060 to 0.34034, saving model to Post_val_weights1.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8770 - val_loss: 0.3402 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.34034 to 0.34015, saving model to Post_val_weights1.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8770 - val_loss: 0.3399 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.34015 to 0.33994, saving model to Post_val_weights1.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8771 - val_loss: 0.3398 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33994 to 0.33984, saving model to Post_val_weights1.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8772 - val_loss: 0.3396 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33984 to 0.33963, saving model to Post_val_weights1.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8772 - val_loss: 0.3395 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33963 to 0.33953, saving model to Post_val_weights1.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8773 - val_loss: 0.3395 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33953 to 0.33948, saving model to Post_val_weights1.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8775 - val_loss: 0.3393 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33948 to 0.33932, saving model to Post_val_weights1.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8780 - val_loss: 0.3388 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33932 to 0.33882, saving model to Post_val_weights1.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3158 - acc: 0.8783 - val_loss: 0.3384 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33882 to 0.33845, saving model to Post_val_weights1.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8784 - val_loss: 0.3381 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33845 to 0.33807, saving model to Post_val_weights1.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8784 - val_loss: 0.3378 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33807 to 0.33776, saving model to Post_val_weights1.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8787 - val_loss: 0.3375 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33776 to 0.33751, saving model to Post_val_weights1.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8790 - val_loss: 0.3375 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33751 to 0.33746, saving model to Post_val_weights1.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8793 - val_loss: 0.3374 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33746 to 0.33742, saving model to Post_val_weights1.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3118 - acc: 0.8795 - val_loss: 0.3375 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33742\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3111 - acc: 0.8798 - val_loss: 0.3378 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33742\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3105 - acc: 0.8799 - val_loss: 0.3380 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33742\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3098 - acc: 0.8803 - val_loss: 0.3387 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33742\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3092 - acc: 0.8803 - val_loss: 0.3391 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33742\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3087 - acc: 0.8808 - val_loss: 0.3395 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33742\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3081 - acc: 0.8808 - val_loss: 0.3401 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33742\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3076 - acc: 0.8809 - val_loss: 0.3407 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33742\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8811 - val_loss: 0.3413 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33742\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3066 - acc: 0.8811 - val_loss: 0.3420 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33742\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8814 - val_loss: 0.3425 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33742\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8813 - val_loss: 0.3433 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33742\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8814 - val_loss: 0.3437 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33742\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3049 - acc: 0.8817 - val_loss: 0.3445 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33742\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8815 - val_loss: 0.3449 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33742\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8818 - val_loss: 0.3458 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33742\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3038 - acc: 0.8821 - val_loss: 0.3462 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33742\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3034 - acc: 0.8823 - val_loss: 0.3468 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33742\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3030 - acc: 0.8825 - val_loss: 0.3473 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33742\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3028 - acc: 0.8827 - val_loss: 0.3478 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33742\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3025 - acc: 0.8825 - val_loss: 0.3483 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33742\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3022 - acc: 0.8828 - val_loss: 0.3485 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33742\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3019 - acc: 0.8830 - val_loss: 0.3486 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33742\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3016 - acc: 0.8834 - val_loss: 0.3486 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33742\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8834 - val_loss: 0.3490 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33742\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3011 - acc: 0.8834 - val_loss: 0.3490 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33742\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3008 - acc: 0.8835 - val_loss: 0.3488 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33742\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3003 - acc: 0.8840 - val_loss: 0.3486 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33742\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2998 - acc: 0.8846 - val_loss: 0.3486 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33742\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2994 - acc: 0.8847 - val_loss: 0.3493 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33742\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2991 - acc: 0.8847 - val_loss: 0.3498 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33742\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2987 - acc: 0.8849 - val_loss: 0.3505 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33742\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2980 - acc: 0.8853 - val_loss: 0.3511 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33742\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2975 - acc: 0.8856 - val_loss: 0.3519 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33742\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2971 - acc: 0.8855 - val_loss: 0.3522 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33742\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2969 - acc: 0.8857 - val_loss: 0.3531 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33742\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2965 - acc: 0.8859 - val_loss: 0.3539 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33742\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2961 - acc: 0.8860 - val_loss: 0.3551 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33742\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2959 - acc: 0.8861 - val_loss: 0.3561 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33742\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2959 - acc: 0.8860 - val_loss: 0.3563 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33742\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2956 - acc: 0.8864 - val_loss: 0.3568 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33742\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2951 - acc: 0.8866 - val_loss: 0.3582 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33742\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2948 - acc: 0.8865 - val_loss: 0.3588 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33742\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2948 - acc: 0.8865 - val_loss: 0.3589 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33742\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2946 - acc: 0.8867 - val_loss: 0.3596 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33742\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2940 - acc: 0.8869 - val_loss: 0.3608 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33742\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2937 - acc: 0.8868 - val_loss: 0.3613 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33742\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8871 - val_loss: 0.3621 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33742\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8871 - val_loss: 0.3626 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33742\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 8192\n",
      "Fold: 0\n",
      "best val loss: 0.33741538244381286\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  88.08752512931824\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.2488 - acc: 0.5888 - val_loss: 1.1120 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11196, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.0425 - acc: 0.6980 - val_loss: 0.9562 - val_acc: 0.7337\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.11196 to 0.95620, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.9062 - acc: 0.7603 - val_loss: 0.8409 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.95620 to 0.84085, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.8002 - acc: 0.7993 - val_loss: 0.7474 - val_acc: 0.8135\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.84085 to 0.74744, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7117 - acc: 0.8269 - val_loss: 0.6693 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.74744 to 0.66935, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6376 - acc: 0.8450 - val_loss: 0.6066 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.66935 to 0.60663, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5792 - acc: 0.8557 - val_loss: 0.5583 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60663 to 0.55833, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5341 - acc: 0.8619 - val_loss: 0.5204 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55833 to 0.52043, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4990 - acc: 0.8652 - val_loss: 0.4902 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52043 to 0.49017, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4710 - acc: 0.8681 - val_loss: 0.4658 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49017 to 0.46579, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4480 - acc: 0.8696 - val_loss: 0.4458 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.46579 to 0.44577, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4290 - acc: 0.8706 - val_loss: 0.4291 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44577 to 0.42907, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4131 - acc: 0.8713 - val_loss: 0.4151 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.42907 to 0.41508, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3997 - acc: 0.8721 - val_loss: 0.4034 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.41508 to 0.40340, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3885 - acc: 0.8731 - val_loss: 0.3936 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40340 to 0.39362, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3790 - acc: 0.8734 - val_loss: 0.3854 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39362 to 0.38537, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3710 - acc: 0.8741 - val_loss: 0.3783 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.38537 to 0.37834, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3642 - acc: 0.8744 - val_loss: 0.3723 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37834 to 0.37234, saving model to Post_val_weights2.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3584 - acc: 0.8745 - val_loss: 0.3672 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37234 to 0.36717, saving model to Post_val_weights2.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3534 - acc: 0.8746 - val_loss: 0.3627 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36717 to 0.36269, saving model to Post_val_weights2.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3491 - acc: 0.8747 - val_loss: 0.3588 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36269 to 0.35879, saving model to Post_val_weights2.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3455 - acc: 0.8748 - val_loss: 0.3554 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35879 to 0.35537, saving model to Post_val_weights2.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3423 - acc: 0.8748 - val_loss: 0.3524 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35537 to 0.35237, saving model to Post_val_weights2.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3395 - acc: 0.8750 - val_loss: 0.3497 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35237 to 0.34973, saving model to Post_val_weights2.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3371 - acc: 0.8754 - val_loss: 0.3474 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34973 to 0.34743, saving model to Post_val_weights2.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3349 - acc: 0.8753 - val_loss: 0.3454 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34743 to 0.34542, saving model to Post_val_weights2.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3330 - acc: 0.8753 - val_loss: 0.3437 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34542 to 0.34368, saving model to Post_val_weights2.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3312 - acc: 0.8755 - val_loss: 0.3422 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34368 to 0.34220, saving model to Post_val_weights2.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3296 - acc: 0.8758 - val_loss: 0.3410 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34220 to 0.34095, saving model to Post_val_weights2.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8760 - val_loss: 0.3399 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34095 to 0.33990, saving model to Post_val_weights2.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3269 - acc: 0.8761 - val_loss: 0.3390 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33990 to 0.33901, saving model to Post_val_weights2.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3256 - acc: 0.8762 - val_loss: 0.3383 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33901 to 0.33825, saving model to Post_val_weights2.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3245 - acc: 0.8765 - val_loss: 0.3376 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33825 to 0.33760, saving model to Post_val_weights2.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8766 - val_loss: 0.3370 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33760 to 0.33703, saving model to Post_val_weights2.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8769 - val_loss: 0.3366 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33703 to 0.33657, saving model to Post_val_weights2.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8770 - val_loss: 0.3362 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33657 to 0.33618, saving model to Post_val_weights2.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8771 - val_loss: 0.3359 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33618 to 0.33588, saving model to Post_val_weights2.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8771 - val_loss: 0.3356 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33588 to 0.33564, saving model to Post_val_weights2.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8772 - val_loss: 0.3354 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33564 to 0.33544, saving model to Post_val_weights2.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8775 - val_loss: 0.3353 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33544 to 0.33530, saving model to Post_val_weights2.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8776 - val_loss: 0.3352 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33530 to 0.33515, saving model to Post_val_weights2.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8777 - val_loss: 0.3351 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33515 to 0.33506, saving model to Post_val_weights2.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8778 - val_loss: 0.3350 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33506 to 0.33503, saving model to Post_val_weights2.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8780 - val_loss: 0.3350 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33503 to 0.33500, saving model to Post_val_weights2.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8783 - val_loss: 0.3350 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33500 to 0.33500, saving model to Post_val_weights2.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3137 - acc: 0.8785 - val_loss: 0.3350 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33500 to 0.33497, saving model to Post_val_weights2.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8788 - val_loss: 0.3350 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33497 to 0.33496, saving model to Post_val_weights2.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3123 - acc: 0.8791 - val_loss: 0.3350 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33496\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3117 - acc: 0.8793 - val_loss: 0.3351 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33496\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3110 - acc: 0.8795 - val_loss: 0.3351 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33496\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8799 - val_loss: 0.3352 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33496\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8802 - val_loss: 0.3356 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33496\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3091 - acc: 0.8805 - val_loss: 0.3356 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33496\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8807 - val_loss: 0.3359 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33496\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3077 - acc: 0.8808 - val_loss: 0.3361 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33496\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3071 - acc: 0.8808 - val_loss: 0.3364 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33496\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3064 - acc: 0.8809 - val_loss: 0.3366 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33496\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8815 - val_loss: 0.3371 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33496\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8815 - val_loss: 0.3374 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33496\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3047 - acc: 0.8816 - val_loss: 0.3381 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33496\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3042 - acc: 0.8820 - val_loss: 0.3386 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33496\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3037 - acc: 0.8821 - val_loss: 0.3392 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33496\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8824 - val_loss: 0.3399 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33496\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3026 - acc: 0.8825 - val_loss: 0.3407 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33496\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8828 - val_loss: 0.3411 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33496\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3016 - acc: 0.8831 - val_loss: 0.3423 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33496\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3011 - acc: 0.8833 - val_loss: 0.3428 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33496\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3007 - acc: 0.8834 - val_loss: 0.3436 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33496\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3001 - acc: 0.8839 - val_loss: 0.3443 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33496\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2997 - acc: 0.8841 - val_loss: 0.3452 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33496\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2992 - acc: 0.8843 - val_loss: 0.3459 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33496\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2987 - acc: 0.8846 - val_loss: 0.3466 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33496\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2982 - acc: 0.8847 - val_loss: 0.3471 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33496\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2978 - acc: 0.8846 - val_loss: 0.3481 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33496\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8849 - val_loss: 0.3491 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33496\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2970 - acc: 0.8850 - val_loss: 0.3496 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33496\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2965 - acc: 0.8854 - val_loss: 0.3505 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33496\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2961 - acc: 0.8857 - val_loss: 0.3511 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33496\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2956 - acc: 0.8858 - val_loss: 0.3519 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33496\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2953 - acc: 0.8861 - val_loss: 0.3531 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33496\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8861 - val_loss: 0.3539 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33496\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2945 - acc: 0.8863 - val_loss: 0.3543 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33496\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2939 - acc: 0.8864 - val_loss: 0.3551 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33496\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2936 - acc: 0.8866 - val_loss: 0.3562 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33496\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2931 - acc: 0.8865 - val_loss: 0.3567 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33496\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8870 - val_loss: 0.3575 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33496\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8871 - val_loss: 0.3586 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33496\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2919 - acc: 0.8874 - val_loss: 0.3593 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33496\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2915 - acc: 0.8873 - val_loss: 0.3603 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33496\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2912 - acc: 0.8876 - val_loss: 0.3614 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33496\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2909 - acc: 0.8877 - val_loss: 0.3621 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33496\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2905 - acc: 0.8879 - val_loss: 0.3624 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33496\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2901 - acc: 0.8880 - val_loss: 0.3631 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33496\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2898 - acc: 0.8881 - val_loss: 0.3640 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33496\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2894 - acc: 0.8884 - val_loss: 0.3646 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33496\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2891 - acc: 0.8885 - val_loss: 0.3652 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33496\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2887 - acc: 0.8885 - val_loss: 0.3661 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33496\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2885 - acc: 0.8887 - val_loss: 0.3665 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33496\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2882 - acc: 0.8888 - val_loss: 0.3675 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33496\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2879 - acc: 0.8889 - val_loss: 0.3678 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33496\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 8192\n",
      "Fold: 1\n",
      "best val loss: 0.334961117478142\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  81.27614450454712\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.2486 - acc: 0.5877 - val_loss: 1.1154 - val_acc: 0.6561\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11539, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.0423 - acc: 0.6978 - val_loss: 0.9616 - val_acc: 0.7360\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.11539 to 0.96156, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.9060 - acc: 0.7599 - val_loss: 0.8489 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.96156 to 0.84890, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7999 - acc: 0.7990 - val_loss: 0.7572 - val_acc: 0.8049\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.84890 to 0.75723, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7113 - acc: 0.8273 - val_loss: 0.6799 - val_acc: 0.8269\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75723 to 0.67992, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6372 - acc: 0.8460 - val_loss: 0.6170 - val_acc: 0.8420\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67992 to 0.61697, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5788 - acc: 0.8565 - val_loss: 0.5675 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61697 to 0.56752, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5335 - acc: 0.8623 - val_loss: 0.5280 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56752 to 0.52800, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4983 - acc: 0.8663 - val_loss: 0.4963 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52800 to 0.49631, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4702 - acc: 0.8684 - val_loss: 0.4712 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49631 to 0.47118, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4472 - acc: 0.8702 - val_loss: 0.4509 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.47118 to 0.45087, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4282 - acc: 0.8712 - val_loss: 0.4338 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.45087 to 0.43382, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4123 - acc: 0.8723 - val_loss: 0.4195 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43382 to 0.41946, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3989 - acc: 0.8728 - val_loss: 0.4074 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.41946 to 0.40740, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3876 - acc: 0.8731 - val_loss: 0.3972 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40740 to 0.39721, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3781 - acc: 0.8737 - val_loss: 0.3886 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39721 to 0.38861, saving model to Post_val_weights3.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3700 - acc: 0.8741 - val_loss: 0.3813 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.38861 to 0.38135, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3632 - acc: 0.8746 - val_loss: 0.3752 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38135 to 0.37520, saving model to Post_val_weights3.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3573 - acc: 0.8746 - val_loss: 0.3700 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37520 to 0.37000, saving model to Post_val_weights3.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3523 - acc: 0.8748 - val_loss: 0.3656 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.37000 to 0.36559, saving model to Post_val_weights3.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3480 - acc: 0.8750 - val_loss: 0.3618 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36559 to 0.36184, saving model to Post_val_weights3.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3443 - acc: 0.8753 - val_loss: 0.3587 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36184 to 0.35866, saving model to Post_val_weights3.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3410 - acc: 0.8754 - val_loss: 0.3560 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35866 to 0.35595, saving model to Post_val_weights3.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3382 - acc: 0.8756 - val_loss: 0.3536 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35595 to 0.35363, saving model to Post_val_weights3.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3357 - acc: 0.8755 - val_loss: 0.3516 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35363 to 0.35164, saving model to Post_val_weights3.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3335 - acc: 0.8756 - val_loss: 0.3499 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35164 to 0.34993, saving model to Post_val_weights3.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3315 - acc: 0.8757 - val_loss: 0.3484 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34993 to 0.34845, saving model to Post_val_weights3.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3298 - acc: 0.8757 - val_loss: 0.3471 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34845 to 0.34715, saving model to Post_val_weights3.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3283 - acc: 0.8758 - val_loss: 0.3460 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34715 to 0.34601, saving model to Post_val_weights3.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8760 - val_loss: 0.3450 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34601 to 0.34501, saving model to Post_val_weights3.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8761 - val_loss: 0.3441 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34501 to 0.34413, saving model to Post_val_weights3.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8763 - val_loss: 0.3434 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.34413 to 0.34337, saving model to Post_val_weights3.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3233 - acc: 0.8765 - val_loss: 0.3427 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.34337 to 0.34269, saving model to Post_val_weights3.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3222 - acc: 0.8766 - val_loss: 0.3421 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.34269 to 0.34210, saving model to Post_val_weights3.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8767 - val_loss: 0.3416 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34210 to 0.34160, saving model to Post_val_weights3.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3203 - acc: 0.8768 - val_loss: 0.3412 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.34160 to 0.34119, saving model to Post_val_weights3.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8769 - val_loss: 0.3408 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.34119 to 0.34085, saving model to Post_val_weights3.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8771 - val_loss: 0.3405 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.34085 to 0.34055, saving model to Post_val_weights3.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8774 - val_loss: 0.3404 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.34055 to 0.34037, saving model to Post_val_weights3.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8777 - val_loss: 0.3402 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.34037 to 0.34015, saving model to Post_val_weights3.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8780 - val_loss: 0.3401 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.34015 to 0.34012, saving model to Post_val_weights3.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8783 - val_loss: 0.3400 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.34012 to 0.34003, saving model to Post_val_weights3.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8784 - val_loss: 0.3401 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34003\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8786 - val_loss: 0.3401 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34003\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8789 - val_loss: 0.3403 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34003\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8790 - val_loss: 0.3405 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34003\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3121 - acc: 0.8792 - val_loss: 0.3407 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34003\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3115 - acc: 0.8797 - val_loss: 0.3409 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34003\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3109 - acc: 0.8799 - val_loss: 0.3413 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34003\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3103 - acc: 0.8801 - val_loss: 0.3416 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34003\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3097 - acc: 0.8802 - val_loss: 0.3420 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34003\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8805 - val_loss: 0.3422 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34003\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3085 - acc: 0.8807 - val_loss: 0.3429 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34003\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8808 - val_loss: 0.3431 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34003\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3073 - acc: 0.8812 - val_loss: 0.3438 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34003\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3067 - acc: 0.8813 - val_loss: 0.3441 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34003\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8815 - val_loss: 0.3446 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34003\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8820 - val_loss: 0.3450 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34003\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3051 - acc: 0.8824 - val_loss: 0.3455 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34003\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3045 - acc: 0.8825 - val_loss: 0.3460 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34003\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8828 - val_loss: 0.3468 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34003\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3035 - acc: 0.8830 - val_loss: 0.3469 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34003\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3029 - acc: 0.8834 - val_loss: 0.3477 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34003\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8835 - val_loss: 0.3481 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34003\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3019 - acc: 0.8839 - val_loss: 0.3487 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34003\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8840 - val_loss: 0.3493 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34003\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3009 - acc: 0.8841 - val_loss: 0.3498 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34003\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3004 - acc: 0.8845 - val_loss: 0.3504 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34003\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8844 - val_loss: 0.3510 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34003\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8847 - val_loss: 0.3514 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34003\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2990 - acc: 0.8849 - val_loss: 0.3522 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34003\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2985 - acc: 0.8850 - val_loss: 0.3526 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34003\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2981 - acc: 0.8852 - val_loss: 0.3535 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34003\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2978 - acc: 0.8852 - val_loss: 0.3538 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34003\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2973 - acc: 0.8856 - val_loss: 0.3544 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34003\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2969 - acc: 0.8857 - val_loss: 0.3549 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34003\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2965 - acc: 0.8858 - val_loss: 0.3553 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34003\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2960 - acc: 0.8859 - val_loss: 0.3562 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34003\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2956 - acc: 0.8860 - val_loss: 0.3566 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34003\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2952 - acc: 0.8859 - val_loss: 0.3570 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34003\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8859 - val_loss: 0.3575 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34003\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2945 - acc: 0.8863 - val_loss: 0.3577 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34003\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2941 - acc: 0.8864 - val_loss: 0.3590 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34003\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2938 - acc: 0.8863 - val_loss: 0.3591 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34003\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2935 - acc: 0.8866 - val_loss: 0.3596 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34003\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2932 - acc: 0.8865 - val_loss: 0.3605 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34003\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2929 - acc: 0.8868 - val_loss: 0.3606 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34003\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2927 - acc: 0.8868 - val_loss: 0.3612 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34003\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8870 - val_loss: 0.3620 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34003\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2920 - acc: 0.8870 - val_loss: 0.3623 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34003\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2917 - acc: 0.8874 - val_loss: 0.3631 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34003\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2914 - acc: 0.8879 - val_loss: 0.3631 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34003\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2911 - acc: 0.8878 - val_loss: 0.3641 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34003\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2908 - acc: 0.8878 - val_loss: 0.3638 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34003\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2906 - acc: 0.8882 - val_loss: 0.3649 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34003\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2904 - acc: 0.8884 - val_loss: 0.3649 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34003\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2900 - acc: 0.8886 - val_loss: 0.3652 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34003\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2897 - acc: 0.8887 - val_loss: 0.3665 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34003\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2892 - acc: 0.8888 - val_loss: 0.3673 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34003\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2888 - acc: 0.8889 - val_loss: 0.3684 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34003\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 8192\n",
      "Fold: 2\n",
      "best val loss: 0.3400255871795074\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  82.41073536872864\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.2503 - acc: 0.5863 - val_loss: 1.1187 - val_acc: 0.6580\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11868, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.0435 - acc: 0.6961 - val_loss: 0.9659 - val_acc: 0.7315\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.11868 to 0.96588, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.9071 - acc: 0.7591 - val_loss: 0.8513 - val_acc: 0.7761\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.96588 to 0.85128, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.8012 - acc: 0.7990 - val_loss: 0.7554 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.85128 to 0.75540, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7129 - acc: 0.8263 - val_loss: 0.6739 - val_acc: 0.8352\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75540 to 0.67393, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6389 - acc: 0.8453 - val_loss: 0.6080 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67393 to 0.60795, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5804 - acc: 0.8561 - val_loss: 0.5578 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60795 to 0.55778, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5351 - acc: 0.8618 - val_loss: 0.5197 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55778 to 0.51970, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4999 - acc: 0.8651 - val_loss: 0.4900 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51970 to 0.49005, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4720 - acc: 0.8682 - val_loss: 0.4657 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49005 to 0.46568, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4492 - acc: 0.8694 - val_loss: 0.4455 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.46568 to 0.44553, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4302 - acc: 0.8706 - val_loss: 0.4287 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44553 to 0.42874, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4143 - acc: 0.8717 - val_loss: 0.4146 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.42874 to 0.41461, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.4010 - acc: 0.8722 - val_loss: 0.4027 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.41461 to 0.40270, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3897 - acc: 0.8728 - val_loss: 0.3927 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40270 to 0.39266, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3802 - acc: 0.8732 - val_loss: 0.3842 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39266 to 0.38416, saving model to Post_val_weights4.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3722 - acc: 0.8736 - val_loss: 0.3770 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.38416 to 0.37697, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3653 - acc: 0.8735 - val_loss: 0.3709 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37697 to 0.37088, saving model to Post_val_weights4.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3595 - acc: 0.8740 - val_loss: 0.3657 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37088 to 0.36571, saving model to Post_val_weights4.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3545 - acc: 0.8742 - val_loss: 0.3613 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36571 to 0.36132, saving model to Post_val_weights4.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3502 - acc: 0.8744 - val_loss: 0.3576 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36132 to 0.35758, saving model to Post_val_weights4.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3464 - acc: 0.8744 - val_loss: 0.3543 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.35758 to 0.35433, saving model to Post_val_weights4.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3432 - acc: 0.8747 - val_loss: 0.3515 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35433 to 0.35154, saving model to Post_val_weights4.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3404 - acc: 0.8747 - val_loss: 0.3491 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35154 to 0.34911, saving model to Post_val_weights4.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3379 - acc: 0.8749 - val_loss: 0.3470 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34911 to 0.34703, saving model to Post_val_weights4.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3357 - acc: 0.8750 - val_loss: 0.3452 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34703 to 0.34519, saving model to Post_val_weights4.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3338 - acc: 0.8752 - val_loss: 0.3437 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34519 to 0.34370, saving model to Post_val_weights4.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3321 - acc: 0.8751 - val_loss: 0.3424 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34370 to 0.34239, saving model to Post_val_weights4.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3305 - acc: 0.8751 - val_loss: 0.3412 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34239 to 0.34118, saving model to Post_val_weights4.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3291 - acc: 0.8752 - val_loss: 0.3403 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34118 to 0.34033, saving model to Post_val_weights4.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3278 - acc: 0.8752 - val_loss: 0.3394 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.34033 to 0.33942, saving model to Post_val_weights4.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3266 - acc: 0.8755 - val_loss: 0.3387 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33942 to 0.33875, saving model to Post_val_weights4.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8756 - val_loss: 0.3381 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33875 to 0.33811, saving model to Post_val_weights4.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3245 - acc: 0.8759 - val_loss: 0.3376 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33811 to 0.33763, saving model to Post_val_weights4.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3235 - acc: 0.8760 - val_loss: 0.3371 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33763 to 0.33713, saving model to Post_val_weights4.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8760 - val_loss: 0.3367 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33713 to 0.33672, saving model to Post_val_weights4.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8762 - val_loss: 0.3364 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33672 to 0.33644, saving model to Post_val_weights4.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8762 - val_loss: 0.3362 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33644 to 0.33618, saving model to Post_val_weights4.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8764 - val_loss: 0.3359 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33618 to 0.33594, saving model to Post_val_weights4.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8766 - val_loss: 0.3356 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33594 to 0.33560, saving model to Post_val_weights4.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8769 - val_loss: 0.3355 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33560 to 0.33551, saving model to Post_val_weights4.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8771 - val_loss: 0.3352 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33551 to 0.33525, saving model to Post_val_weights4.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8776 - val_loss: 0.3352 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33525 to 0.33515, saving model to Post_val_weights4.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8776 - val_loss: 0.3350 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33515 to 0.33503, saving model to Post_val_weights4.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8778 - val_loss: 0.3349 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33503 to 0.33490, saving model to Post_val_weights4.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3152 - acc: 0.8778 - val_loss: 0.3349 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33490 to 0.33489, saving model to Post_val_weights4.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8781 - val_loss: 0.3350 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33489\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8783 - val_loss: 0.3352 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33489\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8785 - val_loss: 0.3353 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33489\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8786 - val_loss: 0.3355 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33489\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3119 - acc: 0.8789 - val_loss: 0.3357 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33489\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3113 - acc: 0.8792 - val_loss: 0.3360 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33489\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3107 - acc: 0.8795 - val_loss: 0.3364 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33489\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8798 - val_loss: 0.3368 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33489\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8799 - val_loss: 0.3373 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33489\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8801 - val_loss: 0.3377 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33489\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8802 - val_loss: 0.3382 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33489\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8805 - val_loss: 0.3386 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33489\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8806 - val_loss: 0.3391 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33489\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8808 - val_loss: 0.3399 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33489\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3063 - acc: 0.8809 - val_loss: 0.3403 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33489\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3058 - acc: 0.8810 - val_loss: 0.3410 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33489\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3053 - acc: 0.8813 - val_loss: 0.3417 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33489\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3048 - acc: 0.8814 - val_loss: 0.3421 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33489\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3043 - acc: 0.8818 - val_loss: 0.3429 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33489\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3039 - acc: 0.8820 - val_loss: 0.3437 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33489\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3033 - acc: 0.8823 - val_loss: 0.3441 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33489\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3030 - acc: 0.8824 - val_loss: 0.3450 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33489\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3024 - acc: 0.8826 - val_loss: 0.3457 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33489\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3019 - acc: 0.8828 - val_loss: 0.3462 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33489\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3014 - acc: 0.8829 - val_loss: 0.3471 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33489\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3009 - acc: 0.8832 - val_loss: 0.3477 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33489\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3005 - acc: 0.8835 - val_loss: 0.3484 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33489\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3000 - acc: 0.8839 - val_loss: 0.3491 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33489\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2996 - acc: 0.8841 - val_loss: 0.3498 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33489\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2992 - acc: 0.8842 - val_loss: 0.3507 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33489\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2988 - acc: 0.8843 - val_loss: 0.3512 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33489\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2983 - acc: 0.8846 - val_loss: 0.3518 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33489\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2978 - acc: 0.8847 - val_loss: 0.3525 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33489\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8850 - val_loss: 0.3532 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33489\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2970 - acc: 0.8851 - val_loss: 0.3545 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33489\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2966 - acc: 0.8854 - val_loss: 0.3548 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33489\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2961 - acc: 0.8855 - val_loss: 0.3558 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33489\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2959 - acc: 0.8857 - val_loss: 0.3568 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33489\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2956 - acc: 0.8857 - val_loss: 0.3567 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33489\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2951 - acc: 0.8857 - val_loss: 0.3562 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33489\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2947 - acc: 0.8860 - val_loss: 0.3562 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33489\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2943 - acc: 0.8864 - val_loss: 0.3570 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33489\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2941 - acc: 0.8866 - val_loss: 0.3592 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33489\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2935 - acc: 0.8868 - val_loss: 0.3615 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33489\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2935 - acc: 0.8871 - val_loss: 0.3616 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33489\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2935 - acc: 0.8865 - val_loss: 0.3606 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33489\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8869 - val_loss: 0.3606 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33489\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2929 - acc: 0.8873 - val_loss: 0.3625 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33489\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2918 - acc: 0.8877 - val_loss: 0.3642 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33489\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2914 - acc: 0.8877 - val_loss: 0.3632 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33489\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2911 - acc: 0.8879 - val_loss: 0.3635 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33489\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2909 - acc: 0.8887 - val_loss: 0.3648 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33489\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2905 - acc: 0.8891 - val_loss: 0.3671 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33489\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2899 - acc: 0.8890 - val_loss: 0.3676 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33489\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 8192\n",
      "Fold: 3\n",
      "best val loss: 0.33489134584253993\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  84.52903461456299\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.2505 - acc: 0.5865 - val_loss: 1.1273 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.12731, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.0439 - acc: 0.6960 - val_loss: 0.9716 - val_acc: 0.7280\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.12731 to 0.97158, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.9072 - acc: 0.7595 - val_loss: 0.8565 - val_acc: 0.7749\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.97158 to 0.85649, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.8009 - acc: 0.7991 - val_loss: 0.7621 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.85649 to 0.76208, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7121 - acc: 0.8273 - val_loss: 0.6826 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.76208 to 0.68259, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6382 - acc: 0.8464 - val_loss: 0.6190 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68259 to 0.61895, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5800 - acc: 0.8565 - val_loss: 0.5691 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61895 to 0.56912, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5349 - acc: 0.8622 - val_loss: 0.5301 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56912 to 0.53007, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4996 - acc: 0.8654 - val_loss: 0.4996 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53007 to 0.49959, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4715 - acc: 0.8683 - val_loss: 0.4749 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49959 to 0.47495, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4484 - acc: 0.8700 - val_loss: 0.4544 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.47495 to 0.45437, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4293 - acc: 0.8715 - val_loss: 0.4373 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.45437 to 0.43729, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4132 - acc: 0.8721 - val_loss: 0.4231 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43729 to 0.42307, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3997 - acc: 0.8729 - val_loss: 0.4111 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.42307 to 0.41113, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3883 - acc: 0.8734 - val_loss: 0.4011 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.41113 to 0.40106, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3787 - acc: 0.8739 - val_loss: 0.3925 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.40106 to 0.39251, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3706 - acc: 0.8740 - val_loss: 0.3853 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.39251 to 0.38528, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3637 - acc: 0.8743 - val_loss: 0.3792 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38528 to 0.37919, saving model to Post_val_weights5.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3578 - acc: 0.8747 - val_loss: 0.3741 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37919 to 0.37407, saving model to Post_val_weights5.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3528 - acc: 0.8750 - val_loss: 0.3698 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.37407 to 0.36980, saving model to Post_val_weights5.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3484 - acc: 0.8752 - val_loss: 0.3662 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36980 to 0.36622, saving model to Post_val_weights5.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3446 - acc: 0.8753 - val_loss: 0.3632 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36622 to 0.36321, saving model to Post_val_weights5.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3413 - acc: 0.8755 - val_loss: 0.3607 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.36321 to 0.36066, saving model to Post_val_weights5.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3385 - acc: 0.8758 - val_loss: 0.3585 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.36066 to 0.35852, saving model to Post_val_weights5.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3359 - acc: 0.8758 - val_loss: 0.3567 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35852 to 0.35666, saving model to Post_val_weights5.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3337 - acc: 0.8760 - val_loss: 0.3551 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35666 to 0.35513, saving model to Post_val_weights5.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3317 - acc: 0.8761 - val_loss: 0.3537 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.35513 to 0.35373, saving model to Post_val_weights5.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3299 - acc: 0.8763 - val_loss: 0.3526 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.35373 to 0.35255, saving model to Post_val_weights5.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3282 - acc: 0.8765 - val_loss: 0.3514 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.35255 to 0.35136, saving model to Post_val_weights5.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3268 - acc: 0.8765 - val_loss: 0.3504 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.35136 to 0.35042, saving model to Post_val_weights5.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3254 - acc: 0.8764 - val_loss: 0.3493 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.35042 to 0.34931, saving model to Post_val_weights5.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3242 - acc: 0.8765 - val_loss: 0.3486 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.34931 to 0.34862, saving model to Post_val_weights5.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3230 - acc: 0.8766 - val_loss: 0.3476 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.34862 to 0.34760, saving model to Post_val_weights5.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8768 - val_loss: 0.3466 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.34760 to 0.34661, saving model to Post_val_weights5.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8770 - val_loss: 0.3459 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34661 to 0.34588, saving model to Post_val_weights5.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3198 - acc: 0.8772 - val_loss: 0.3450 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.34588 to 0.34501, saving model to Post_val_weights5.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8773 - val_loss: 0.3445 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.34501 to 0.34447, saving model to Post_val_weights5.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8776 - val_loss: 0.3441 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.34447 to 0.34408, saving model to Post_val_weights5.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8778 - val_loss: 0.3441 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34408\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8782 - val_loss: 0.3435 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.34408 to 0.34349, saving model to Post_val_weights5.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8782 - val_loss: 0.3432 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.34349 to 0.34321, saving model to Post_val_weights5.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8782 - val_loss: 0.3432 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.34321 to 0.34315, saving model to Post_val_weights5.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8785 - val_loss: 0.3429 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.34315 to 0.34285, saving model to Post_val_weights5.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8789 - val_loss: 0.3430 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34285\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8793 - val_loss: 0.3430 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34285\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3121 - acc: 0.8795 - val_loss: 0.3429 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34285\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3115 - acc: 0.8796 - val_loss: 0.3427 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.34285 to 0.34274, saving model to Post_val_weights5.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3108 - acc: 0.8799 - val_loss: 0.3427 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.34274 to 0.34268, saving model to Post_val_weights5.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3102 - acc: 0.8799 - val_loss: 0.3429 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34268\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3096 - acc: 0.8801 - val_loss: 0.3433 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34268\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3090 - acc: 0.8803 - val_loss: 0.3435 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34268\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3084 - acc: 0.8805 - val_loss: 0.3439 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34268\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3079 - acc: 0.8808 - val_loss: 0.3443 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34268\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3074 - acc: 0.8810 - val_loss: 0.3446 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34268\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3068 - acc: 0.8811 - val_loss: 0.3450 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34268\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3062 - acc: 0.8813 - val_loss: 0.3450 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34268\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3057 - acc: 0.8816 - val_loss: 0.3454 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34268\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3052 - acc: 0.8816 - val_loss: 0.3460 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34268\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3046 - acc: 0.8818 - val_loss: 0.3460 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34268\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3041 - acc: 0.8822 - val_loss: 0.3469 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34268\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3036 - acc: 0.8824 - val_loss: 0.3471 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34268\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3031 - acc: 0.8826 - val_loss: 0.3479 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34268\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3025 - acc: 0.8829 - val_loss: 0.3483 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34268\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3021 - acc: 0.8831 - val_loss: 0.3492 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34268\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3016 - acc: 0.8829 - val_loss: 0.3494 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34268\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3012 - acc: 0.8832 - val_loss: 0.3505 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34268\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3007 - acc: 0.8833 - val_loss: 0.3507 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34268\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3003 - acc: 0.8835 - val_loss: 0.3515 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34268\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2999 - acc: 0.8838 - val_loss: 0.3516 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34268\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2995 - acc: 0.8840 - val_loss: 0.3526 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34268\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2990 - acc: 0.8843 - val_loss: 0.3532 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34268\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2986 - acc: 0.8846 - val_loss: 0.3540 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34268\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2982 - acc: 0.8847 - val_loss: 0.3546 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34268\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2978 - acc: 0.8847 - val_loss: 0.3556 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34268\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2974 - acc: 0.8848 - val_loss: 0.3559 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34268\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2969 - acc: 0.8849 - val_loss: 0.3571 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34268\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2965 - acc: 0.8852 - val_loss: 0.3572 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34268\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2961 - acc: 0.8853 - val_loss: 0.3578 - val_acc: 0.8615\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34268\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2957 - acc: 0.8857 - val_loss: 0.3589 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34268\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2953 - acc: 0.8858 - val_loss: 0.3595 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34268\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2949 - acc: 0.8860 - val_loss: 0.3605 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34268\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2945 - acc: 0.8859 - val_loss: 0.3614 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34268\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2943 - acc: 0.8861 - val_loss: 0.3622 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34268\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2940 - acc: 0.8860 - val_loss: 0.3630 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34268\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2937 - acc: 0.8864 - val_loss: 0.3638 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34268\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2934 - acc: 0.8864 - val_loss: 0.3641 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34268\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2931 - acc: 0.8869 - val_loss: 0.3648 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34268\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2928 - acc: 0.8870 - val_loss: 0.3650 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34268\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2925 - acc: 0.8870 - val_loss: 0.3658 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34268\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2923 - acc: 0.8872 - val_loss: 0.3663 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34268\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2921 - acc: 0.8871 - val_loss: 0.3664 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34268\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2920 - acc: 0.8872 - val_loss: 0.3671 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34268\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2917 - acc: 0.8873 - val_loss: 0.3671 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34268\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2914 - acc: 0.8873 - val_loss: 0.3663 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34268\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2910 - acc: 0.8873 - val_loss: 0.3670 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34268\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2907 - acc: 0.8876 - val_loss: 0.3666 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34268\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2903 - acc: 0.8878 - val_loss: 0.3671 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34268\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2899 - acc: 0.8879 - val_loss: 0.3674 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34268\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2896 - acc: 0.8882 - val_loss: 0.3689 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34268\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2893 - acc: 0.8880 - val_loss: 0.3684 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34268\n",
      "#################################\n",
      "Number of units: 32\n",
      "Batch size: 8192\n",
      "Fold: 4\n",
      "best val loss: 0.3426787891861988\n",
      "#################################\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686], [16, 8192, 0, 0.3300208747317219], [16, 8192, 1, 0.330462209139651], [16, 8192, 2, 0.3360145849094056], [16, 8192, 3, 0.32807612699374816], [16, 8192, 4, 0.33612065163969296], [32, 512, 0, 0.33564156908040854], [32, 512, 1, 0.3362385708755917], [32, 512, 2, 0.34011004318270766], [32, 512, 3, 0.33541222581389357], [32, 512, 4, 0.3429361226684169], [32, 1024, 0, 0.3381186140141292], [32, 1024, 1, 0.3369432279519867], [32, 1024, 2, 0.34130778909426684], [32, 1024, 3, 0.33597521700357136], [32, 1024, 4, 0.3410962222751818], [32, 2048, 0, 0.333883015684217], [32, 2048, 1, 0.334981138929289], [32, 2048, 2, 0.3410016691963575], [32, 2048, 3, 0.3337871924408695], [32, 2048, 4, 0.3403301309214698], [32, 4096, 0, 0.333830724745466], [32, 4096, 1, 0.3340547772597151], [32, 4096, 2, 0.34056920306027283], [32, 4096, 3, 0.3345642007721795], [32, 4096, 4, 0.34149437257420945], [32, 8192, 0, 0.33741538244381286], [32, 8192, 1, 0.334961117478142], [32, 8192, 2, 0.3400255871795074], [32, 8192, 3, 0.33489134584253993], [32, 8192, 4, 0.3426787891861988]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  85.28174257278442\n",
      "Entire process took:  4800.561390399933\n",
      "Experiment record:\n",
      "[[16, 512, 0, 0.33344130067797434], [16, 512, 1, 0.33365830542748437], [16, 512, 2, 0.3391906669892763], [16, 512, 3, 0.3334132865367577], [16, 512, 4, 0.3394083375122115], [16, 1024, 0, 0.3331538017172562], [16, 1024, 1, 0.33298310250566715], [16, 1024, 2, 0.3394669556757163], [16, 1024, 3, 0.33222298836847497], [16, 1024, 4, 0.33804537513102706], [16, 2048, 0, 0.32901830730382464], [16, 2048, 1, 0.3312898122915748], [16, 2048, 2, 0.3379315251565119], [16, 2048, 3, 0.3303973318749701], [16, 2048, 4, 0.33539121395663213], [16, 4096, 0, 0.32826085590479664], [16, 4096, 1, 0.3301164361538246], [16, 4096, 2, 0.3362120342394065], [16, 4096, 3, 0.32965048246913486], [16, 4096, 4, 0.3344200807844686], [16, 8192, 0, 0.3300208747317219], [16, 8192, 1, 0.330462209139651], [16, 8192, 2, 0.3360145849094056], [16, 8192, 3, 0.32807612699374816], [16, 8192, 4, 0.33612065163969296], [32, 512, 0, 0.33564156908040854], [32, 512, 1, 0.3362385708755917], [32, 512, 2, 0.34011004318270766], [32, 512, 3, 0.33541222581389357], [32, 512, 4, 0.3429361226684169], [32, 1024, 0, 0.3381186140141292], [32, 1024, 1, 0.3369432279519867], [32, 1024, 2, 0.34130778909426684], [32, 1024, 3, 0.33597521700357136], [32, 1024, 4, 0.3410962222751818], [32, 2048, 0, 0.333883015684217], [32, 2048, 1, 0.334981138929289], [32, 2048, 2, 0.3410016691963575], [32, 2048, 3, 0.3337871924408695], [32, 2048, 4, 0.3403301309214698], [32, 4096, 0, 0.333830724745466], [32, 4096, 1, 0.3340547772597151], [32, 4096, 2, 0.34056920306027283], [32, 4096, 3, 0.3345642007721795], [32, 4096, 4, 0.34149437257420945], [32, 8192, 0, 0.33741538244381286], [32, 8192, 1, 0.334961117478142], [32, 8192, 2, 0.3400255871795074], [32, 8192, 3, 0.33489134584253993], [32, 8192, 4, 0.3426787891861988]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "num_per_fold = x_train.shape[0]//10\n",
    "print(num_per_fold)\n",
    "\n",
    "units_list = [16,32] #[2,4,8,16,32]\n",
    "batch_size_list = [512, 1024, 2048, 4096, 8192]# [256, 512, 1024, 2048, 4096]# 64,128,256, 512, 1024]#, 2048, 4096]#, 8192]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "exp_record = []\n",
    "\n",
    "for units in units_list:\n",
    "    for batch_s in batch_size_list:\n",
    "        for f in range(5):#10\n",
    "            #start = f*num_per_fold\n",
    "            end = (f+1)*num_per_fold\n",
    "            train1_x = x_train[:end, ]\n",
    "            train2_x = x_train[end:, ]\n",
    "            train_x_lstm = np.append(train2_x, train1_x, axis=0) \n",
    "            train1_y = y_train[:end, ]\n",
    "            train2_y = y_train[end:, ]\n",
    "            train_y_lstm = np.append(train2_y, train1_y, axis=0)\n",
    "            ###############################\n",
    "            seed(1)\n",
    "            set_random_seed(1)\n",
    "            ###############################\n",
    "            start_time_inner = time.time()\n",
    "            #config = tf.ConfigProto(log_device_placement = True)\n",
    "            #config.gpu_options.visible_device_list='1'\n",
    "            with tf.Session(config = tf.ConfigProto(log_device_placement = True)):\n",
    "                model = Sequential()\n",
    "                model.add(SimpleRNN(units, #CuDNNLSTM\n",
    "                                    kernel_regularizer=regularizers.l2(0.01),\n",
    "                                    #return_sequences=True, \n",
    "                                    input_shape=(8, 182))) #20 , 27\n",
    "                #model.add(SimpleRNN(units, \n",
    "                #                    kernel_regularizer=regularizers.l2(0.01)))\n",
    "                model.add(Dense(2, activation='softmax'))\n",
    "                model.compile(loss='categorical_crossentropy', \n",
    "                              optimizer='adam', metrics=['accuracy'])\n",
    "                val_weight = \"Post_val_weights\" + str(f+1) + \".hdf5\"\n",
    "                val_checkpointer = ModelCheckpoint(filepath=val_weight,\n",
    "                                            monitor='val_loss', verbose=1,\n",
    "                                            save_best_only=True)\n",
    "                history = model.fit(train_x_lstm, train_y_lstm, batch_size=batch_s, \n",
    "                                    epochs=100, validation_split=0.1, \n",
    "                                    callbacks=[val_checkpointer], \n",
    "                                    verbose=2, \n",
    "                                    shuffle=False) \n",
    "                print(\"#################################\")\n",
    "                print(\"Number of units:\", units)\n",
    "                print(\"Batch size:\", batch_s)\n",
    "                print(\"Fold:\", f)\n",
    "                print(\"best val loss:\", min(history.history['val_loss']))\n",
    "                exp_record.append([units, batch_s, f, min(history.history['val_loss'])])\n",
    "                print(\"#################################\")\n",
    "                if(f==4):\n",
    "                    print(exp_record)\n",
    "                pyplot.plot(history.history['loss'], label='train')\n",
    "                pyplot.plot(history.history['val_loss'], label='validation')\n",
    "                pyplot.legend()\n",
    "                pyplot.show()\n",
    "            end_time = time.time()\n",
    "            print(\"Time to train LSTM: \", time.time() - start_time_inner)\n",
    "print(\"Entire process took: \", time.time() - start_time)\n",
    "\n",
    "print(\"Experiment record:\")\n",
    "print(exp_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 4)\n",
      "###############################\n",
      "Units: 1.0\n",
      "Batch size: 256.0\n",
      "Val loss (mean): 0.33462\n",
      "Val loss (std): 0.00304\n",
      "###############################\n",
      "###############################\n",
      "Units: 1.0\n",
      "Batch size: 512.0\n",
      "Val loss (mean): 0.33301\n",
      "Val loss (std): 0.00284\n",
      "###############################\n",
      "###############################\n",
      "Units: 1.0\n",
      "Batch size: 1024.0\n",
      "Val loss (mean): 0.33163\n",
      "Val loss (std): 0.00346\n",
      "###############################\n",
      "###############################\n",
      "Units: 1.0\n",
      "Batch size: 2048.0\n",
      "Val loss (mean): 0.33238\n",
      "Val loss (std): 0.00402\n",
      "###############################\n",
      "###############################\n",
      "Units: 1.0\n",
      "Batch size: 4096.0\n",
      "Val loss (mean): 0.3348\n",
      "Val loss (std): 0.00329\n",
      "###############################\n",
      "###############################\n",
      "Units: 2.0\n",
      "Batch size: 256.0\n",
      "Val loss (mean): 0.32794\n",
      "Val loss (std): 0.00221\n",
      "###############################\n",
      "###############################\n",
      "Units: 2.0\n",
      "Batch size: 512.0\n",
      "Val loss (mean): 0.32646\n",
      "Val loss (std): 0.00243\n",
      "###############################\n",
      "###############################\n",
      "Units: 2.0\n",
      "Batch size: 1024.0\n",
      "Val loss (mean): 0.32569\n",
      "Val loss (std): 0.00277\n",
      "###############################\n",
      "###############################\n",
      "Units: 2.0\n",
      "Batch size: 2048.0\n",
      "Val loss (mean): 0.32534\n",
      "Val loss (std): 0.00325\n",
      "###############################\n",
      "###############################\n",
      "Units: 2.0\n",
      "Batch size: 4096.0\n",
      "Val loss (mean): 0.32755\n",
      "Val loss (std): 0.00392\n",
      "###############################\n",
      "###############################\n",
      "Units: 4.0\n",
      "Batch size: 256.0\n",
      "Val loss (mean): 0.32882\n",
      "Val loss (std): 0.00321\n",
      "###############################\n",
      "###############################\n",
      "Units: 4.0\n",
      "Batch size: 512.0\n",
      "Val loss (mean): 0.32749\n",
      "Val loss (std): 0.00342\n",
      "###############################\n",
      "###############################\n",
      "Units: 4.0\n",
      "Batch size: 1024.0\n",
      "Val loss (mean): 0.32659\n",
      "Val loss (std): 0.00263\n",
      "###############################\n",
      "###############################\n",
      "Units: 4.0\n",
      "Batch size: 2048.0\n",
      "Val loss (mean): 0.32595\n",
      "Val loss (std): 0.00351\n",
      "###############################\n",
      "###############################\n",
      "Units: 4.0\n",
      "Batch size: 4096.0\n",
      "Val loss (mean): 0.32738\n",
      "Val loss (std): 0.00311\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 256.0\n",
      "Val loss (mean): 0.33257\n",
      "Val loss (std): 0.00272\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 512.0\n",
      "Val loss (mean): 0.33223\n",
      "Val loss (std): 0.0038\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 1024.0\n",
      "Val loss (mean): 0.33105\n",
      "Val loss (std): 0.00279\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 2048.0\n",
      "Val loss (mean): 0.33084\n",
      "Val loss (std): 0.00277\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "Val loss (mean): 0.33008\n",
      "Val loss (std): 0.00288\n",
      "###############################\n",
      "###############################\n",
      "Units: 16.0\n",
      "Batch size: 256.0\n",
      "Val loss (mean): 0.33563\n",
      "Val loss (std): 0.00345\n",
      "###############################\n",
      "###############################\n",
      "Units: 16.0\n",
      "Batch size: 512.0\n",
      "Val loss (mean): 0.3347\n",
      "Val loss (std): 0.00339\n",
      "###############################\n",
      "###############################\n",
      "Units: 16.0\n",
      "Batch size: 1024.0\n",
      "Val loss (mean): 0.33421\n",
      "Val loss (std): 0.00259\n",
      "###############################\n",
      "###############################\n",
      "Units: 16.0\n",
      "Batch size: 2048.0\n",
      "Val loss (mean): 0.33345\n",
      "Val loss (std): 0.00341\n",
      "###############################\n",
      "###############################\n",
      "Units: 16.0\n",
      "Batch size: 4096.0\n",
      "Val loss (mean): 0.33437\n",
      "Val loss (std): 0.0038\n",
      "###############################\n",
      "0.3253433551021486\n"
     ]
    }
   ],
   "source": [
    "exp_record = [[1, 256, 0, 0.33373971937692654], [1, 256, 1, 0.33087750627980594], [1, 256, 2, 0.337586320394661], [1, 256, 3, 0.3321857688092349], [1, 256, 4, 0.33870807545226916], [1, 512, 0, 0.3310056498176173], [1, 512, 1, 0.3301281402334135], [1, 512, 2, 0.3366727458942703], [1, 512, 3, 0.3309771340074595], [1, 512, 4, 0.33624743742552415], [1, 1024, 0, 0.32872952579057707], [1, 1024, 1, 0.3285976597997877], [1, 1024, 2, 0.3362235160250413], [1, 1024, 3, 0.32911919812012835], [1, 1024, 4, 0.33549180959400376], [1, 2048, 0, 0.3289467690283792], [1, 2048, 1, 0.32835071831418755], [1, 2048, 2, 0.33851355123241045], [1, 2048, 3, 0.3303666505060698], [1, 2048, 4, 0.33569956366778814], [1, 4096, 0, 0.33192524474266677], [1, 4096, 1, 0.331446019111321], [1, 4096, 2, 0.33751572658444007], [1, 4096, 3, 0.33332109055323905], [1, 4096, 4, 0.33981251248839306], [2, 256, 0, 0.3263539231450934], [2, 256, 1, 0.32645767021597477], [2, 256, 2, 0.3291474593870821], [2, 256, 3, 0.32597644410635296], [2, 256, 4, 0.33174539766813577], [2, 512, 0, 0.32366034840979774], [2, 512, 1, 0.32601600946041576], [2, 512, 2, 0.3288598933345393], [2, 512, 3, 0.324121917123683], [2, 512, 4, 0.3296589992408864], [2, 1024, 0, 0.323465822077634], [2, 1024, 1, 0.32659017510581434], [2, 1024, 2, 0.3283320514779342], [2, 1024, 3, 0.3215137346446166], [2, 1024, 4, 0.32854372555749456], [2, 2048, 0, 0.32162549684619346], [2, 2048, 1, 0.3246906866804201], [2, 2048, 2, 0.32804700887691207], [2, 2048, 3, 0.32231379122761955], [2, 2048, 4, 0.33003979187959814], [2, 4096, 0, 0.32152968565622964], [2, 4096, 1, 0.3274307930887791], [2, 4096, 2, 0.3308543865583096], [2, 4096, 3, 0.3254021459573891], [2, 4096, 4, 0.33255067070325217], [4, 256, 0, 0.325794471523218], [4, 256, 1, 0.32559512870353563], [4, 256, 2, 0.33152923292235326], [4, 256, 3, 0.3275414863246226], [4, 256, 4, 0.33363133020568314], [4, 512, 0, 0.3258081548674065], [4, 512, 1, 0.3252046762154116], [4, 512, 2, 0.33122848609037564], [4, 512, 3, 0.3233371983912953], [4, 512, 4, 0.33186769327225046], [4, 1024, 0, 0.3235955278009002], [4, 1024, 1, 0.32753638616082265], [4, 1024, 2, 0.32990747700657763], [4, 1024, 3, 0.3234332045128471], [4, 1024, 4, 0.32849316480564095], [4, 2048, 0, 0.32275870544171475], [4, 2048, 1, 0.3245726459835008], [4, 2048, 2, 0.32840848748446905], [4, 2048, 3, 0.3224618855903023], [4, 2048, 4, 0.3315419124441537], [4, 4096, 0, 0.32238277055366693], [4, 4096, 1, 0.3294706178129765], [4, 4096, 2, 0.3291927848712743], [4, 4096, 3, 0.32517570245335675], [4, 4096, 4, 0.33069406777097465], [8, 256, 0, 0.33077406986415037], [8, 256, 1, 0.33092566218989633], [8, 256, 2, 0.333596356751626], [8, 256, 3, 0.3300971656166322], [8, 256, 4, 0.33745486787885254], [8, 512, 0, 0.3288329930472792], [8, 512, 1, 0.3300926153422796], [8, 512, 2, 0.33561725276255466], [8, 512, 3, 0.3287116362825472], [8, 512, 4, 0.3379042322802962], [8, 1024, 0, 0.3288948223186515], [8, 1024, 1, 0.3317811742163541], [8, 1024, 2, 0.3331390493445926], [8, 1024, 3, 0.3269019777872409], [8, 1024, 4, 0.3345437005109954], [8, 2048, 0, 0.32707936470271554], [8, 2048, 1, 0.32950529179377863], [8, 2048, 2, 0.3347000645336352], [8, 2048, 3, 0.3296172488851157], [8, 2048, 4, 0.333321427329939], [8, 4096, 0, 0.32702213060089025], [8, 4096, 1, 0.32769308581686857], [8, 4096, 2, 0.3334182149206686], [8, 4096, 3, 0.32857582691120124], [8, 4096, 4, 0.3337007244776564], [16, 256, 0, 0.3346934361694849], [16, 256, 1, 0.3332425984443977], [16, 256, 2, 0.33746642178610753], [16, 256, 3, 0.33143664015663993], [16, 256, 4, 0.3412931953605853], [16, 512, 0, 0.3301699568583951], [16, 512, 1, 0.3324853811277981], [16, 512, 2, 0.33617296469839], [16, 512, 3, 0.3345299708006675], [16, 512, 4, 0.3401655615212624], [16, 1024, 0, 0.3309552421765021], [16, 1024, 1, 0.3343099619979747], [16, 1024, 2, 0.33531423548508804], [16, 1024, 3, 0.3321164547978786], [16, 1024, 4, 0.3383660544986613], [16, 2048, 0, 0.32783758251290573], [16, 2048, 1, 0.3349672385753944], [16, 2048, 2, 0.33693749952734564], [16, 2048, 3, 0.33130132684930724], [16, 2048, 4, 0.3361893757602625], [16, 4096, 0, 0.32849209746422126], [16, 4096, 1, 0.3316592068212074], [16, 4096, 2, 0.33827894258917424], [16, 4096, 3, 0.3353203216421674], [16, 4096, 4, 0.33810724308616236]]\n",
    "\n",
    "complete_v = np.array(exp_record)\n",
    "print(complete_v.shape)\n",
    "\n",
    "val_loss_list = []\n",
    "for i in range(25):\n",
    "    h_params = complete_v[(i*5):((i+1)*5), :]\n",
    "    print(\"###############################\")\n",
    "    print(\"Units:\", h_params[0, 0])\n",
    "    print(\"Batch size:\", h_params[0, 1])\n",
    "    #print(\"Val loss (mean):\", np.mean(h_params[:, 3]))\n",
    "    #print(\"Val loss (std):\", np.std(h_params[:, 3]))\n",
    "    print(\"Val loss (mean):\", \n",
    "          np.round(np.mean(h_params[:, 3]), decimals=5))\n",
    "    print(\"Val loss (std):\", \n",
    "          np.round(np.std(h_params[:, 3]), decimals=5))\n",
    "    print(\"###############################\")\n",
    "    val_loss_list.append(np.mean(h_params[:, 3]))\n",
    "print(min(val_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_126 (CuDNNLSTM)   (None, 1)                 740       \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 744\n",
      "Trainable params: 744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = 1\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(units, \n",
    "                    kernel_regularizer=regularizers.l2(0.01),\n",
    "                    #return_sequences=True, \n",
    "                    input_shape=(4, 182))) #20 , 27\n",
    "#model.add(CuDNNLSTM(units, \n",
    "#                    kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min L2 layer 1:\t 0.00500063495754628\n",
      "Max L2 layer 1:\t 0.01456012400954233\n",
      "Min L2 layer 2:\t 1.1490073473552646e-08\n",
      "Max L2 layer 2:\t 4.6407510846938845e-05\n",
      "Layer 1 L2:\t [0.013637599855700826, 0.007849059652276268, 0.00573256388083736, 0.012632372043302849, 0.009527190575994113, 0.010422968740087744, 0.012266357828275072, 0.013489051076148218, 0.012681999778089821, 0.012331437233200173, 0.007419864247038851, 0.012203086925547387, 0.005583773058117212, 0.009096689261577843, 0.0111067227385766, 0.0075591487456188825, 0.007856719275463319, 0.011844637468101177, 0.013409197353885589, 0.013091534201008212, 0.00500063495754628, 0.014236100947219523, 0.01306965163145652, 0.01456012400954233, 0.009847289899093989]\n",
      "Layer 2 L2:\t [2.2371957504223983e-07, 1.1608426866140592e-07, 1.366317063276529e-06, 6.000773098573809e-08, 1.770312290714157e-06, 3.0467787559539307e-05, 2.7002110552468955e-07, 1.2173772675801509e-06, 2.3308638794421389e-07, 4.6407510846938845e-05, 2.2136423090180878e-07, 1.0870253187523527e-06, 9.522299432206237e-08, 1.9431574758469257e-06, 4.794657534795281e-06, 1.2280044148248403e-06, 2.0982271779310356e-08, 5.886406432645012e-06, 1.1490073473552646e-08, 3.507802928127537e-05, 1.3120163872711362e-08, 3.2103571649190456e-08, 1.6253685350102705e-08, 1.131673850698275e-05, 3.7141200590076085e-08]\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# generate random numbers\n",
    "# for layer 1 and 2 \n",
    "# L2 search\n",
    "###########################\n",
    "from numpy.random import seed\n",
    "seed(29) # seed 13 for LSTM seed 16 for SimpleRNN (16 to 4)\n",
    "         # seed 18 for LSTM seed for 19 SimpleRNN (4 to 4)\n",
    "         # seed 4 for LSTM  7 for SimpleRNN (16 to 4) 1 layer\n",
    "         # seed 8 for LSTM  9 for SimpleRNN  (4 to 4) 1 layer\n",
    "         # seed 22 for LSTM  23 for SimpleRNN (12 to 4) 1layer   \n",
    "         # seed 28 for LSTM 29 for SimpleRNN (8 to 4) 1layer\n",
    "# L2 for layer 1 between 0.005 and 0.015\n",
    "L2_1_list = []\n",
    "for i in range(25):\n",
    "    L2_1_list.append(np.random.uniform(0.005, 0.015))\n",
    "# L2 for layer 2 between 1e-4 and 1e-8\n",
    "L2_2_list = []\n",
    "for i in range(25):\n",
    "    r = -4*np.random.rand()\n",
    "    s = 0.0001*(10**r)\n",
    "    L2_2_list.append(s)\n",
    "print(\"Min L2 layer 1:\\t\", min(L2_1_list))\n",
    "print(\"Max L2 layer 1:\\t\", max(L2_1_list))\n",
    "print(\"Min L2 layer 2:\\t\", min(L2_2_list))\n",
    "print(\"Max L2 layer 2:\\t\", max(L2_2_list))\n",
    "print(\"Layer 1 L2:\\t\", L2_1_list)\n",
    "print(\"Layer 2 L2:\\t\", L2_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min L2 layer 1:\t 0.003413438310678853\n",
      "Max L2 layer 1:\t 0.0048372218158758435\n",
      "Min L2 layer 2:\t 2.9388964687128024e-08\n",
      "Max L2 layer 2:\t 4.2126709964605095e-07\n",
      "Layer 1 L2:\t [0.003443986342179479, 0.004741464612354753, 0.003413438310678853, 0.0048372218158758435, 0.003976822377589659]\n",
      "Layer 2 L2:\t [5.977399380019084e-08, 2.9388964687128024e-08, 9.186794976618292e-08, 2.5491711623149535e-07, 4.2126709964605095e-07]\n"
     ]
    }
   ],
   "source": [
    "### from numpy.random import seed\n",
    "seed(5) # seed 13 for LSTM seed 16 for SimpleRNN (16 to 4)\n",
    "         # seed 18 for LSTM seed for 19 SimpleRNN (4 to 4)\n",
    "         # seed 1 for SimpleRNN extend 1 layer\n",
    "         # seed 5 for LSTM extend 1 layer\n",
    "# L2 for layer 1 between 0.005 and 0.015\n",
    "L2_1_list = []\n",
    "for i in range(5):\n",
    "    L2_1_list.append(np.random.uniform(0.003, 0.005))\n",
    "# L2 for layer 2 between 1e-4 and 1e-8\n",
    "L2_2_list = []\n",
    "for i in range(5):\n",
    "    r = -2*np.random.rand()\n",
    "    s = 0.000001*(10**r)\n",
    "    L2_2_list.append(s)\n",
    "print(\"Min L2 layer 1:\\t\", min(L2_1_list))\n",
    "print(\"Max L2 layer 1:\\t\", max(L2_1_list))\n",
    "print(\"Min L2 layer 2:\\t\", min(L2_2_list))\n",
    "print(\"Max L2 layer 2:\\t\", max(L2_2_list))\n",
    "print(\"Layer 1 L2:\\t\", L2_1_list)\n",
    "print(\"Layer 2 L2:\\t\", L2_2_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8550\n",
      "WARNING:tensorflow:From /home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8579 - acc: 0.5717 - val_loss: 0.7797 - val_acc: 0.6313\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77970, saving model to Post_val_weights1.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.7259 - acc: 0.6715 - val_loss: 0.6729 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77970 to 0.67291, saving model to Post_val_weights1.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6285 - acc: 0.7434 - val_loss: 0.5884 - val_acc: 0.7696\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67291 to 0.58843, saving model to Post_val_weights1.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5478 - acc: 0.7916 - val_loss: 0.5167 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58843 to 0.51675, saving model to Post_val_weights1.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4805 - acc: 0.8247 - val_loss: 0.4596 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51675 to 0.45961, saving model to Post_val_weights1.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4311 - acc: 0.8455 - val_loss: 0.4202 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45961 to 0.42021, saving model to Post_val_weights1.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3986 - acc: 0.8562 - val_loss: 0.3937 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42021 to 0.39372, saving model to Post_val_weights1.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3772 - acc: 0.8636 - val_loss: 0.3773 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39372 to 0.37727, saving model to Post_val_weights1.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3634 - acc: 0.8669 - val_loss: 0.3668 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.37727 to 0.36685, saving model to Post_val_weights1.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3543 - acc: 0.8684 - val_loss: 0.3596 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36685 to 0.35964, saving model to Post_val_weights1.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3479 - acc: 0.8699 - val_loss: 0.3541 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.35964 to 0.35408, saving model to Post_val_weights1.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3432 - acc: 0.8705 - val_loss: 0.3499 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35408 to 0.34985, saving model to Post_val_weights1.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3396 - acc: 0.8714 - val_loss: 0.3464 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34985 to 0.34644, saving model to Post_val_weights1.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3367 - acc: 0.8720 - val_loss: 0.3436 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34644 to 0.34362, saving model to Post_val_weights1.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3344 - acc: 0.8722 - val_loss: 0.3413 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34362 to 0.34132, saving model to Post_val_weights1.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3325 - acc: 0.8723 - val_loss: 0.3393 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34132 to 0.33932, saving model to Post_val_weights1.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3308 - acc: 0.8726 - val_loss: 0.3377 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33932 to 0.33770, saving model to Post_val_weights1.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3295 - acc: 0.8726 - val_loss: 0.3363 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33770 to 0.33626, saving model to Post_val_weights1.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3281 - acc: 0.8729 - val_loss: 0.3350 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33626 to 0.33496, saving model to Post_val_weights1.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3272 - acc: 0.8731 - val_loss: 0.3339 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33496 to 0.33389, saving model to Post_val_weights1.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3262 - acc: 0.8731 - val_loss: 0.3328 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33389 to 0.33285, saving model to Post_val_weights1.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3254 - acc: 0.8731 - val_loss: 0.3320 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33285 to 0.33203, saving model to Post_val_weights1.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3246 - acc: 0.8736 - val_loss: 0.3313 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33203 to 0.33128, saving model to Post_val_weights1.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8737 - val_loss: 0.3307 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33128 to 0.33065, saving model to Post_val_weights1.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8738 - val_loss: 0.3301 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33065 to 0.33007, saving model to Post_val_weights1.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8738 - val_loss: 0.3296 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33007 to 0.32960, saving model to Post_val_weights1.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8740 - val_loss: 0.3291 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.32960 to 0.32913, saving model to Post_val_weights1.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3220 - acc: 0.8739 - val_loss: 0.3287 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.32913 to 0.32872, saving model to Post_val_weights1.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8739 - val_loss: 0.3284 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.32872 to 0.32836, saving model to Post_val_weights1.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8741 - val_loss: 0.3280 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.32836 to 0.32800, saving model to Post_val_weights1.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3208 - acc: 0.8742 - val_loss: 0.3277 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.32800 to 0.32774, saving model to Post_val_weights1.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8742 - val_loss: 0.3275 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.32774 to 0.32745, saving model to Post_val_weights1.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8743 - val_loss: 0.3273 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.32745 to 0.32730, saving model to Post_val_weights1.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3200 - acc: 0.8743 - val_loss: 0.3270 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.32730 to 0.32701, saving model to Post_val_weights1.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8743 - val_loss: 0.3269 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.32701 to 0.32686, saving model to Post_val_weights1.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3195 - acc: 0.8743 - val_loss: 0.3266 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.32686 to 0.32660, saving model to Post_val_weights1.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8741 - val_loss: 0.3265 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.32660 to 0.32648, saving model to Post_val_weights1.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8741 - val_loss: 0.3263 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.32648 to 0.32629, saving model to Post_val_weights1.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8742 - val_loss: 0.3261 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.32629 to 0.32610, saving model to Post_val_weights1.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8743 - val_loss: 0.3260 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.32610 to 0.32598, saving model to Post_val_weights1.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8744 - val_loss: 0.3258 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.32598 to 0.32581, saving model to Post_val_weights1.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8745 - val_loss: 0.3257 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.32581 to 0.32569, saving model to Post_val_weights1.hdf5\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3181 - acc: 0.8744 - val_loss: 0.3256 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.32569 to 0.32558, saving model to Post_val_weights1.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8746 - val_loss: 0.3255 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.32558 to 0.32546, saving model to Post_val_weights1.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8745 - val_loss: 0.3254 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.32546 to 0.32536, saving model to Post_val_weights1.hdf5\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8747 - val_loss: 0.3253 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.32536 to 0.32526, saving model to Post_val_weights1.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8746 - val_loss: 0.3252 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.32526 to 0.32517, saving model to Post_val_weights1.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8746 - val_loss: 0.3252 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.32517 to 0.32516, saving model to Post_val_weights1.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8746 - val_loss: 0.3250 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.32516 to 0.32502, saving model to Post_val_weights1.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8746 - val_loss: 0.3250 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.32502 to 0.32500, saving model to Post_val_weights1.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8747 - val_loss: 0.3249 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.32500 to 0.32489, saving model to Post_val_weights1.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8747 - val_loss: 0.3248 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.32489 to 0.32483, saving model to Post_val_weights1.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8747 - val_loss: 0.3248 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.32483 to 0.32476, saving model to Post_val_weights1.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8748 - val_loss: 0.3247 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.32476 to 0.32471, saving model to Post_val_weights1.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8748 - val_loss: 0.3246 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.32471 to 0.32465, saving model to Post_val_weights1.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8748 - val_loss: 0.3246 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.32465 to 0.32455, saving model to Post_val_weights1.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8748 - val_loss: 0.3246 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32455\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8748 - val_loss: 0.3244 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.32455 to 0.32444, saving model to Post_val_weights1.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8748 - val_loss: 0.3244 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.32444 to 0.32440, saving model to Post_val_weights1.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8748 - val_loss: 0.3243 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.32440 to 0.32431, saving model to Post_val_weights1.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8747 - val_loss: 0.3243 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.32431 to 0.32430, saving model to Post_val_weights1.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8746 - val_loss: 0.3242 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.32430 to 0.32422, saving model to Post_val_weights1.hdf5\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8747 - val_loss: 0.3242 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.32422 to 0.32416, saving model to Post_val_weights1.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8748 - val_loss: 0.3241 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.32416 to 0.32407, saving model to Post_val_weights1.hdf5\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8750 - val_loss: 0.3241 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32407\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8749 - val_loss: 0.3240 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.32407 to 0.32402, saving model to Post_val_weights1.hdf5\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8749 - val_loss: 0.3242 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.32402\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8749 - val_loss: 0.3241 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.32402\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8748 - val_loss: 0.3240 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32402\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8748 - val_loss: 0.3239 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.32402 to 0.32394, saving model to Post_val_weights1.hdf5\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8749 - val_loss: 0.3239 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.32394 to 0.32387, saving model to Post_val_weights1.hdf5\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8749 - val_loss: 0.3238 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.32387 to 0.32383, saving model to Post_val_weights1.hdf5\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8749 - val_loss: 0.3238 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.32383 to 0.32376, saving model to Post_val_weights1.hdf5\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8750 - val_loss: 0.3237 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.32376 to 0.32374, saving model to Post_val_weights1.hdf5\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8751 - val_loss: 0.3237 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.32374 to 0.32374, saving model to Post_val_weights1.hdf5\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8750 - val_loss: 0.3237 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.32374 to 0.32367, saving model to Post_val_weights1.hdf5\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8751 - val_loss: 0.3237 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32367\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8751 - val_loss: 0.3236 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.32367 to 0.32357, saving model to Post_val_weights1.hdf5\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8751 - val_loss: 0.3237 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32357\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8751 - val_loss: 0.3237 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32357\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8753 - val_loss: 0.3236 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32357\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8752 - val_loss: 0.3236 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.32357 to 0.32355, saving model to Post_val_weights1.hdf5\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8753 - val_loss: 0.3235 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.32355 to 0.32353, saving model to Post_val_weights1.hdf5\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8753 - val_loss: 0.3235 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.32353 to 0.32345, saving model to Post_val_weights1.hdf5\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8753 - val_loss: 0.3235 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32345\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8753 - val_loss: 0.3234 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.32345 to 0.32343, saving model to Post_val_weights1.hdf5\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8754 - val_loss: 0.3234 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.32343 to 0.32341, saving model to Post_val_weights1.hdf5\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8752 - val_loss: 0.3233 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.32341 to 0.32334, saving model to Post_val_weights1.hdf5\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8754 - val_loss: 0.3233 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32334\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8753 - val_loss: 0.3233 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.32334 to 0.32333, saving model to Post_val_weights1.hdf5\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3141 - acc: 0.8754 - val_loss: 0.3233 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.32333 to 0.32331, saving model to Post_val_weights1.hdf5\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8755 - val_loss: 0.3232 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.32331 to 0.32324, saving model to Post_val_weights1.hdf5\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8756 - val_loss: 0.3233 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32324\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8756 - val_loss: 0.3232 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.32324 to 0.32320, saving model to Post_val_weights1.hdf5\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8756 - val_loss: 0.3232 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32320\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8757 - val_loss: 0.3232 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.32320 to 0.32316, saving model to Post_val_weights1.hdf5\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8757 - val_loss: 0.3232 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32316\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8757 - val_loss: 0.3231 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.32316 to 0.32314, saving model to Post_val_weights1.hdf5\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8758 - val_loss: 0.3232 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32314\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8758 - val_loss: 0.3231 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.32314 to 0.32307, saving model to Post_val_weights1.hdf5\n",
      "#################################\n",
      "Number of units: 8\n",
      "Batch size: 4096\n",
      "Fold: 0\n",
      "L2_1: 0.009847289899093989\n",
      "best val loss: 0.3230706051497432\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.8575 - acc: 0.5723 - val_loss: 0.7807 - val_acc: 0.6291\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78071, saving model to Post_val_weights2.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.7257 - acc: 0.6708 - val_loss: 0.6712 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78071 to 0.67116, saving model to Post_val_weights2.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6283 - acc: 0.7434 - val_loss: 0.5853 - val_acc: 0.7683\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67116 to 0.58526, saving model to Post_val_weights2.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5478 - acc: 0.7916 - val_loss: 0.5106 - val_acc: 0.8104\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58526 to 0.51062, saving model to Post_val_weights2.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4809 - acc: 0.8245 - val_loss: 0.4531 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51062 to 0.45313, saving model to Post_val_weights2.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4313 - acc: 0.8452 - val_loss: 0.4144 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45313 to 0.41435, saving model to Post_val_weights2.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3984 - acc: 0.8560 - val_loss: 0.3900 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41435 to 0.39004, saving model to Post_val_weights2.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3770 - acc: 0.8631 - val_loss: 0.3741 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39004 to 0.37413, saving model to Post_val_weights2.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3633 - acc: 0.8668 - val_loss: 0.3637 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.37413 to 0.36371, saving model to Post_val_weights2.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3543 - acc: 0.8685 - val_loss: 0.3566 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36371 to 0.35660, saving model to Post_val_weights2.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3478 - acc: 0.8698 - val_loss: 0.3514 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.35660 to 0.35145, saving model to Post_val_weights2.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3431 - acc: 0.8706 - val_loss: 0.3475 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35145 to 0.34754, saving model to Post_val_weights2.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3395 - acc: 0.8713 - val_loss: 0.3443 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34754 to 0.34434, saving model to Post_val_weights2.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3366 - acc: 0.8717 - val_loss: 0.3418 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34434 to 0.34181, saving model to Post_val_weights2.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3342 - acc: 0.8723 - val_loss: 0.3398 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34181 to 0.33979, saving model to Post_val_weights2.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3323 - acc: 0.8724 - val_loss: 0.3381 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33979 to 0.33813, saving model to Post_val_weights2.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3306 - acc: 0.8726 - val_loss: 0.3369 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33813 to 0.33688, saving model to Post_val_weights2.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3292 - acc: 0.8728 - val_loss: 0.3358 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33688 to 0.33578, saving model to Post_val_weights2.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3280 - acc: 0.8730 - val_loss: 0.3349 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33578 to 0.33492, saving model to Post_val_weights2.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3270 - acc: 0.8731 - val_loss: 0.3341 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33492 to 0.33412, saving model to Post_val_weights2.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3260 - acc: 0.8734 - val_loss: 0.3335 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33412 to 0.33346, saving model to Post_val_weights2.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8735 - val_loss: 0.3329 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33346 to 0.33285, saving model to Post_val_weights2.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3244 - acc: 0.8735 - val_loss: 0.3323 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33285 to 0.33234, saving model to Post_val_weights2.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3238 - acc: 0.8736 - val_loss: 0.3319 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33234 to 0.33188, saving model to Post_val_weights2.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8738 - val_loss: 0.3315 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33188 to 0.33152, saving model to Post_val_weights2.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3226 - acc: 0.8739 - val_loss: 0.3311 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33152 to 0.33113, saving model to Post_val_weights2.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8742 - val_loss: 0.3308 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33113 to 0.33081, saving model to Post_val_weights2.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3216 - acc: 0.8742 - val_loss: 0.3305 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33081 to 0.33053, saving model to Post_val_weights2.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3212 - acc: 0.8743 - val_loss: 0.3302 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33053 to 0.33023, saving model to Post_val_weights2.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8744 - val_loss: 0.3300 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33023 to 0.32998, saving model to Post_val_weights2.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8745 - val_loss: 0.3297 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.32998 to 0.32972, saving model to Post_val_weights2.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8743 - val_loss: 0.3294 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.32972 to 0.32940, saving model to Post_val_weights2.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8742 - val_loss: 0.3292 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.32940 to 0.32921, saving model to Post_val_weights2.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8743 - val_loss: 0.3290 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.32921 to 0.32904, saving model to Post_val_weights2.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8742 - val_loss: 0.3289 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.32904 to 0.32890, saving model to Post_val_weights2.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8743 - val_loss: 0.3287 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.32890 to 0.32868, saving model to Post_val_weights2.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8742 - val_loss: 0.3287 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.32868\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8742 - val_loss: 0.3284 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.32868 to 0.32845, saving model to Post_val_weights2.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8740 - val_loss: 0.3284 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.32845 to 0.32845, saving model to Post_val_weights2.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8742 - val_loss: 0.3284 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.32845 to 0.32837, saving model to Post_val_weights2.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8743 - val_loss: 0.3284 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.32837 to 0.32835, saving model to Post_val_weights2.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8743 - val_loss: 0.3281 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.32835 to 0.32809, saving model to Post_val_weights2.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8744 - val_loss: 0.3282 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.32809\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8744 - val_loss: 0.3280 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.32809 to 0.32800, saving model to Post_val_weights2.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8743 - val_loss: 0.3280 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.32800\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8746 - val_loss: 0.3280 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.32800 to 0.32798, saving model to Post_val_weights2.hdf5\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3171 - acc: 0.8746 - val_loss: 0.3279 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.32798 to 0.32792, saving model to Post_val_weights2.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8748 - val_loss: 0.3279 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.32792 to 0.32790, saving model to Post_val_weights2.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8749 - val_loss: 0.3277 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.32790 to 0.32774, saving model to Post_val_weights2.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8751 - val_loss: 0.3276 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.32774 to 0.32763, saving model to Post_val_weights2.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8751 - val_loss: 0.3280 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.32763\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8751 - val_loss: 0.3279 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.32763\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8750 - val_loss: 0.3277 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32763\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8750 - val_loss: 0.3277 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.32763\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8751 - val_loss: 0.3277 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.32763\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8750 - val_loss: 0.3276 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.32763 to 0.32761, saving model to Post_val_weights2.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8750 - val_loss: 0.3276 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.32761 to 0.32758, saving model to Post_val_weights2.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8750 - val_loss: 0.3276 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.32758 to 0.32757, saving model to Post_val_weights2.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8752 - val_loss: 0.3278 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.32757\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8751 - val_loss: 0.3275 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.32757 to 0.32753, saving model to Post_val_weights2.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8751 - val_loss: 0.3276 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.32753\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8750 - val_loss: 0.3278 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32753\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8751 - val_loss: 0.3277 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32753\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8750 - val_loss: 0.3275 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.32753 to 0.32748, saving model to Post_val_weights2.hdf5\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8752 - val_loss: 0.3276 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32748\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8751 - val_loss: 0.3276 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.32748\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8753 - val_loss: 0.3275 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.32748\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8753 - val_loss: 0.3274 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.32748 to 0.32739, saving model to Post_val_weights2.hdf5\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8753 - val_loss: 0.3275 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32739\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8753 - val_loss: 0.3274 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.32739\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8755 - val_loss: 0.3273 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.32739 to 0.32730, saving model to Post_val_weights2.hdf5\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8755 - val_loss: 0.3275 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.32730\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8756 - val_loss: 0.3276 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.32730\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8756 - val_loss: 0.3274 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.32730\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8755 - val_loss: 0.3275 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.32730\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8755 - val_loss: 0.3276 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.32730\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8755 - val_loss: 0.3275 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32730\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8754 - val_loss: 0.3276 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.32730\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8754 - val_loss: 0.3276 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32730\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8754 - val_loss: 0.3275 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32730\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8753 - val_loss: 0.3276 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32730\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8754 - val_loss: 0.3277 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.32730\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8755 - val_loss: 0.3276 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.32730\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8756 - val_loss: 0.3277 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.32730\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8756 - val_loss: 0.3278 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32730\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8756 - val_loss: 0.3276 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.32730\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8758 - val_loss: 0.3279 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.32730\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8758 - val_loss: 0.3278 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.32730\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8760 - val_loss: 0.3278 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32730\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8759 - val_loss: 0.3277 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.32730\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8758 - val_loss: 0.3279 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.32730\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8759 - val_loss: 0.3277 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.32730\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8760 - val_loss: 0.3278 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32730\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8759 - val_loss: 0.3278 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.32730\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8759 - val_loss: 0.3278 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32730\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8758 - val_loss: 0.3277 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.32730\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8759 - val_loss: 0.3279 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32730\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8760 - val_loss: 0.3277 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32730\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8760 - val_loss: 0.3276 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32730\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8760 - val_loss: 0.3276 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32730\n",
      "#################################\n",
      "Number of units: 8\n",
      "Batch size: 4096\n",
      "Fold: 1\n",
      "L2_1: 0.009847289899093989\n",
      "best val loss: 0.3273032117587084\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.8568 - acc: 0.5725 - val_loss: 0.7859 - val_acc: 0.6232\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78595, saving model to Post_val_weights3.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.7256 - acc: 0.6704 - val_loss: 0.6762 - val_acc: 0.7132\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78595 to 0.67624, saving model to Post_val_weights3.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6287 - acc: 0.7430 - val_loss: 0.5905 - val_acc: 0.7667\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67624 to 0.59054, saving model to Post_val_weights3.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5482 - acc: 0.7915 - val_loss: 0.5194 - val_acc: 0.8037\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59054 to 0.51936, saving model to Post_val_weights3.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4808 - acc: 0.8246 - val_loss: 0.4629 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51936 to 0.46295, saving model to Post_val_weights3.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4308 - acc: 0.8458 - val_loss: 0.4238 - val_acc: 0.8425\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46295 to 0.42376, saving model to Post_val_weights3.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3981 - acc: 0.8565 - val_loss: 0.3980 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42376 to 0.39795, saving model to Post_val_weights3.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3768 - acc: 0.8636 - val_loss: 0.3812 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39795 to 0.38121, saving model to Post_val_weights3.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3631 - acc: 0.8670 - val_loss: 0.3700 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38121 to 0.36998, saving model to Post_val_weights3.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3538 - acc: 0.8690 - val_loss: 0.3623 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36998 to 0.36227, saving model to Post_val_weights3.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3473 - acc: 0.8702 - val_loss: 0.3573 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36227 to 0.35727, saving model to Post_val_weights3.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3426 - acc: 0.8713 - val_loss: 0.3536 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35727 to 0.35361, saving model to Post_val_weights3.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3389 - acc: 0.8720 - val_loss: 0.3506 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35361 to 0.35062, saving model to Post_val_weights3.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3360 - acc: 0.8730 - val_loss: 0.3482 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35062 to 0.34820, saving model to Post_val_weights3.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3336 - acc: 0.8731 - val_loss: 0.3462 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34820 to 0.34624, saving model to Post_val_weights3.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3317 - acc: 0.8734 - val_loss: 0.3447 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34624 to 0.34471, saving model to Post_val_weights3.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3300 - acc: 0.8739 - val_loss: 0.3434 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34471 to 0.34342, saving model to Post_val_weights3.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8739 - val_loss: 0.3423 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34342 to 0.34233, saving model to Post_val_weights3.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3274 - acc: 0.8740 - val_loss: 0.3414 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34233 to 0.34138, saving model to Post_val_weights3.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8740 - val_loss: 0.3405 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34138 to 0.34054, saving model to Post_val_weights3.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3254 - acc: 0.8740 - val_loss: 0.3398 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34054 to 0.33979, saving model to Post_val_weights3.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3245 - acc: 0.8742 - val_loss: 0.3391 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33979 to 0.33911, saving model to Post_val_weights3.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3237 - acc: 0.8745 - val_loss: 0.3385 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33911 to 0.33847, saving model to Post_val_weights3.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3231 - acc: 0.8747 - val_loss: 0.3379 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33847 to 0.33787, saving model to Post_val_weights3.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3224 - acc: 0.8749 - val_loss: 0.3373 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33787 to 0.33731, saving model to Post_val_weights3.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3219 - acc: 0.8750 - val_loss: 0.3368 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33731 to 0.33678, saving model to Post_val_weights3.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3214 - acc: 0.8751 - val_loss: 0.3363 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33678 to 0.33629, saving model to Post_val_weights3.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3210 - acc: 0.8751 - val_loss: 0.3359 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33629 to 0.33587, saving model to Post_val_weights3.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8750 - val_loss: 0.3354 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33587 to 0.33544, saving model to Post_val_weights3.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8750 - val_loss: 0.3351 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33544 to 0.33513, saving model to Post_val_weights3.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8750 - val_loss: 0.3347 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33513 to 0.33474, saving model to Post_val_weights3.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8752 - val_loss: 0.3346 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33474 to 0.33463, saving model to Post_val_weights3.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3193 - acc: 0.8752 - val_loss: 0.3344 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33463 to 0.33436, saving model to Post_val_weights3.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3190 - acc: 0.8752 - val_loss: 0.3342 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33436 to 0.33415, saving model to Post_val_weights3.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3188 - acc: 0.8751 - val_loss: 0.3339 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33415 to 0.33388, saving model to Post_val_weights3.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8750 - val_loss: 0.3338 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33388 to 0.33379, saving model to Post_val_weights3.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8750 - val_loss: 0.3335 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33379 to 0.33353, saving model to Post_val_weights3.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3181 - acc: 0.8750 - val_loss: 0.3334 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33353 to 0.33342, saving model to Post_val_weights3.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3178 - acc: 0.8750 - val_loss: 0.3331 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33342 to 0.33313, saving model to Post_val_weights3.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8749 - val_loss: 0.3331 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33313 to 0.33311, saving model to Post_val_weights3.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8750 - val_loss: 0.3329 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33311 to 0.33292, saving model to Post_val_weights3.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8749 - val_loss: 0.3328 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33292 to 0.33281, saving model to Post_val_weights3.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8750 - val_loss: 0.3326 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33281 to 0.33265, saving model to Post_val_weights3.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8751 - val_loss: 0.3325 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33265 to 0.33253, saving model to Post_val_weights3.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8751 - val_loss: 0.3325 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33253 to 0.33249, saving model to Post_val_weights3.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3166 - acc: 0.8752 - val_loss: 0.3325 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33249 to 0.33248, saving model to Post_val_weights3.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8753 - val_loss: 0.3324 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33248 to 0.33235, saving model to Post_val_weights3.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8754 - val_loss: 0.3323 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33235 to 0.33233, saving model to Post_val_weights3.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8753 - val_loss: 0.3322 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33233 to 0.33223, saving model to Post_val_weights3.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8753 - val_loss: 0.3322 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33223\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8753 - val_loss: 0.3321 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33223 to 0.33210, saving model to Post_val_weights3.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8753 - val_loss: 0.3322 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33210\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8754 - val_loss: 0.3321 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33210 to 0.33209, saving model to Post_val_weights3.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8754 - val_loss: 0.3321 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33209\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8755 - val_loss: 0.3321 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33209 to 0.33206, saving model to Post_val_weights3.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8755 - val_loss: 0.3321 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33206\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8755 - val_loss: 0.3320 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33206 to 0.33205, saving model to Post_val_weights3.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8756 - val_loss: 0.3321 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33205\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8757 - val_loss: 0.3322 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33205\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8757 - val_loss: 0.3322 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33205\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8758 - val_loss: 0.3322 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33205\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8757 - val_loss: 0.3322 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33205\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8757 - val_loss: 0.3323 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33205\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8757 - val_loss: 0.3323 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33205\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8758 - val_loss: 0.3323 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33205\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33205\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8758 - val_loss: 0.3323 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33205\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8759 - val_loss: 0.3323 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33205\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8760 - val_loss: 0.3324 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33205\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8760 - val_loss: 0.3323 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33205\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33205\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8760 - val_loss: 0.3323 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33205\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33205\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8760 - val_loss: 0.3324 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33205\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8758 - val_loss: 0.3325 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33205\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33205\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8759 - val_loss: 0.3323 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33205\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33205\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33205\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33205\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33205\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8758 - val_loss: 0.3324 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33205\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8758 - val_loss: 0.3323 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33205\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8758 - val_loss: 0.3322 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33205\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8758 - val_loss: 0.3324 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33205\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8759 - val_loss: 0.3324 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33205\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8760 - val_loss: 0.3323 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33205\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8759 - val_loss: 0.3323 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33205\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8760 - val_loss: 0.3323 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33205\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8759 - val_loss: 0.3323 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33205\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8758 - val_loss: 0.3325 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33205\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8758 - val_loss: 0.3324 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33205\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8759 - val_loss: 0.3325 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33205\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8758 - val_loss: 0.3324 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33205\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8759 - val_loss: 0.3325 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33205\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3127 - acc: 0.8759 - val_loss: 0.3325 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33205\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3126 - acc: 0.8759 - val_loss: 0.3326 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33205\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8760 - val_loss: 0.3325 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33205\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8761 - val_loss: 0.3328 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33205\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3125 - acc: 0.8761 - val_loss: 0.3327 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33205\n",
      "#################################\n",
      "Number of units: 8\n",
      "Batch size: 4096\n",
      "Fold: 2\n",
      "L2_1: 0.009847289899093989\n",
      "best val loss: 0.33204920897009776\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe230475a90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.8570 - acc: 0.5729 - val_loss: 0.7872 - val_acc: 0.6242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78723, saving model to Post_val_weights4.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.7252 - acc: 0.6714 - val_loss: 0.6802 - val_acc: 0.7077\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78723 to 0.68016, saving model to Post_val_weights4.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6279 - acc: 0.7441 - val_loss: 0.5948 - val_acc: 0.7616\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68016 to 0.59483, saving model to Post_val_weights4.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5476 - acc: 0.7917 - val_loss: 0.5197 - val_acc: 0.8067\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59483 to 0.51972, saving model to Post_val_weights4.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4807 - acc: 0.8243 - val_loss: 0.4599 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51972 to 0.45985, saving model to Post_val_weights4.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4310 - acc: 0.8459 - val_loss: 0.4199 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45985 to 0.41992, saving model to Post_val_weights4.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3983 - acc: 0.8564 - val_loss: 0.3936 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41992 to 0.39365, saving model to Post_val_weights4.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3770 - acc: 0.8630 - val_loss: 0.3766 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39365 to 0.37660, saving model to Post_val_weights4.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3634 - acc: 0.8664 - val_loss: 0.3653 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.37660 to 0.36527, saving model to Post_val_weights4.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3544 - acc: 0.8678 - val_loss: 0.3579 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36527 to 0.35790, saving model to Post_val_weights4.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3481 - acc: 0.8694 - val_loss: 0.3526 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.35790 to 0.35256, saving model to Post_val_weights4.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3434 - acc: 0.8706 - val_loss: 0.3485 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35256 to 0.34851, saving model to Post_val_weights4.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3397 - acc: 0.8713 - val_loss: 0.3453 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34851 to 0.34527, saving model to Post_val_weights4.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3369 - acc: 0.8717 - val_loss: 0.3427 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34527 to 0.34275, saving model to Post_val_weights4.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3346 - acc: 0.8719 - val_loss: 0.3404 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34275 to 0.34041, saving model to Post_val_weights4.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3326 - acc: 0.8724 - val_loss: 0.3387 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34041 to 0.33867, saving model to Post_val_weights4.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3310 - acc: 0.8726 - val_loss: 0.3371 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33867 to 0.33707, saving model to Post_val_weights4.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3296 - acc: 0.8730 - val_loss: 0.3358 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33707 to 0.33583, saving model to Post_val_weights4.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3284 - acc: 0.8729 - val_loss: 0.3346 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33583 to 0.33457, saving model to Post_val_weights4.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3273 - acc: 0.8732 - val_loss: 0.3336 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33457 to 0.33359, saving model to Post_val_weights4.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3264 - acc: 0.8731 - val_loss: 0.3327 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33359 to 0.33272, saving model to Post_val_weights4.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3255 - acc: 0.8733 - val_loss: 0.3319 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33272 to 0.33193, saving model to Post_val_weights4.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3248 - acc: 0.8735 - val_loss: 0.3312 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33193 to 0.33121, saving model to Post_val_weights4.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8734 - val_loss: 0.3306 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33121 to 0.33060, saving model to Post_val_weights4.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8735 - val_loss: 0.3301 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33060 to 0.33009, saving model to Post_val_weights4.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3228 - acc: 0.8739 - val_loss: 0.3297 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33009 to 0.32966, saving model to Post_val_weights4.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8740 - val_loss: 0.3295 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.32966 to 0.32949, saving model to Post_val_weights4.hdf5\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8739 - val_loss: 0.3289 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.32949 to 0.32891, saving model to Post_val_weights4.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8741 - val_loss: 0.3288 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.32891 to 0.32878, saving model to Post_val_weights4.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8742 - val_loss: 0.3285 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.32878 to 0.32846, saving model to Post_val_weights4.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3206 - acc: 0.8743 - val_loss: 0.3283 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.32846 to 0.32833, saving model to Post_val_weights4.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3202 - acc: 0.8745 - val_loss: 0.3281 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.32833 to 0.32811, saving model to Post_val_weights4.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8745 - val_loss: 0.3280 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.32811 to 0.32797, saving model to Post_val_weights4.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8745 - val_loss: 0.3278 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.32797 to 0.32782, saving model to Post_val_weights4.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8745 - val_loss: 0.3277 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.32782 to 0.32773, saving model to Post_val_weights4.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8744 - val_loss: 0.3275 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.32773 to 0.32753, saving model to Post_val_weights4.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8745 - val_loss: 0.3275 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.32753 to 0.32749, saving model to Post_val_weights4.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3187 - acc: 0.8743 - val_loss: 0.3273 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.32749 to 0.32730, saving model to Post_val_weights4.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3185 - acc: 0.8744 - val_loss: 0.3272 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.32730 to 0.32721, saving model to Post_val_weights4.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3183 - acc: 0.8745 - val_loss: 0.3271 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.32721 to 0.32708, saving model to Post_val_weights4.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8744 - val_loss: 0.3269 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.32708 to 0.32694, saving model to Post_val_weights4.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8746 - val_loss: 0.3268 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.32694 to 0.32682, saving model to Post_val_weights4.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8747 - val_loss: 0.3268 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.32682 to 0.32676, saving model to Post_val_weights4.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8748 - val_loss: 0.3267 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.32676 to 0.32671, saving model to Post_val_weights4.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3176 - acc: 0.8749 - val_loss: 0.3266 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.32671 to 0.32661, saving model to Post_val_weights4.hdf5\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3174 - acc: 0.8750 - val_loss: 0.3265 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.32661 to 0.32653, saving model to Post_val_weights4.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3173 - acc: 0.8749 - val_loss: 0.3264 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.32653 to 0.32639, saving model to Post_val_weights4.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8748 - val_loss: 0.3263 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.32639 to 0.32631, saving model to Post_val_weights4.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3170 - acc: 0.8748 - val_loss: 0.3262 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.32631 to 0.32622, saving model to Post_val_weights4.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8748 - val_loss: 0.3261 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.32622 to 0.32612, saving model to Post_val_weights4.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8749 - val_loss: 0.3260 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.32612 to 0.32601, saving model to Post_val_weights4.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8749 - val_loss: 0.3259 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.32601 to 0.32595, saving model to Post_val_weights4.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3165 - acc: 0.8749 - val_loss: 0.3259 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.32595 to 0.32586, saving model to Post_val_weights4.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8749 - val_loss: 0.3258 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.32586 to 0.32578, saving model to Post_val_weights4.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8750 - val_loss: 0.3257 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.32578 to 0.32566, saving model to Post_val_weights4.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8751 - val_loss: 0.3256 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.32566 to 0.32563, saving model to Post_val_weights4.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8751 - val_loss: 0.3255 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.32563 to 0.32555, saving model to Post_val_weights4.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8751 - val_loss: 0.3255 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.32555 to 0.32547, saving model to Post_val_weights4.hdf5\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8752 - val_loss: 0.3254 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.32547 to 0.32542, saving model to Post_val_weights4.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8751 - val_loss: 0.3253 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.32542 to 0.32534, saving model to Post_val_weights4.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8753 - val_loss: 0.3253 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.32534 to 0.32529, saving model to Post_val_weights4.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8754 - val_loss: 0.3252 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.32529 to 0.32524, saving model to Post_val_weights4.hdf5\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8755 - val_loss: 0.3251 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.32524 to 0.32515, saving model to Post_val_weights4.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8755 - val_loss: 0.3251 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.32515\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8754 - val_loss: 0.3250 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.32515 to 0.32505, saving model to Post_val_weights4.hdf5\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8753 - val_loss: 0.3250 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.32505 to 0.32501, saving model to Post_val_weights4.hdf5\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8752 - val_loss: 0.3249 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.32501 to 0.32489, saving model to Post_val_weights4.hdf5\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8752 - val_loss: 0.3249 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.32489 to 0.32488, saving model to Post_val_weights4.hdf5\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8752 - val_loss: 0.3248 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.32488 to 0.32480, saving model to Post_val_weights4.hdf5\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8750 - val_loss: 0.3248 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.32480 to 0.32479, saving model to Post_val_weights4.hdf5\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8751 - val_loss: 0.3247 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.32479 to 0.32472, saving model to Post_val_weights4.hdf5\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8751 - val_loss: 0.3247 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.32472\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8750 - val_loss: 0.3246 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.32472 to 0.32463, saving model to Post_val_weights4.hdf5\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8751 - val_loss: 0.3246 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.32463 to 0.32462, saving model to Post_val_weights4.hdf5\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8750 - val_loss: 0.3246 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.32462 to 0.32459, saving model to Post_val_weights4.hdf5\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8751 - val_loss: 0.3246 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.32459\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8753 - val_loss: 0.3246 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.32459 to 0.32456, saving model to Post_val_weights4.hdf5\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8753 - val_loss: 0.3246 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.32456\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8753 - val_loss: 0.3246 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32456\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8753 - val_loss: 0.3247 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32456\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8753 - val_loss: 0.3247 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32456\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8753 - val_loss: 0.3248 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.32456\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8753 - val_loss: 0.3249 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.32456\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8753 - val_loss: 0.3250 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.32456\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8752 - val_loss: 0.3250 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32456\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8752 - val_loss: 0.3252 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.32456\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8751 - val_loss: 0.3252 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.32456\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8753 - val_loss: 0.3253 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.32456\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8752 - val_loss: 0.3253 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32456\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8752 - val_loss: 0.3254 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.32456\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8753 - val_loss: 0.3254 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.32456\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8753 - val_loss: 0.3255 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.32456\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8753 - val_loss: 0.3254 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32456\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8752 - val_loss: 0.3255 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.32456\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8753 - val_loss: 0.3255 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32456\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8752 - val_loss: 0.3255 - val_acc: 0.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00096: val_loss did not improve from 0.32456\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8753 - val_loss: 0.3255 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32456\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8752 - val_loss: 0.3256 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32456\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8752 - val_loss: 0.3257 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32456\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8752 - val_loss: 0.3257 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32456\n",
      "#################################\n",
      "Number of units: 8\n",
      "Batch size: 4096\n",
      "Fold: 3\n",
      "L2_1: 0.009847289899093989\n",
      "best val loss: 0.324557525198362\n",
      "#################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe2143bc2e8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/whsu014/.conda/envs/whsuphd/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76950 samples, validate on 8550 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8588 - acc: 0.5722 - val_loss: 0.7800 - val_acc: 0.6242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77999, saving model to Post_val_weights5.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.7273 - acc: 0.6704 - val_loss: 0.6723 - val_acc: 0.7118\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77999 to 0.67233, saving model to Post_val_weights5.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6300 - acc: 0.7432 - val_loss: 0.5876 - val_acc: 0.7665\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67233 to 0.58765, saving model to Post_val_weights5.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5491 - acc: 0.7912 - val_loss: 0.5151 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58765 to 0.51511, saving model to Post_val_weights5.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4814 - acc: 0.8247 - val_loss: 0.4589 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51511 to 0.45892, saving model to Post_val_weights5.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4314 - acc: 0.8451 - val_loss: 0.4222 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45892 to 0.42220, saving model to Post_val_weights5.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3983 - acc: 0.8569 - val_loss: 0.3982 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42220 to 0.39819, saving model to Post_val_weights5.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3767 - acc: 0.8637 - val_loss: 0.3813 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39819 to 0.38127, saving model to Post_val_weights5.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3628 - acc: 0.8669 - val_loss: 0.3705 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38127 to 0.37051, saving model to Post_val_weights5.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3536 - acc: 0.8688 - val_loss: 0.3632 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37051 to 0.36321, saving model to Post_val_weights5.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3472 - acc: 0.8699 - val_loss: 0.3580 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36321 to 0.35795, saving model to Post_val_weights5.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3425 - acc: 0.8707 - val_loss: 0.3540 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35795 to 0.35402, saving model to Post_val_weights5.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3388 - acc: 0.8719 - val_loss: 0.3509 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35402 to 0.35092, saving model to Post_val_weights5.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3359 - acc: 0.8722 - val_loss: 0.3484 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35092 to 0.34836, saving model to Post_val_weights5.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3335 - acc: 0.8727 - val_loss: 0.3464 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34836 to 0.34639, saving model to Post_val_weights5.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3315 - acc: 0.8729 - val_loss: 0.3446 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34639 to 0.34457, saving model to Post_val_weights5.hdf5\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3298 - acc: 0.8736 - val_loss: 0.3432 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34457 to 0.34322, saving model to Post_val_weights5.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3284 - acc: 0.8734 - val_loss: 0.3419 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34322 to 0.34190, saving model to Post_val_weights5.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3272 - acc: 0.8736 - val_loss: 0.3409 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34190 to 0.34094, saving model to Post_val_weights5.hdf5\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3261 - acc: 0.8740 - val_loss: 0.3400 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34094 to 0.34004, saving model to Post_val_weights5.hdf5\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8742 - val_loss: 0.3393 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34004 to 0.33929, saving model to Post_val_weights5.hdf5\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8745 - val_loss: 0.3385 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33929 to 0.33855, saving model to Post_val_weights5.hdf5\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3236 - acc: 0.8746 - val_loss: 0.3380 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33855 to 0.33798, saving model to Post_val_weights5.hdf5\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3229 - acc: 0.8746 - val_loss: 0.3373 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33798 to 0.33733, saving model to Post_val_weights5.hdf5\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3223 - acc: 0.8747 - val_loss: 0.3369 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33733 to 0.33691, saving model to Post_val_weights5.hdf5\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8748 - val_loss: 0.3362 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33691 to 0.33624, saving model to Post_val_weights5.hdf5\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3213 - acc: 0.8751 - val_loss: 0.3364 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33624\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3209 - acc: 0.8750 - val_loss: 0.3355 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33624 to 0.33553, saving model to Post_val_weights5.hdf5\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3205 - acc: 0.8751 - val_loss: 0.3355 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33553 to 0.33553, saving model to Post_val_weights5.hdf5\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3201 - acc: 0.8750 - val_loss: 0.3352 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33553 to 0.33521, saving model to Post_val_weights5.hdf5\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3197 - acc: 0.8750 - val_loss: 0.3348 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33521 to 0.33477, saving model to Post_val_weights5.hdf5\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3194 - acc: 0.8750 - val_loss: 0.3346 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33477 to 0.33456, saving model to Post_val_weights5.hdf5\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3192 - acc: 0.8750 - val_loss: 0.3344 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33456 to 0.33437, saving model to Post_val_weights5.hdf5\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3189 - acc: 0.8752 - val_loss: 0.3341 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33437 to 0.33415, saving model to Post_val_weights5.hdf5\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3186 - acc: 0.8751 - val_loss: 0.3340 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33415 to 0.33405, saving model to Post_val_weights5.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3184 - acc: 0.8750 - val_loss: 0.3339 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33405 to 0.33388, saving model to Post_val_weights5.hdf5\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3182 - acc: 0.8750 - val_loss: 0.3337 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33388 to 0.33373, saving model to Post_val_weights5.hdf5\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3180 - acc: 0.8749 - val_loss: 0.3335 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33373 to 0.33355, saving model to Post_val_weights5.hdf5\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3179 - acc: 0.8748 - val_loss: 0.3334 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33355 to 0.33343, saving model to Post_val_weights5.hdf5\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3177 - acc: 0.8748 - val_loss: 0.3332 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33343 to 0.33322, saving model to Post_val_weights5.hdf5\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3175 - acc: 0.8747 - val_loss: 0.3331 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33322 to 0.33312, saving model to Post_val_weights5.hdf5\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3174 - acc: 0.8749 - val_loss: 0.3330 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33312 to 0.33297, saving model to Post_val_weights5.hdf5\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3172 - acc: 0.8750 - val_loss: 0.3328 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33297 to 0.33282, saving model to Post_val_weights5.hdf5\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3171 - acc: 0.8751 - val_loss: 0.3327 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33282 to 0.33271, saving model to Post_val_weights5.hdf5\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3169 - acc: 0.8752 - val_loss: 0.3326 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33271 to 0.33260, saving model to Post_val_weights5.hdf5\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3168 - acc: 0.8752 - val_loss: 0.3325 - val_acc: 0.8662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_loss improved from 0.33260 to 0.33250, saving model to Post_val_weights5.hdf5\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3167 - acc: 0.8753 - val_loss: 0.3324 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33250 to 0.33243, saving model to Post_val_weights5.hdf5\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3166 - acc: 0.8753 - val_loss: 0.3323 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33243 to 0.33232, saving model to Post_val_weights5.hdf5\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3164 - acc: 0.8753 - val_loss: 0.3322 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33232 to 0.33223, saving model to Post_val_weights5.hdf5\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3163 - acc: 0.8753 - val_loss: 0.3322 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33223 to 0.33217, saving model to Post_val_weights5.hdf5\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3162 - acc: 0.8755 - val_loss: 0.3321 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33217 to 0.33206, saving model to Post_val_weights5.hdf5\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3161 - acc: 0.8754 - val_loss: 0.3320 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33206 to 0.33198, saving model to Post_val_weights5.hdf5\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3160 - acc: 0.8753 - val_loss: 0.3318 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33198 to 0.33182, saving model to Post_val_weights5.hdf5\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8753 - val_loss: 0.3318 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.33182 to 0.33179, saving model to Post_val_weights5.hdf5\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3158 - acc: 0.8753 - val_loss: 0.3317 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33179 to 0.33167, saving model to Post_val_weights5.hdf5\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3157 - acc: 0.8754 - val_loss: 0.3316 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.33167 to 0.33164, saving model to Post_val_weights5.hdf5\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3156 - acc: 0.8754 - val_loss: 0.3315 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33164 to 0.33147, saving model to Post_val_weights5.hdf5\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3155 - acc: 0.8754 - val_loss: 0.3315 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33147\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3154 - acc: 0.8754 - val_loss: 0.3314 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33147 to 0.33137, saving model to Post_val_weights5.hdf5\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3153 - acc: 0.8755 - val_loss: 0.3313 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33137 to 0.33133, saving model to Post_val_weights5.hdf5\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3152 - acc: 0.8754 - val_loss: 0.3312 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33133 to 0.33125, saving model to Post_val_weights5.hdf5\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8754 - val_loss: 0.3313 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33125\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3151 - acc: 0.8754 - val_loss: 0.3311 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.33125 to 0.33113, saving model to Post_val_weights5.hdf5\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3150 - acc: 0.8755 - val_loss: 0.3313 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33113\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3149 - acc: 0.8756 - val_loss: 0.3311 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.33113 to 0.33111, saving model to Post_val_weights5.hdf5\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3148 - acc: 0.8756 - val_loss: 0.3312 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33111\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3147 - acc: 0.8757 - val_loss: 0.3311 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33111\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3146 - acc: 0.8756 - val_loss: 0.3313 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33111\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8755 - val_loss: 0.3313 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33111\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3145 - acc: 0.8756 - val_loss: 0.3314 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33111\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3144 - acc: 0.8756 - val_loss: 0.3312 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33111\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3143 - acc: 0.8756 - val_loss: 0.3315 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33111\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3142 - acc: 0.8757 - val_loss: 0.3313 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33111\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8758 - val_loss: 0.3315 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33111\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3141 - acc: 0.8759 - val_loss: 0.3315 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33111\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8759 - val_loss: 0.3316 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33111\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3140 - acc: 0.8761 - val_loss: 0.3314 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33111\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3139 - acc: 0.8759 - val_loss: 0.3318 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33111\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8760 - val_loss: 0.3317 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33111\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3138 - acc: 0.8761 - val_loss: 0.3318 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33111\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8761 - val_loss: 0.3317 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33111\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3137 - acc: 0.8762 - val_loss: 0.3318 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33111\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8764 - val_loss: 0.3317 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33111\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3136 - acc: 0.8763 - val_loss: 0.3320 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33111\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8763 - val_loss: 0.3318 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33111\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3135 - acc: 0.8764 - val_loss: 0.3321 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33111\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8763 - val_loss: 0.3320 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33111\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3134 - acc: 0.8763 - val_loss: 0.3325 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33111\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8763 - val_loss: 0.3321 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33111\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3133 - acc: 0.8764 - val_loss: 0.3324 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33111\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8765 - val_loss: 0.3322 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33111\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3132 - acc: 0.8765 - val_loss: 0.3326 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33111\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8765 - val_loss: 0.3323 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33111\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8764 - val_loss: 0.3325 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33111\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3131 - acc: 0.8765 - val_loss: 0.3325 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33111\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3130 - acc: 0.8765 - val_loss: 0.3325 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33111\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8766 - val_loss: 0.3325 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33111\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3129 - acc: 0.8766 - val_loss: 0.3325 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33111\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8766 - val_loss: 0.3326 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33111\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3128 - acc: 0.8767 - val_loss: 0.3325 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33111\n",
      "#################################\n",
      "Number of units: 8\n",
      "Batch size: 4096\n",
      "Fold: 4\n",
      "L2_1: 0.009847289899093989\n",
      "best val loss: 0.3311056639088525\n",
      "#################################\n",
      "[[8, 4096, 0.009847289899093989, 0, 0.3230706051497432], [8, 4096, 0.009847289899093989, 1, 0.3273032117587084], [8, 4096, 0.009847289899093989, 2, 0.33204920897009776], [8, 4096, 0.009847289899093989, 3, 0.324557525198362], [8, 4096, 0.009847289899093989, 4, 0.3311056639088525]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LSTM:  66.28643369674683\n",
      "Entire process took:  325.6279122829437\n",
      "Experiment record:\n",
      "[[8, 4096, 0.009847289899093989, 0, 0.3230706051497432], [8, 4096, 0.009847289899093989, 1, 0.3273032117587084], [8, 4096, 0.009847289899093989, 2, 0.33204920897009776], [8, 4096, 0.009847289899093989, 3, 0.324557525198362], [8, 4096, 0.009847289899093989, 4, 0.3311056639088525]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "num_per_fold = x_train.shape[0]//10\n",
    "print(num_per_fold)\n",
    "\n",
    "units = 8\n",
    "batch_s = 4096\n",
    "\n",
    "L2_1_list = [0.009847289899093989]\n",
    "#L2_1_list = [0.005061408663460982, 0.012720438714445361, 0.01457832168093275, 0.012019378840943111, 0.007975782668650504, 0.012679927419555908, 0.011882183248926141, 0.008871834803810222, 0.01115205825093056, 0.009275552398443406]\n",
    "start_time = time.time()\n",
    "\n",
    "exp_record = []\n",
    "\n",
    "for i in range(len(L2_1_list)):\n",
    "    L2_1 = L2_1_list[i]\n",
    "    #L2_2 = L2_2_list[i]\n",
    "    for f in range(5):#10\n",
    "        #start = f*num_per_fold\n",
    "        end = (f+1)*num_per_fold\n",
    "        train1_x = x_train[:end, ]\n",
    "        train2_x = x_train[end:, ]\n",
    "        train_x_lstm = np.append(train2_x, train1_x, axis=0) \n",
    "        train1_y = y_train[:end, ]\n",
    "        train2_y = y_train[end:, ]\n",
    "        train_y_lstm = np.append(train2_y, train1_y, axis=0)\n",
    "        #######################\n",
    "        seed(1)\n",
    "        set_random_seed(1)\n",
    "        #######################\n",
    "        start_time_inner = time.time()\n",
    "        #config = tf.ConfigProto(log_device_placement = True)\n",
    "        #config.gpu_options.visible_device_list='1'\n",
    "        with tf.Session(config = tf.ConfigProto(log_device_placement = True)):\n",
    "            model = Sequential()\n",
    "            model.add(SimpleRNN(units, #CuDNNLSTM\n",
    "                                kernel_regularizer=regularizers.l2(L2_1),\n",
    "                                #return_sequences=True, \n",
    "                                input_shape=(8, 182))) \n",
    "            #model.add(CuDNNLSTM(units, \n",
    "            #                    kernel_regularizer=regularizers.l2(L2_2)))\n",
    "            model.add(Dense(2, activation='softmax'))\n",
    "            #adam = optimizers.Adam(lr=0.0015) #decay=1e-4\n",
    "            #sgdm = optimizers.SGD(lr=0.001, momentum=0.9, decay=1e-7) \n",
    "            model.compile(loss='categorical_crossentropy', \n",
    "                          optimizer='adam', metrics=['accuracy'])\n",
    "            val_weight = \"Post_val_weights\" + str(f+1) + \".hdf5\"\n",
    "            val_checkpointer = ModelCheckpoint(filepath=val_weight,\n",
    "                                               monitor='val_loss', verbose=1,\n",
    "                                               save_best_only=True)\n",
    "            history = model.fit(train_x_lstm, train_y_lstm, batch_size=batch_s, \n",
    "                                epochs=100, validation_split=0.1, \n",
    "                                callbacks=[val_checkpointer], \n",
    "                                verbose=2, \n",
    "                                shuffle=False) \n",
    "            print(\"#################################\")\n",
    "            print(\"Number of units:\", units)\n",
    "            print(\"Batch size:\", batch_s)\n",
    "            print(\"Fold:\", f)\n",
    "            print(\"L2_1:\", L2_1)\n",
    "            #print(\"L2_2:\", L2_2)\n",
    "            print(\"best val loss:\", min(history.history['val_loss']))\n",
    "            exp_record.append([units, batch_s, L2_1, f, min(history.history['val_loss'])])\n",
    "            #exp_record.append([units, batch_s, L2_1, L2_2, f, min(history.history['val_loss'])])\n",
    "            print(\"#################################\")\n",
    "            if(f==4):\n",
    "                print(exp_record)\n",
    "            pyplot.plot(history.history['loss'], label='train')\n",
    "            pyplot.plot(history.history['val_loss'], label='validation')\n",
    "            pyplot.legend()\n",
    "            pyplot.show()\n",
    "    end_time = time.time()\n",
    "    print(\"Time to train LSTM: \", time.time() - start_time_inner)\n",
    "print(\"Entire process took: \", time.time() - start_time)\n",
    "\n",
    "print(\"Experiment record:\")\n",
    "print(exp_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 5)\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.013637599855700826\n",
      "Val loss (mean): 0.32915\n",
      "Val loss (std): 0.00374\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.007849059652276268\n",
      "Val loss (mean): 0.32765\n",
      "Val loss (std): 0.00365\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.00573256388083736\n",
      "Val loss (mean): 0.32833\n",
      "Val loss (std): 0.00354\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.012632372043302849\n",
      "Val loss (mean): 0.3285\n",
      "Val loss (std): 0.00392\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.009527190575994113\n",
      "Val loss (mean): 0.32755\n",
      "Val loss (std): 0.00357\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.010422968740087744\n",
      "Val loss (mean): 0.32799\n",
      "Val loss (std): 0.00349\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.012266357828275072\n",
      "Val loss (mean): 0.32838\n",
      "Val loss (std): 0.00383\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.013489051076148218\n",
      "Val loss (mean): 0.32893\n",
      "Val loss (std): 0.00388\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.012681999778089821\n",
      "Val loss (mean): 0.32856\n",
      "Val loss (std): 0.00384\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.012331437233200173\n",
      "Val loss (mean): 0.32835\n",
      "Val loss (std): 0.00384\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.007419864247038851\n",
      "Val loss (mean): 0.32779\n",
      "Val loss (std): 0.00376\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.012203086925547387\n",
      "Val loss (mean): 0.32844\n",
      "Val loss (std): 0.0037\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.005583773058117212\n",
      "Val loss (mean): 0.32827\n",
      "Val loss (std): 0.00355\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.009096689261577843\n",
      "Val loss (mean): 0.32753\n",
      "Val loss (std): 0.00367\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.0111067227385766\n",
      "Val loss (mean): 0.32813\n",
      "Val loss (std): 0.00371\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.0075591487456188825\n",
      "Val loss (mean): 0.3278\n",
      "Val loss (std): 0.00369\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.007856719275463319\n",
      "Val loss (mean): 0.32762\n",
      "Val loss (std): 0.00366\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.011844637468101177\n",
      "Val loss (mean): 0.32829\n",
      "Val loss (std): 0.00371\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.013409197353885589\n",
      "Val loss (mean): 0.32892\n",
      "Val loss (std): 0.0038\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.013091534201008212\n",
      "Val loss (mean): 0.32867\n",
      "Val loss (std): 0.00383\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.00500063495754628\n",
      "Val loss (mean): 0.32801\n",
      "Val loss (std): 0.00365\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.014236100947219523\n",
      "Val loss (mean): 0.3296\n",
      "Val loss (std): 0.00308\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.01306965163145652\n",
      "Val loss (mean): 0.32868\n",
      "Val loss (std): 0.00388\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.01456012400954233\n",
      "Val loss (mean): 0.32968\n",
      "Val loss (std): 0.00322\n",
      "###############################\n",
      "###############################\n",
      "Units: 8.0\n",
      "Batch size: 4096.0\n",
      "L2 1: 0.009847289899093989\n",
      "Val loss (mean): 0.32762\n",
      "Val loss (std): 0.00352\n",
      "###############################\n",
      "Min Val loss: 0.32752658719207806\n",
      "Min L2 1: 0.00500063495754628\n",
      "Max L2 1: 0.01456012400954233\n"
     ]
    }
   ],
   "source": [
    "exp_record = [[8, 4096, 0.013637599855700826, 0, 0.32415541849638285], [8, 4096, 0.013637599855700826, 1, 0.328797492841531], [8, 4096, 0.013637599855700826, 2, 0.3336404241595352], [8, 4096, 0.013637599855700826, 3, 0.3260851768443459], [8, 4096, 0.013637599855700826, 4, 0.3330834898753473], [8, 4096, 0.007849059652276268, 0, 0.3234921474833237], [8, 4096, 0.007849059652276268, 1, 0.3271810264824427], [8, 4096, 0.007849059652276268, 2, 0.3322985153100644], [8, 4096, 0.007849059652276268, 3, 0.32392454699466106], [8, 4096, 0.007849059652276268, 4, 0.33133533448503727], [8, 4096, 0.00573256388083736, 0, 0.32430463897554496], [8, 4096, 0.00573256388083736, 1, 0.32689393519658094], [8, 4096, 0.00573256388083736, 2, 0.3324947276519753], [8, 4096, 0.00573256388083736, 3, 0.3253669369708725], [8, 4096, 0.00573256388083736, 4, 0.3325899460580614], [8, 4096, 0.012632372043302849, 0, 0.3235187980236366], [8, 4096, 0.012632372043302849, 1, 0.3284282022400906], [8, 4096, 0.012632372043302849, 2, 0.33292572780659324], [8, 4096, 0.012632372043302849, 3, 0.3248028986844403], [8, 4096, 0.012632372043302849, 4, 0.3328416218952826], [8, 4096, 0.009527190575994113, 0, 0.32314381766040423], [8, 4096, 0.009527190575994113, 1, 0.327473776005862], [8, 4096, 0.009527190575994113, 2, 0.3319953565430223], [8, 4096, 0.009527190575994113, 3, 0.32406300855658904], [8, 4096, 0.009527190575994113, 4, 0.33105038348694293], [8, 4096, 0.010422968740087744, 0, 0.323199686697352], [8, 4096, 0.010422968740087744, 1, 0.3274111739236709], [8, 4096, 0.010422968740087744, 2, 0.33219186232103937], [8, 4096, 0.010422968740087744, 3, 0.3254736132231372], [8, 4096, 0.010422968740087744, 4, 0.33166261516119305], [8, 4096, 0.012266357828275072, 0, 0.3234781904318179], [8, 4096, 0.012266357828275072, 1, 0.3282874966852846], [8, 4096, 0.012266357828275072, 2, 0.33251611344298426], [8, 4096, 0.012266357828275072, 3, 0.3248279383447435], [8, 4096, 0.012266357828275072, 4, 0.3328117259831456], [8, 4096, 0.013489051076148218, 0, 0.32349211268257677], [8, 4096, 0.013489051076148218, 1, 0.32887475906059754], [8, 4096, 0.013489051076148218, 2, 0.33334807790510834], [8, 4096, 0.013489051076148218, 3, 0.3258923501577991], [8, 4096, 0.013489051076148218, 4, 0.33304327064090306], [8, 4096, 0.012681999778089821, 0, 0.32375161075452613], [8, 4096, 0.012681999778089821, 1, 0.32847715918083636], [8, 4096, 0.012681999778089821, 2, 0.3328903889656067], [8, 4096, 0.012681999778089821, 3, 0.32485783544200203], [8, 4096, 0.012681999778089821, 4, 0.3328080089050427], [8, 4096, 0.012331437233200173, 0, 0.32333060463966684], [8, 4096, 0.012331437233200173, 1, 0.32828347930434154], [8, 4096, 0.012331437233200173, 2, 0.33255407479074267], [8, 4096, 0.012331437233200173, 3, 0.32488117417396856], [8, 4096, 0.012331437233200173, 4, 0.3326774081291511], [8, 4096, 0.007419864247038851, 0, 0.3233692505624559], [8, 4096, 0.007419864247038851, 1, 0.32721156606200147], [8, 4096, 0.007419864247038851, 2, 0.33271728849550436], [8, 4096, 0.007419864247038851, 3, 0.32417496813668145], [8, 4096, 0.007419864247038851, 4, 0.3314633682178475], [8, 4096, 0.012203086925547387, 0, 0.3238162960992222], [8, 4096, 0.012203086925547387, 1, 0.32825103121194227], [8, 4096, 0.012203086925547387, 2, 0.33239174885359424], [8, 4096, 0.012203086925547387, 3, 0.3249226434746681], [8, 4096, 0.012203086925547387, 4, 0.3328105481047379], [8, 4096, 0.005583773058117212, 0, 0.3244263251343666], [8, 4096, 0.005583773058117212, 1, 0.32679621785704854], [8, 4096, 0.005583773058117212, 2, 0.33247265136729903], [8, 4096, 0.005583773058117212, 3, 0.325100645698302], [8, 4096, 0.005583773058117212, 4, 0.33253972699070533], [8, 4096, 0.009096689261577843, 0, 0.32292151197355395], [8, 4096, 0.009096689261577843, 1, 0.3274908230179235], [8, 4096, 0.009096689261577843, 2, 0.3320276365642659], [8, 4096, 0.009096689261577843, 3, 0.32399680794331065], [8, 4096, 0.009096689261577843, 4, 0.33119615646133643], [8, 4096, 0.0111067227385766, 0, 0.32343410181720356], [8, 4096, 0.0111067227385766, 1, 0.3275030647871787], [8, 4096, 0.0111067227385766, 2, 0.3323815730092121], [8, 4096, 0.0111067227385766, 3, 0.3249447660975986], [8, 4096, 0.0111067227385766, 4, 0.3323992367655213], [8, 4096, 0.0075591487456188825, 0, 0.3233579979305379], [8, 4096, 0.0075591487456188825, 1, 0.32733345440256667], [8, 4096, 0.0075591487456188825, 2, 0.3326135721123009], [8, 4096, 0.0075591487456188825, 3, 0.32431020930496574], [8, 4096, 0.0075591487456188825, 4, 0.3313925801034559], [8, 4096, 0.007856719275463319, 0, 0.32344832708961085], [8, 4096, 0.007856719275463319, 1, 0.3271349229240975], [8, 4096, 0.007856719275463319, 2, 0.3322886445578079], [8, 4096, 0.007856719275463319, 3, 0.3238835867036853], [8, 4096, 0.007856719275463319, 4, 0.33132802236847014], [8, 4096, 0.011844637468101177, 0, 0.3235182853609498], [8, 4096, 0.011844637468101177, 1, 0.3282395578755273], [8, 4096, 0.011844637468101177, 2, 0.3320332533504531], [8, 4096, 0.011844637468101177, 3, 0.3248659537967883], [8, 4096, 0.011844637468101177, 4, 0.3328129621834783], [8, 4096, 0.013409197353885589, 0, 0.323772089739292], [8, 4096, 0.013409197353885589, 1, 0.32879548136253806], [8, 4096, 0.013409197353885589, 2, 0.3332476043840598], [8, 4096, 0.013409197353885589, 3, 0.3257705068169979], [8, 4096, 0.013409197353885589, 4, 0.3330293974193216], [8, 4096, 0.013091534201008212, 0, 0.32379583906709103], [8, 4096, 0.013091534201008212, 1, 0.3286413802180374], [8, 4096, 0.013091534201008212, 2, 0.33308866548956484], [8, 4096, 0.013091534201008212, 3, 0.3250617655397159], [8, 4096, 0.013091534201008212, 4, 0.3327826297980303], [8, 4096, 0.00500063495754628, 0, 0.32385322317045334], [8, 4096, 0.00500063495754628, 1, 0.3267437319030539], [8, 4096, 0.00500063495754628, 2, 0.3321993997292212], [8, 4096, 0.00500063495754628, 3, 0.3247981286118602], [8, 4096, 0.00500063495754628, 4, 0.33245356048059743], [8, 4096, 0.014236100947219523, 0, 0.3263320689382609], [8, 4096, 0.014236100947219523, 1, 0.3287192872881192], [8, 4096, 0.014236100947219523, 2, 0.33326341408038], [8, 4096, 0.014236100947219523, 3, 0.3265016420124567], [8, 4096, 0.014236100947219523, 4, 0.33318215060652345], [8, 4096, 0.01306965163145652, 0, 0.32376977259652656], [8, 4096, 0.01306965163145652, 1, 0.3287034447011892], [8, 4096, 0.01306965163145652, 2, 0.33308406772669297], [8, 4096, 0.01306965163145652, 3, 0.32494522384035657], [8, 4096, 0.01306965163145652, 4, 0.33291676927728264], [8, 4096, 0.01456012400954233, 0, 0.32597265449183727], [8, 4096, 0.01456012400954233, 1, 0.3290702944192273], [8, 4096, 0.01456012400954233, 2, 0.33344563040816994], [8, 4096, 0.01456012400954233, 3, 0.3265323549962183], [8, 4096, 0.01456012400954233, 4, 0.33338806383093894], [8, 4096, 0.009847289899093989, 0, 0.3230706051497432], [8, 4096, 0.009847289899093989, 1, 0.3273032117587084], [8, 4096, 0.009847289899093989, 2, 0.33204920897009776], [8, 4096, 0.009847289899093989, 3, 0.324557525198362], [8, 4096, 0.009847289899093989, 4, 0.3311056639088525]]\n",
    "\n",
    "\n",
    "complete_v = np.array(exp_record)\n",
    "print(complete_v.shape)\n",
    "\n",
    "val_loss_list = []\n",
    "for i in range(25):\n",
    "    h_params = complete_v[(i*5):((i+1)*5), :]\n",
    "    print(\"###############################\")\n",
    "    print(\"Units:\", h_params[0, 0])\n",
    "    print(\"Batch size:\", h_params[0, 1])\n",
    "    print(\"L2 1:\", h_params[0, 2])\n",
    "    #print(\"h2 2:\", h_params[0, 3])\n",
    "    #print(\"Val loss (mean):\", np.mean(h_params[:, 5]))\n",
    "    #print(\"Val loss (std):\", np.std(h_params[:, 5]))\n",
    "    print(\"Val loss (mean):\", \n",
    "          np.round(np.mean(h_params[:, 4]), decimals=5))\n",
    "    print(\"Val loss (std):\", \n",
    "          np.round(np.std(h_params[:, 4]), decimals=5))\n",
    "    print(\"###############################\")\n",
    "    \n",
    "    val_loss_list.append(np.mean(h_params[:, 4]))\n",
    "print(\"Min Val loss:\", min(val_loss_list))\n",
    "print(\"Min L2 1:\", min(complete_v[:, 2]))\n",
    "#print(\"Min L2 2:\", min(complete_v[:, 3]))\n",
    "print(\"Max L2 1:\", max(complete_v[:, 2]))\n",
    "#print(\"Max L2 2:\", max(complete_v[:, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surfaceplot of h_params (Units and batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  4  8 16]\n",
      " [ 1  2  4  8 16]\n",
      " [ 1  2  4  8 16]\n",
      " [ 1  2  4  8 16]\n",
      " [ 1  2  4  8 16]]\n",
      "[[ 128  128  128  128  128]\n",
      " [ 256  256  256  256  256]\n",
      " [ 512  512  512  512  512]\n",
      " [1024 1024 1024 1024 1024]\n",
      " [2048 2048 2048 2048 2048]]\n",
      "[[0.34018 0.33796 0.33886 0.33973 0.34132]\n",
      " [0.33774 0.33643 0.33687 0.33875 0.34047]\n",
      " [0.337   0.33528 0.33611 0.33759 0.33951]\n",
      " [0.33738 0.33621 0.33594 0.3365  0.33861]\n",
      " [0.34153 0.33762 0.33714 0.33859 0.33916]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 4, 8, 16])\n",
    "y = np.array([128, 256, 512, 1024, 2048])\n",
    "complete_list = [[0.34018,0.33796,0.33886,0.33973,0.34132],\n",
    "                 [0.33774,0.33643,0.33687,0.33875,0.34047],\n",
    "                 [0.33700,0.33528,0.33611,0.33759,0.33951],\n",
    "                 [0.33738,0.33621,0.33594,0.33650,0.33861],\n",
    "                 [0.34153,0.33762,0.33714,0.33859,0.33916]]\n",
    "X,Y = np.meshgrid(x, y)\n",
    "print(X)\n",
    "print(Y)\n",
    "print(np.round(complete_list, decimals=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"799.9999880790713\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import axes3d    \n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "X,Y = np.meshgrid(x, y)\n",
    "z = np.array(complete_list)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(z.shape)\n",
    "fig = pyplot.figure(figsize=(8, 6))\n",
    "ax = pyplot.axes(projection='3d')\n",
    "\n",
    "ax.set_xlabel('Units')\n",
    "ax.set_ylabel('Batch size')\n",
    "ax.set_zlabel('Validation loss (MAE)')\n",
    "\n",
    "ax.plot_surface(X, Y, z, rstride=1, cstride=1,\n",
    "                cmap='winter', edgecolor='none')\n",
    "ax.set_title('Post-PREDICT (4 to 4) PDC LSTM hyperparameter search \\n(units and batch size)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface plot of h_params (Layer 1 and 2 L2 params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 6)\n",
      "(35, 3)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"799.9999880790713\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, 'Post-PREDICT PDC (4 to 4) LSTM hyperparameter search (Layer 1 and 2 L2)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D   \n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# CuDNNLSTM\n",
    "exp_record = [[2, 512, 0.011503742417395916, 1.5928644630171495e-08, 0, 0.330696214695423], [2, 512, 0.011503742417395916, 1.5928644630171495e-08, 1, 0.3303653117160351], [2, 512, 0.011503742417395916, 1.5928644630171495e-08, 2, 0.3338263375438445], [2, 512, 0.011503742417395916, 1.5928644630171495e-08, 3, 0.3296992521536978], [2, 512, 0.011503742417395916, 1.5928644630171495e-08, 4, 0.33320469053168045], [2, 512, 0.010054533737348428, 1.240504819968725e-06, 0, 0.33244210705422517], [2, 512, 0.010054533737348428, 1.240504819968725e-06, 1, 0.33181475447632414], [2, 512, 0.010054533737348428, 1.240504819968725e-06, 2, 0.33427960874741536], [2, 512, 0.010054533737348428, 1.240504819968725e-06, 3, 0.3286478312879975], [2, 512, 0.010054533737348428, 1.240504819968725e-06, 4, 0.33687255053492315], [2, 512, 0.013786014709215519, 2.1557510587836568e-07, 0, 0.3295556279650906], [2, 512, 0.013786014709215519, 2.1557510587836568e-07, 1, 0.3296908256254698], [2, 512, 0.013786014709215519, 2.1557510587836568e-07, 2, 0.3338570160405678], [2, 512, 0.013786014709215519, 2.1557510587836568e-07, 3, 0.32975371967979344], [2, 512, 0.013786014709215519, 2.1557510587836568e-07, 4, 0.33451254586727297], [2, 512, 0.006818402253715344, 1.4280777442862709e-05, 0, 0.33223618634960106], [2, 512, 0.006818402253715344, 1.4280777442862709e-05, 1, 0.32887674643282305], [2, 512, 0.006818402253715344, 1.4280777442862709e-05, 2, 0.3347611892014219], [2, 512, 0.006818402253715344, 1.4280777442862709e-05, 3, 0.32999238157132915], [2, 512, 0.006818402253715344, 1.4280777442862709e-05, 4, 0.33522172690135], [2, 512, 0.013522330686745972, 5.887009065667275e-08, 0, 0.3308742811247619], [2, 512, 0.013522330686745972, 5.887009065667275e-08, 1, 0.3328217088827613], [2, 512, 0.013522330686745972, 5.887009065667275e-08, 2, 0.33298014452582914], [2, 512, 0.013522330686745972, 5.887009065667275e-08, 3, 0.32835887055648], [2, 512, 0.013522330686745972, 5.887009065667275e-08, 4, 0.3327879531550826], [2, 512, 0.012501362861060105, 5.263268404506872e-06, 0, 0.33273488661002], [2, 512, 0.012501362861060105, 5.263268404506872e-06, 1, 0.33207973748619796], [2, 512, 0.012501362861060105, 5.263268404506872e-06, 2, 0.33417477322600736], [2, 512, 0.012501362861060105, 5.263268404506872e-06, 3, 0.3273650242013541], [2, 512, 0.012501362861060105, 5.263268404506872e-06, 4, 0.33487109520281966], [2, 512, 0.011661016674853225, 6.672000976511281e-06, 0, 0.3339575461407154], [2, 512, 0.011661016674853225, 6.672000976511281e-06, 1, 0.3295798115353835], [2, 512, 0.011661016674853225, 6.672000976511281e-06, 2, 0.3347304419746176], [2, 512, 0.011661016674853225, 6.672000976511281e-06, 3, 0.3302121811024627], [2, 512, 0.011661016674853225, 6.672000976511281e-06, 4, 0.3342184036726143], [2, 512, 0.01487895448275962, 6.199080690569743e-06, 0, 0.3318766562980518], [2, 512, 0.01487895448275962, 6.199080690569743e-06, 1, 0.3322305351391173], [2, 512, 0.01487895448275962, 6.199080690569743e-06, 2, 0.33813083073549105], [2, 512, 0.01487895448275962, 6.199080690569743e-06, 3, 0.3275693065241764], [2, 512, 0.01487895448275962, 6.199080690569743e-06, 4, 0.3364909582528455], [2, 512, 0.007569684226038301, 4.8802536254275044e-08, 0, 0.3343125497249135], [2, 512, 0.007569684226038301, 4.8802536254275044e-08, 1, 0.33244934890702454], [2, 512, 0.007569684226038301, 4.8802536254275044e-08, 2, 0.33342191435440244], [2, 512, 0.007569684226038301, 4.8802536254275044e-08, 3, 0.32994161878412925], [2, 512, 0.007569684226038301, 4.8802536254275044e-08, 4, 0.33376337356037566], [2, 512, 0.005283059252724981, 6.164037108697286e-07, 0, 0.3312062950441015], [2, 512, 0.005283059252724981, 6.164037108697286e-07, 1, 0.33031076858615316], [2, 512, 0.005283059252724981, 6.164037108697286e-07, 2, 0.3333499977114605], [2, 512, 0.005283059252724981, 6.164037108697286e-07, 3, 0.33237614758530554], [2, 512, 0.005283059252724981, 6.164037108697286e-07, 4, 0.33577618538984777], [2, 512, 0.011357191154610015, 1.711159056883078e-05, 0, 0.3326533601785961], [2, 512, 0.011357191154610015, 1.711159056883078e-05, 1, 0.3299518696676221], [2, 512, 0.011357191154610015, 1.711159056883078e-05, 2, 0.33654550472198175], [2, 512, 0.011357191154610015, 1.711159056883078e-05, 3, 0.3286512641042297], [2, 512, 0.011357191154610015, 1.711159056883078e-05, 4, 0.3341741582385281], [2, 512, 0.01347312387486626, 1.389866339919429e-07, 0, 0.3328871206303089], [2, 512, 0.01347312387486626, 1.389866339919429e-07, 1, 0.3315061343204208], [2, 512, 0.01347312387486626, 1.389866339919429e-07, 2, 0.3353458923972838], [2, 512, 0.01347312387486626, 1.389866339919429e-07, 3, 0.3295804456521196], [2, 512, 0.01347312387486626, 1.389866339919429e-07, 4, 0.334945722895059], [2, 512, 0.012361746251160106, 2.757519365696676e-07, 0, 0.33144191615762764], [2, 512, 0.012361746251160106, 2.757519365696676e-07, 1, 0.3317195760994627], [2, 512, 0.012361746251160106, 2.757519365696676e-07, 2, 0.3377762046543478], [2, 512, 0.012361746251160106, 2.757519365696676e-07, 3, 0.3309179220840945], [2, 512, 0.012361746251160106, 2.757519365696676e-07, 4, 0.3340038675871509], [2, 512, 0.005208071119234904, 7.365202206813203e-07, 0, 0.3315437799448158], [2, 512, 0.005208071119234904, 7.365202206813203e-07, 1, 0.3281919132826621], [2, 512, 0.005208071119234904, 7.365202206813203e-07, 2, 0.3328899422235656], [2, 512, 0.005208071119234904, 7.365202206813203e-07, 3, 0.32599598972420946], [2, 512, 0.005208071119234904, 7.365202206813203e-07, 4, 0.3357307079521536], [2, 512, 0.006116031306650328, 5.127295485984823e-07, 0, 0.329101913588786], [2, 512, 0.006116031306650328, 5.127295485984823e-07, 1, 0.3299288381400861], [2, 512, 0.006116031306650328, 5.127295485984823e-07, 2, 0.3343795937613437], [2, 512, 0.006116031306650328, 5.127295485984823e-07, 3, 0.32985366272647476], [2, 512, 0.006116031306650328, 5.127295485984823e-07, 4, 0.33303383991035107], [2, 512, 0.007977237418558597, 8.926266524691063e-05, 0, 0.3329355904581951], [2, 512, 0.007977237418558597, 8.926266524691063e-05, 1, 0.3316555600974992], [2, 512, 0.007977237418558597, 8.926266524691063e-05, 2, 0.33556078466755607], [2, 512, 0.007977237418558597, 8.926266524691063e-05, 3, 0.3332385562107577], [2, 512, 0.007977237418558597, 8.926266524691063e-05, 4, 0.3349975636409737], [2, 512, 0.011869701913398437, 1.6559533069402407e-07, 0, 0.33042377150546737], [2, 512, 0.011869701913398437, 1.6559533069402407e-07, 1, 0.3294680201937581], [2, 512, 0.011869701913398437, 1.6559533069402407e-07, 2, 0.337127840693234], [2, 512, 0.011869701913398437, 1.6559533069402407e-07, 3, 0.33030594159985144], [2, 512, 0.011869701913398437, 1.6559533069402407e-07, 4, 0.3366877951120075], [2, 512, 0.013616260560016462, 7.26713383628764e-07, 0, 0.3300308758961527], [2, 512, 0.013616260560016462, 7.26713383628764e-07, 1, 0.32778849376572505], [2, 512, 0.013616260560016462, 7.26713383628764e-07, 2, 0.3373556469267572], [2, 512, 0.013616260560016462, 7.26713383628764e-07, 3, 0.3260677042760347], [2, 512, 0.013616260560016462, 7.26713383628764e-07, 4, 0.3340539031140288], [2, 512, 0.006986343591837809, 4.8245979822256096e-05, 0, 0.33106061231323153], [2, 512, 0.006986343591837809, 4.8245979822256096e-05, 1, 0.3305133697024563], [2, 512, 0.006986343591837809, 4.8245979822256096e-05, 2, 0.3334461885307267], [2, 512, 0.006986343591837809, 4.8245979822256096e-05, 3, 0.32946011481229326], [2, 512, 0.006986343591837809, 4.8245979822256096e-05, 4, 0.3339596665323826], [2, 512, 0.011571890306104225, 8.81962242466112e-05, 0, 0.3308160005048005], [2, 512, 0.011571890306104225, 8.81962242466112e-05, 1, 0.33181322511176614], [2, 512, 0.011571890306104225, 8.81962242466112e-05, 2, 0.33535629442560744], [2, 512, 0.011571890306104225, 8.81962242466112e-05, 3, 0.32945343714708475], [2, 512, 0.011571890306104225, 8.81962242466112e-05, 4, 0.3371707672473283], [2, 512, 0.01199655628992095, 7.737271559555158e-06, 0, 0.33245071510125324], [2, 512, 0.01199655628992095, 7.737271559555158e-06, 1, 0.3312450687996825], [2, 512, 0.01199655628992095, 7.737271559555158e-06, 2, 0.3362490973904816], [2, 512, 0.01199655628992095, 7.737271559555158e-06, 3, 0.3271318970577062], [2, 512, 0.01199655628992095, 7.737271559555158e-06, 4, 0.3365079014691693], [2, 512, 0.008523924687578462, 1.0243747621637809e-08, 0, 0.33179501645746284], [2, 512, 0.008523924687578462, 1.0243747621637809e-08, 1, 0.3314009416521641], [2, 512, 0.008523924687578462, 1.0243747621637809e-08, 2, 0.3352649327258618], [2, 512, 0.008523924687578462, 1.0243747621637809e-08, 3, 0.3271410960691017], [2, 512, 0.008523924687578462, 1.0243747621637809e-08, 4, 0.3326421720172927], [2, 512, 0.012899605478253064, 1.2519801642602892e-05, 0, 0.3346302626565186], [2, 512, 0.012899605478253064, 1.2519801642602892e-05, 1, 0.3290281228015297], [2, 512, 0.012899605478253064, 1.2519801642602892e-05, 2, 0.3341820516711787], [2, 512, 0.012899605478253064, 1.2519801642602892e-05, 3, 0.32879729315551404], [2, 512, 0.012899605478253064, 1.2519801642602892e-05, 4, 0.33544130296735036], [2, 512, 0.013140479381170484, 3.801356381681079e-05, 0, 0.33282188156891984], [2, 512, 0.013140479381170484, 3.801356381681079e-05, 1, 0.3302968596645266], [2, 512, 0.013140479381170484, 3.801356381681079e-05, 2, 0.33481050268251294], [2, 512, 0.013140479381170484, 3.801356381681079e-05, 3, 0.3311303837396945], [2, 512, 0.013140479381170484, 3.801356381681079e-05, 4, 0.3352141956976283], [2, 512, 0.00697421284502133, 8.605911687398422e-05, 0, 0.3320179354168518], [2, 512, 0.00697421284502133, 8.605911687398422e-05, 1, 0.3318851223535705], [2, 512, 0.00697421284502133, 8.605911687398422e-05, 2, 0.3350405065915738], [2, 512, 0.00697421284502133, 8.605911687398422e-05, 3, 0.3270069602149272], [2, 512, 0.00697421284502133, 8.605911687398422e-05, 4, 0.33584244438779287], [2, 512, 0.003186216573343716, 2.684797464905755e-07, 0, 0.3305093064503363], [2, 512, 0.003186216573343716, 2.684797464905755e-07, 1, 0.332059428231758], [2, 512, 0.003186216573343716, 2.684797464905755e-07, 2, 0.3345476564398983], [2, 512, 0.003186216573343716, 2.684797464905755e-07, 3, 0.3285025851628934], [2, 512, 0.003186216573343716, 2.684797464905755e-07, 4, 0.3353583902643438], [2, 512, 0.004943311839979575, 1.882518469995204e-08, 0, 0.3313169051610936], [2, 512, 0.004943311839979575, 1.882518469995204e-08, 1, 0.3319102282621707], [2, 512, 0.004943311839979575, 1.882518469995204e-08, 2, 0.3336724465980864], [2, 512, 0.004943311839979575, 1.882518469995204e-08, 3, 0.3288021745598107], [2, 512, 0.004943311839979575, 1.882518469995204e-08, 4, 0.33518825427133436], [2, 512, 0.003967719960927292, 8.275603851871003e-07, 0, 0.32858046152438336], [2, 512, 0.003967719960927292, 8.275603851871003e-07, 1, 0.3306632954195926], [2, 512, 0.003967719960927292, 8.275603851871003e-07, 2, 0.3337993780074761], [2, 512, 0.003967719960927292, 8.275603851871003e-07, 3, 0.3289808169233869], [2, 512, 0.003967719960927292, 8.275603851871003e-07, 4, 0.33323491535688704], [2, 512, 0.003485045402996128, 6.071619290197532e-07, 0, 0.3317595636984061], [2, 512, 0.003485045402996128, 6.071619290197532e-07, 1, 0.3284451737947631], [2, 512, 0.003485045402996128, 6.071619290197532e-07, 2, 0.3353798555142698], [2, 512, 0.003485045402996128, 6.071619290197532e-07, 3, 0.33069204506121186], [2, 512, 0.003485045402996128, 6.071619290197532e-07, 4, 0.33670173405206694], [2, 512, 0.004062247659614507, 2.9219979650324778e-08, 0, 0.3293355335059919], [2, 512, 0.004062247659614507, 2.9219979650324778e-08, 1, 0.3316886630323198], [2, 512, 0.004062247659614507, 2.9219979650324778e-08, 2, 0.33249885621126635], [2, 512, 0.004062247659614507, 2.9219979650324778e-08, 3, 0.326440162832974], [2, 512, 0.004062247659614507, 2.9219979650324778e-08, 4, 0.3327512489215672], [2, 512, 0.00255540482114764, 1.239086157209966e-07, 0, 0.3310207402287868], [2, 512, 0.00255540482114764, 1.239086157209966e-07, 1, 0.3315925597307975], [2, 512, 0.00255540482114764, 1.239086157209966e-07, 2, 0.3359579099688614], [2, 512, 0.00255540482114764, 1.239086157209966e-07, 3, 0.328550654614878], [2, 512, 0.00255540482114764, 1.239086157209966e-07, 4, 0.33510361755103396], [2, 512, 0.0014750824400698247, 6.052225129829875e-08, 0, 0.33209546376390064], [2, 512, 0.0014750824400698247, 6.052225129829875e-08, 1, 0.3356662479548426], [2, 512, 0.0014750824400698247, 6.052225129829875e-08, 2, 0.3340554144229108], [2, 512, 0.0014750824400698247, 6.052225129829875e-08, 3, 0.32672893991944385], [2, 512, 0.0014750824400698247, 6.052225129829875e-08, 4, 0.3389865433402926], [2, 512, 0.002648557065322737, 2.8115575062682035e-08, 0, 0.330615975236335], [2, 512, 0.002648557065322737, 2.8115575062682035e-08, 1, 0.3314779954137858], [2, 512, 0.002648557065322737, 2.8115575062682035e-08, 2, 0.33506100656693444], [2, 512, 0.002648557065322737, 2.8115575062682035e-08, 3, 0.3298838086434972], [2, 512, 0.002648557065322737, 2.8115575062682035e-08, 4, 0.33611558108301887], [2, 512, 0.0029314983960859993, 5.2092273309735754e-08, 0, 0.33159611472609446], [2, 512, 0.0029314983960859993, 5.2092273309735754e-08, 1, 0.3286334168771554], [2, 512, 0.0029314983960859993, 5.2092273309735754e-08, 2, 0.33562923987009374], [2, 512, 0.0029314983960859993, 5.2092273309735754e-08, 3, 0.3307660688712583], [2, 512, 0.0029314983960859993, 5.2092273309735754e-08, 4, 0.337942861611383], [2, 512, 0.0029452022278097867, 3.5971913545665144e-08, 0, 0.3284741621547275], [2, 512, 0.0029452022278097867, 3.5971913545665144e-08, 1, 0.3309403525109877], [2, 512, 0.0029452022278097867, 3.5971913545665144e-08, 2, 0.33074402149657756], [2, 512, 0.0029452022278097867, 3.5971913545665144e-08, 3, 0.3263721279582085], [2, 512, 0.0029452022278097867, 3.5971913545665144e-08, 4, 0.33334756425249645]]\n",
    "\n",
    "# SimpleRNN\n",
    "#exp_record = [[8, 2048, 0.013734294027918162, 1.2615958279503796e-05, 0, 0.5242269070413378], [8, 2048, 0.013734294027918162, 1.2615958279503796e-05, 1, 0.525349099000295], [8, 2048, 0.013734294027918162, 1.2615958279503796e-05, 2, 0.5365885543823242], [8, 2048, 0.013734294027918162, 1.2615958279503796e-05, 3, 0.5425988081296285], [8, 2048, 0.013734294027918162, 1.2615958279503796e-05, 4, 0.5277500336964925], [8, 2048, 0.01468540662820932, 2.66354685054784e-06, 0, 0.5267950610584683], [8, 2048, 0.01468540662820932, 2.66354685054784e-06, 1, 0.5295367503696018], [8, 2048, 0.01468540662820932, 2.66354685054784e-06, 2, 0.5359356097645229], [8, 2048, 0.01468540662820932, 2.66354685054784e-06, 3, 0.5404754420916239], [8, 2048, 0.01468540662820932, 2.66354685054784e-06, 4, 0.5256595751444498], [8, 2048, 0.013691945402139197, 2.6026752396997598e-08, 0, 0.525813970512814], [8, 2048, 0.013691945402139197, 2.6026752396997598e-08, 1, 0.5298542462454902], [8, 2048, 0.013691945402139197, 2.6026752396997598e-08, 2, 0.5415794664488899], [8, 2048, 0.013691945402139197, 2.6026752396997598e-08, 3, 0.5425306218994989], [8, 2048, 0.013691945402139197, 2.6026752396997598e-08, 4, 0.5260763079060449], [8, 2048, 0.010308556915555989, 4.151007824498182e-06, 0, 0.5304228912989298], [8, 2048, 0.010308556915555989, 4.151007824498182e-06, 1, 0.5285163696077135], [8, 2048, 0.010308556915555989, 4.151007824498182e-06, 2, 0.5386655228932699], [8, 2048, 0.010308556915555989, 4.151007824498182e-06, 3, 0.5418453331523472], [8, 2048, 0.010308556915555989, 4.151007824498182e-06, 4, 0.5303631690078312], [8, 2048, 0.007327283279772907, 1.150806353321454e-08, 0, 0.523647670004103], [8, 2048, 0.007327283279772907, 1.150806353321454e-08, 1, 0.5327859327528212], [8, 2048, 0.007327283279772907, 1.150806353321454e-08, 2, 0.5376184265878465], [8, 2048, 0.007327283279772907, 1.150806353321454e-08, 3, 0.5450782774289449], [8, 2048, 0.007327283279772907, 1.150806353321454e-08, 4, 0.5254146420160929], [8, 2048, 0.005113988042774299, 7.674883716837319e-05, 0, 0.5255844561258952], [8, 2048, 0.005113988042774299, 7.674883716837319e-05, 1, 0.5307434382438659], [8, 2048, 0.005113988042774299, 7.674883716837319e-05, 2, 0.53485150358412], [8, 2048, 0.005113988042774299, 7.674883716837319e-05, 3, 0.5425920907656352], [8, 2048, 0.005113988042774299, 7.674883716837319e-05, 4, 0.5274571968449486], [8, 2048, 0.009304688182924905, 3.919774243937197e-06, 0, 0.5232677273750305], [8, 2048, 0.009304688182924905, 3.919774243937197e-06, 1, 0.5287924839125739], [8, 2048, 0.009304688182924905, 3.919774243937197e-06, 2, 0.5406958606508043], [8, 2048, 0.009304688182924905, 3.919774243937197e-06, 3, 0.5436230085160997], [8, 2048, 0.009304688182924905, 3.919774243937197e-06, 4, 0.5279602372911242], [8, 2048, 0.009023513600373647, 2.9933978554623537e-06, 0, 0.5255675659179687], [8, 2048, 0.009023513600373647, 2.9933978554623537e-06, 1, 0.529599747551812], [8, 2048, 0.009023513600373647, 2.9933978554623537e-06, 2, 0.5418711858855354], [8, 2048, 0.009023513600373647, 2.9933978554623537e-06, 3, 0.5419757778909471], [8, 2048, 0.009023513600373647, 2.9933978554623537e-06, 4, 0.5278487567371792], [8, 2048, 0.010226746713525695, 8.777270333934642e-08, 0, 0.5252287040286594], [8, 2048, 0.010226746713525695, 8.777270333934642e-08, 1, 0.5298794255786472], [8, 2048, 0.010226746713525695, 8.777270333934642e-08, 2, 0.5358870939148797], [8, 2048, 0.010226746713525695, 8.777270333934642e-08, 3, 0.5421626020537482], [8, 2048, 0.010226746713525695, 8.777270333934642e-08, 4, 0.5251379496786329], [8, 2048, 0.009783917958024024, 1.7570509162008264e-08, 0, 0.5230150918430753], [8, 2048, 0.009783917958024024, 1.7570509162008264e-08, 1, 0.5325576625929939], [8, 2048, 0.009783917958024024, 1.7570509162008264e-08, 2, 0.539261996852027], [8, 2048, 0.009783917958024024, 1.7570509162008264e-08, 3, 0.5424302851888868], [8, 2048, 0.009783917958024024, 1.7570509162008264e-08, 4, 0.5274898871845669], [8, 2048, 0.010553564738223303, 5.263090212315858e-06, 0, 0.5267839325798882], [8, 2048, 0.010553564738223303, 5.263090212315858e-06, 1, 0.5303446153534783], [8, 2048, 0.010553564738223303, 5.263090212315858e-06, 2, 0.5385400261349148], [8, 2048, 0.010553564738223303, 5.263090212315858e-06, 3, 0.5418429647021823], [8, 2048, 0.010553564738223303, 5.263090212315858e-06, 4, 0.5269385030004713], [8, 2048, 0.010433860175425403, 1.8624999460413055e-06, 0, 0.5313625366952685], [8, 2048, 0.010433860175425403, 1.8624999460413055e-06, 1, 0.5282620739407009], [8, 2048, 0.010433860175425403, 1.8624999460413055e-06, 2, 0.5382821731567383], [8, 2048, 0.010433860175425403, 1.8624999460413055e-06, 3, 0.5451500134997898], [8, 2048, 0.010433860175425403, 1.8624999460413055e-06, 4, 0.5264901434050666], [8, 2048, 0.01260895575602929, 8.306480189406351e-06, 0, 0.5258611058659024], [8, 2048, 0.01260895575602929, 8.306480189406351e-06, 1, 0.5295188352266947], [8, 2048, 0.01260895575602929, 8.306480189406351e-06, 2, 0.5405661355654399], [8, 2048, 0.01260895575602929, 8.306480189406351e-06, 3, 0.5411439078119066], [8, 2048, 0.01260895575602929, 8.306480189406351e-06, 4, 0.5269565528763666], [8, 2048, 0.012123745740820912, 6.248509791352976e-08, 0, 0.5248532167010838], [8, 2048, 0.012123745740820912, 6.248509791352976e-08, 1, 0.5287763313717312], [8, 2048, 0.012123745740820912, 6.248509791352976e-08, 2, 0.5372731739150153], [8, 2048, 0.012123745740820912, 6.248509791352976e-08, 3, 0.540460501352946], [8, 2048, 0.012123745740820912, 6.248509791352976e-08, 4, 0.5239714206589593], [8, 2048, 0.011196820961034394, 2.799269907850571e-07, 0, 0.5258303877512613], [8, 2048, 0.011196820961034394, 2.799269907850571e-07, 1, 0.5287323527336121], [8, 2048, 0.011196820961034394, 2.799269907850571e-07, 2, 0.5389482663472493], [8, 2048, 0.011196820961034394, 2.799269907850571e-07, 3, 0.5430828909873963], [8, 2048, 0.011196820961034394, 2.799269907850571e-07, 4, 0.5255136568811205], [8, 2048, 0.009260917704761921, 5.311772499740694e-05, 0, 0.5231563124126858], [8, 2048, 0.009260917704761921, 5.311772499740694e-05, 1, 0.5301885165638394], [8, 2048, 0.009260917704761921, 5.311772499740694e-05, 2, 0.5362451896667481], [8, 2048, 0.009260917704761921, 5.311772499740694e-05, 3, 0.5419134329160055], [8, 2048, 0.009260917704761921, 5.311772499740694e-05, 4, 0.5271275286144681], [8, 2048, 0.007890750280180877, 3.849657517923333e-07, 0, 0.5255752742025588], [8, 2048, 0.007890750280180877, 3.849657517923333e-07, 1, 0.5302510392400953], [8, 2048, 0.007890750280180877, 3.849657517923333e-07, 2, 0.5363814177513122], [8, 2048, 0.007890750280180877, 3.849657517923333e-07, 3, 0.5430691199302673], [8, 2048, 0.007890750280180877, 3.849657517923333e-07, 4, 0.5260621473259396], [8, 2048, 0.01473855241200446, 6.572063731527396e-08, 0, 0.526260646502177], [8, 2048, 0.01473855241200446, 6.572063731527396e-08, 1, 0.527542490694258], [8, 2048, 0.01473855241200446, 6.572063731527396e-08, 2, 0.5388704651726617], [8, 2048, 0.01473855241200446, 6.572063731527396e-08, 3, 0.5417022616068522], [8, 2048, 0.01473855241200446, 6.572063731527396e-08, 4, 0.525114941491021], [8, 2048, 0.008337740455106704, 7.446760291663771e-05, 0, 0.5263720021777683], [8, 2048, 0.008337740455106704, 7.446760291663771e-05, 1, 0.5278960639105903], [8, 2048, 0.008337740455106704, 7.446760291663771e-05, 2, 0.5385342162979974], [8, 2048, 0.008337740455106704, 7.446760291663771e-05, 3, 0.5443284500439962], [8, 2048, 0.008337740455106704, 7.446760291663771e-05, 4, 0.5268172572718727], [8, 2048, 0.00718801060819828, 1.5073312796375643e-06, 0, 0.5246620207892524], [8, 2048, 0.00718801060819828, 1.5073312796375643e-06, 1, 0.529846426539951], [8, 2048, 0.00718801060819828, 1.5073312796375643e-06, 2, 0.5376503368483649], [8, 2048, 0.00718801060819828, 1.5073312796375643e-06, 3, 0.5387413437101576], [8, 2048, 0.00718801060819828, 1.5073312796375643e-06, 4, 0.5287924146917131], [8, 2048, 0.005658083877872115, 6.907324108593763e-08, 0, 0.5269467938211229], [8, 2048, 0.005658083877872115, 6.907324108593763e-08, 1, 0.528441904703776], [8, 2048, 0.005658083877872115, 6.907324108593763e-08, 2, 0.5390637372334798], [8, 2048, 0.005658083877872115, 6.907324108593763e-08, 3, 0.5433187580638462], [8, 2048, 0.005658083877872115, 6.907324108593763e-08, 4, 0.5264804084565904], [8, 2048, 0.014828705465534338, 1.110743876190369e-08, 0, 0.5252114715046353], [8, 2048, 0.014828705465534338, 1.110743876190369e-08, 1, 0.530470426135593], [8, 2048, 0.014828705465534338, 1.110743876190369e-08, 2, 0.5382516849305895], [8, 2048, 0.014828705465534338, 1.110743876190369e-08, 3, 0.5405394402609931], [8, 2048, 0.014828705465534338, 1.110743876190369e-08, 4, 0.527427950806088], [8, 2048, 0.0062785571292503185, 4.6146824999268986e-07, 0, 0.5258517005708483], [8, 2048, 0.0062785571292503185, 4.6146824999268986e-07, 1, 0.5317648502985637], [8, 2048, 0.0062785571292503185, 4.6146824999268986e-07, 2, 0.5364585013389588], [8, 2048, 0.0062785571292503185, 4.6146824999268986e-07, 3, 0.542794468720754], [8, 2048, 0.0062785571292503185, 4.6146824999268986e-07, 4, 0.5245460402170817], [8, 2048, 0.008221307932041793, 6.987966421208942e-05, 0, 0.5240845356517367], [8, 2048, 0.008221307932041793, 6.987966421208942e-05, 1, 0.5332800193892585], [8, 2048, 0.008221307932041793, 6.987966421208942e-05, 2, 0.5365430009100173], [8, 2048, 0.008221307932041793, 6.987966421208942e-05, 3, 0.5374082610872056], [8, 2048, 0.008221307932041793, 6.987966421208942e-05, 4, 0.5279359411133661], [8, 2048, 0.005709428447501988, 1.63797915243867e-06, 0, 0.5259121624098884], [8, 2048, 0.005709428447501988, 1.63797915243867e-06, 1, 0.52997758436203], [8, 2048, 0.005709428447501988, 1.63797915243867e-06, 2, 0.5415159805615744], [8, 2048, 0.005709428447501988, 1.63797915243867e-06, 3, 0.540463439517551], [8, 2048, 0.005709428447501988, 1.63797915243867e-06, 4, 0.5234653304153019]]\n",
    "\n",
    "complete_v = np.array(exp_record)\n",
    "print(complete_v.shape)\n",
    "xyz = []\n",
    "for i in range(35):\n",
    "    fold_v = complete_v[(i*5):((i+1)*5), :]\n",
    "    xyz.append([fold_v[0, 2], \n",
    "                fold_v[0, 3], \n",
    "                np.mean(fold_v[:, 5])])\n",
    "xyz_v = np.array(xyz)\n",
    "print(xyz_v.shape)\n",
    "xyz_v[:, 1] = np.log10(xyz_v[:, 1])\n",
    "\n",
    "fig = pyplot.figure(figsize=(8, 6))\n",
    "\n",
    "ax = pyplot.axes(projection='3d')\n",
    "ax.set_xlabel('Layer 1 L2')\n",
    "ax.set_ylabel('Layer 2 L2 (10^n)')\n",
    "ax.set_zlabel('Validation loss (MAE)')\n",
    "\n",
    "ax.plot_trisurf(xyz_v[:, 0], xyz_v[:, 1], xyz_v[:, 2],\n",
    "               cmap='winter', edgecolor='none')\n",
    "ax.set_title('Post-PREDICT PDC (4 to 4) LSTM hyperparameter search (Layer 1 and 2 L2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
